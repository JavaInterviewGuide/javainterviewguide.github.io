<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#5391fe" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.0.0"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin><link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png"><link rel="mask-icon" href="/images/logo.png" color="#5391fe"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic%7CComic+Sans+MS:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.css" integrity="sha256-6cQIC71/iBIYXFK+0RHAvwmjwWzkWd+r7v/BX3/vZDc=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-material.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"javainterviewguide.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.19.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"fold":{"enable":true,"height":500},"bookmark":{"enable":true,"color":"#5391fe","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true}}</script><script src="/js/config.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8070896123414715" crossorigin="anonymous"></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-TQWRP5B4WS"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TQWRP5B4WS")</script><meta name="description" content="路漫漫其修远兮，吾将上下而求索"><meta property="og:type" content="website"><meta property="og:title" content="Java面试指南"><meta property="og:url" content="https://javainterviewguide.github.io/default-index/page/2/index.html"><meta property="og:site_name" content="Java面试指南"><meta property="og:description" content="路漫漫其修远兮，吾将上下而求索"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="褚岩"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://javainterviewguide.github.io/default-index/page/2/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"default-index/page/2/index.html","title":""}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Java面试指南</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Java面试指南</h1><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-overview-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">褚岩</p><div class="site-description" itemprop="description">路漫漫其修远兮，吾将上下而求索</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">40</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><span class="site-state-item-count">30</span> <span class="site-state-item-name">分类</span></div><div class="site-state-item site-state-tags"><span class="site-state-item-count">54</span> <span class="site-state-item-name">标签</span></div></nav></div></div></div></div></aside></div><div class="main-inner index posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/4d12791836df.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/4d12791836df.html" class="post-title-link" itemprop="url">Spring boot</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:26:00" itemprop="dateCreated datePublished" datetime="2023-12-20T16:26:00+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-27 15:30:23" itemprop="dateModified" datetime="2023-12-27T15:30:23+08:00">2023-12-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spring/" itemprop="url" rel="index"><span itemprop="name">Spring</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.3k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="什么是Spring-Boot"><a href="#什么是Spring-Boot" class="headerlink" title="什么是Spring Boot"></a>什么是Spring Boot</h1><ul><li>多年来，随着新功能的增加，spring变得越来越复杂。</li><li>如果必须启动一个新的Spring项目，我们必须添加构建路径或添加Maven依赖关系，配置应用程序服务器，添加spring配置。</li><li>因此，开始一个新的spring项目需要很多努力，因为我们现在必须从头开始做所有事情。</li><li>Spring Boot是解决这个问题的方法。Spring Boot已经建立在现有spring框架之上。使用spring启动，我们避免了之前我们必须做的所有样板代码和配置。</li><li>因此，Spring Boot可以帮助我们以最少的工作量，更加健壮地使用现有的Spring功能。</li></ul><h1 id="Spring-Boot有哪些优点"><a href="#Spring-Boot有哪些优点" class="headerlink" title="Spring Boot有哪些优点"></a>Spring Boot有哪些优点</h1><ul><li>减少开发，测试时间和努力。</li><li>使用JavaConfig有助于避免使用XML。</li><li>避免大量的Maven导入和各种版本冲突。</li><li>提供意见发展方法。</li><li>通过提供默认值快速开始开发。</li><li>没有单独的Web服务器需要。这意味着你不再需要启动Tomcat，Glassfish或其他任何东西。</li><li>需要更少的配置 因为没有web.xml文件。只需添加用@ Configuration注释的类，然后添加用@Bean注释的方法，Spring将自动加载对象并像以前一样对其进行管理。您甚至可以将@Autowired添加到bean方法中，以使Spring自动装入需要的依赖关系中。</li><li>基于环境的配置 使用这些属性，您可以将您正在使用的环境传递到应用程序：-Dspring.profiles.active &#x3D; {enviornment}。在加载主应用程序属性文件后，Spring将在（application{environment} .properties）中加载后续的应用程序属性文件。</li></ul><h1 id="什么是JavaConfig"><a href="#什么是JavaConfig" class="headerlink" title="什么是JavaConfig"></a>什么是JavaConfig</h1><ul><li>Spring JavaConfig提供了配置Spring IoC容器的纯Java方法</li><li>因此它有助于避免使用XML配置</li><li>使用JavaConfig的优点在于：<ul><li>面向对象的配置。由于配置被定义为JavaConfig中的类，因此用户可以充分利用Java中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean方法等。</li><li>减少或消除XML配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在XML和Java之间来回切换。</li></ul></li><li>JavaConfig为开发人员提供了一种纯Java方法来配置与XML配置概念相似的Spring容器。</li><li>从技术角度来讲，只使用JavaConfig配置类来配置容器是可行的，但实际上很多人认为将JavaConfig与XML混合匹配是理想的。</li><li>类型安全和重构友好。JavaConfig提供了一种类型安全的方法来配置Spring容器。由于Java 5.0对泛型的支持，现在可以按类型而不是按名称检索bean，不需要任何强制转换或基于字符串的查找。</li></ul><h1 id="如何重新加载Spring-Boot上的更改，而无需重新启动服务器？"><a href="#如何重新加载Spring-Boot上的更改，而无需重新启动服务器？" class="headerlink" title="如何重新加载Spring Boot上的更改，而无需重新启动服务器？"></a>如何重新加载Spring Boot上的更改，而无需重新启动服务器？</h1><ul><li>这可以使用DEV工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat将重新启动。</li><li>Spring Boot有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力</li><li>Java开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。</li><li>开发人员可以重新加载Spring Boot上的更改，而无需重新启动服务器</li><li>这将消除每次手动部署更改的需要</li><li>Spring Boot在发布它的第一个版本时没有这个功能。</li><li>这是开发人员最需要的功能</li><li>DevTools模块完全满足开发人员的需求</li><li>该模块将在生产环境中被禁用</li><li>它还提供H2数据库控制台以更好地测试应用程序。</li></ul><h1 id="Spring-Boot中的监视器是什么？"><a href="#Spring-Boot中的监视器是什么？" class="headerlink" title="Spring Boot中的监视器是什么？"></a>Spring Boot中的监视器是什么？</h1><ul><li>Spring boot actuator是spring启动框架中的重要功能之一</li><li>Spring boot监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。</li><li>有几个指标必须在生产环境中进行检查和监控</li><li>即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息</li><li>监视器模块公开了一组可直接作为HTTP URL访问的REST端点来检查状态。</li></ul><h1 id="如何在Spring-Boot中禁用Actuator端点安全性？"><a href="#如何在Spring-Boot中禁用Actuator端点安全性？" class="headerlink" title="如何在Spring Boot中禁用Actuator端点安全性？"></a>如何在Spring Boot中禁用Actuator端点安全性？</h1><ul><li>默认情况下，所有敏感的HTTP端点都是安全的，只有具有ACTUATOR角色的用户才能访问它们。</li><li>安全性是使用标准的HttpServletRequest.isUserInRole方法实施的</li><li>我们可以使用management.security.enabled &#x3D; false 来禁用安全性</li><li>只有在执行机构端点在防火墙后访问时，才建议禁用安全性。</li></ul><h1 id="如何在自定义端口上运行Spring-Boot应用程序？"><a href="#如何在自定义端口上运行Spring-Boot应用程序？" class="headerlink" title="如何在自定义端口上运行Spring Boot应用程序？"></a>如何在自定义端口上运行Spring Boot应用程序？</h1><ul><li>为了在自定义端口上运行Spring Boot应用程序，您可以在application.properties中指定端口。</li><li>server.port &#x3D; 8090</li></ul><h1 id="什么是YAML？"><a href="#什么是YAML？" class="headerlink" title="什么是YAML？"></a>什么是YAML？</h1><ul><li>YAML是一种人类可读的数据序列化语言</li><li>它通常用于配置文件。</li><li>与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML文件就更加结构化，而且更少混淆</li><li>可以看出YAML具有分层配置数据。</li></ul><h1 id="如何实现Spring-Boot应用程序的安全性？"><a href="#如何实现Spring-Boot应用程序的安全性？" class="headerlink" title="如何实现Spring Boot应用程序的安全性？"></a>如何实现Spring Boot应用程序的安全性？</h1><ul><li>为了实现Spring Boot的安全性，我们使用 spring-boot-starter-security依赖项，并且必须添加安全配置</li><li>它只需要很少的代码。配置类将必须扩展WebSecurityConfigurerAdapter并覆盖其方法。</li></ul><h1 id="如何集成Spring-Boot和ActiveMQ？"><a href="#如何集成Spring-Boot和ActiveMQ？" class="headerlink" title="如何集成Spring Boot和ActiveMQ？"></a>如何集成Spring Boot和ActiveMQ？</h1><ul><li>对于集成Spring Boot和ActiveMQ，我们使用spring-boot-starter-activemq依赖关系</li><li>它只需要很少的配置，并且不需要样板代码</li></ul><h1 id="如何使用Spring-Boot实现分页和排序？"><a href="#如何使用Spring-Boot实现分页和排序？" class="headerlink" title="如何使用Spring Boot实现分页和排序？"></a>如何使用Spring Boot实现分页和排序？</h1><ul><li>使用Spring Boot实现分页非常简单</li><li>使用Spring Data-JPA可以实现将可分页的org.springframework.data.domain.Pageable传递给存储库方法</li></ul><h1 id="什么是Swagger？你用Spring-Boot实现了它吗？"><a href="#什么是Swagger？你用Spring-Boot实现了它吗？" class="headerlink" title="什么是Swagger？你用Spring Boot实现了它吗？"></a>什么是Swagger？你用Spring Boot实现了它吗？</h1><ul><li>Swagger广泛用于可视化API</li><li>使用Swagger UI为前端开发人员提供在线沙箱</li><li>Swagger是用于生成RESTful Web服务的可视化表示的工具，规范和完整框架实现</li><li>它使文档能够以与服务器相同的速度更新</li><li>当通过Swagger正确定义时，消费者可以使用最少量的实现逻辑来理解远程服务并与其进行交互</li><li>因此，Swagger消除了调用服务时的猜测。</li></ul><h1 id="什么是Spring-Profiles？"><a href="#什么是Spring-Profiles？" class="headerlink" title="什么是Spring Profiles？"></a>什么是Spring Profiles？</h1><ul><li>Spring Profiles允许用户根据配置文件（dev，test，prod等）来注册bean</li><li>因此，当应用程序在开发中运行时，只有某些bean可以加载，而在PRODUCTION中，某些其他bean可以加载</li><li>假设我们的要求是Swagger文档仅适用于QA环境，并且禁用所有其他文档</li><li>这可以使用配置文件来完成。Spring Boot使得使用配置文件非常简单。</li></ul><h1 id="什么是Spring-Batch？"><a href="#什么是Spring-Batch？" class="headerlink" title="什么是Spring Batch？"></a>什么是Spring Batch？</h1><ul><li>Spring Boot Batch提供可重用的函数，这些函数在处理大量记录时非常重要，包括日志&#x2F;跟踪，事务管理，作业处理统计信息，作业重新启动，跳过和资源管理</li><li>它还提供了更先进的技术服务和功能，通过优化和分区技术，可以实现极高批量和高性能批处理作业</li><li>简单以及复杂的大批量批处理作业可以高度可扩展的方式利用框架处理重要大量的信息</li></ul><h1 id="什么是FreeMarker模板？"><a href="#什么是FreeMarker模板？" class="headerlink" title="什么是FreeMarker模板？"></a>什么是FreeMarker模板？</h1><ul><li>FreeMarker是一个基于Java的模板引擎，最初专注于使用MVC软件架构进行动态网页生成</li><li>使用Freemarker的主要优点是表示层和业务层的完全分离</li><li>程序员可以处理应用程序代码，而设计人员可以处理html页面设计</li><li>最后使用freemarker可以将这些结合起来，给出最终的输出页面。</li></ul><h1 id="如何使用Spring-Boot实现异常处理？"><a href="#如何使用Spring-Boot实现异常处理？" class="headerlink" title="如何使用Spring Boot实现异常处理？"></a>如何使用Spring Boot实现异常处理？</h1><ul><li>Spring提供了一种使用ControllerAdvice处理异常的非常有用的方法</li><li>我们通过实现一个ControlerAdvice类，来处理控制器类抛出的所有异常。</li></ul><h1 id="您使用了哪些starter-maven依赖项？"><a href="#您使用了哪些starter-maven依赖项？" class="headerlink" title="您使用了哪些starter maven依赖项？"></a>您使用了哪些starter maven依赖项？</h1><ul><li>使用了下面的一些依赖项<ul><li>spring-boot-starter-activemq</li><li>spring-boot-starter-security</li><li>spring-boot-starter-web</li></ul></li><li>这有助于增加更少的依赖关系，并减少版本的冲突。</li></ul><h1 id="如何监视所有Spring-Boot微服务"><a href="#如何监视所有Spring-Boot微服务" class="headerlink" title="如何监视所有Spring Boot微服务"></a>如何监视所有Spring Boot微服务</h1><ul><li>Spring Boot提供监视器端点以监控各个微服务的度量</li><li>这些端点对于获取有关应用程序的信息（如它们是否已启动）以及它们的组件（如数据库等）是否正常运行很有帮助</li><li>但是，使用监视器的一个主要缺点或困难是，我们必须单独打开应用程序的知识点以了解其状态或健康状况</li><li>想象一下涉及50个应用程序的微服务，管理员将不得不击中所有50个应用程序的执行终端。</li></ul><h1 id="SpringBoot项⽬启动时执⾏特定的⽅法"><a href="#SpringBoot项⽬启动时执⾏特定的⽅法" class="headerlink" title="SpringBoot项⽬启动时执⾏特定的⽅法"></a>SpringBoot项⽬启动时执⾏特定的⽅法</h1><ul><li>我们可以通过实现ApplicationRunner和CommandLineRunner，来实现，他们都是在SpringApplication 执⾏之后开始执⾏的</li></ul><h1 id="SpringBoot的启动过程"><a href="#SpringBoot的启动过程" class="headerlink" title="SpringBoot的启动过程"></a>SpringBoot的启动过程</h1><ul><li>通过 SpringFactoriesLoader加载 META-INF&#x2F;spring.factories⽂件，获取并创建 SpringApplicationRunListener对象</li><li>然后由 SpringApplicationRunListener来发出 starting 消息</li><li>创建参数，并配置当前 SpringBoot 应⽤将要使⽤的 Environment</li><li>完成之后，依然由 SpringApplicationRunListener来发出 environmentPrepared 消息</li><li>创建 ApplicationContext</li><li>初始化 ApplicationContext，并设置 Environment，加载相关配置等</li><li>由 SpringApplicationRunListener来发出 contextPrepared消息，告知SpringBoot 应⽤使⽤的 ApplicationContext已准备OK</li><li>将各种 beans 装载⼊ ApplicationContext，继续由 SpringApplicationRunListener来发出 contextLoaded 消息，告知SpringBoot 应⽤使⽤的 ApplicationContext已装填OK</li><li>refresh ApplicationContext，完成IoC容器可⽤的最后⼀步</li><li>由 SpringApplicationRunListener来发出 started 消息</li><li>完成最终的程序的启动</li><li>由 SpringApplicationRunListener来发出 running 消息，告知程序已运⾏起来了</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/5788a7088796.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/5788a7088796.html" class="post-title-link" itemprop="url">Redis</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:24:36" itemprop="dateCreated datePublished" datetime="2023-12-20T16:24:36+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-26 13:25:46" itemprop="dateModified" datetime="2023-12-26T13:25:46+08:00">2023-12-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>20k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>19 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="什么是缓存雪崩"><a href="#什么是缓存雪崩" class="headerlink" title="什么是缓存雪崩"></a>什么是缓存雪崩</h1><ul><li>如果我们的缓存挂掉了，这意味着我们的全部请求都跑去数据库了。</li><li>我们都知道Redis不可能把所有的数据都缓存起来(内存昂贵且有限)，所以Redis需要对数据设置过期时间，并采用的是惰性删除 + 定期删除两种策略对过期键删除。</li><li>如果缓存数据设置的过期时间是相同的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存同时失效，全部请求到数据库中。</li><li>这就是缓存雪崩：Redis挂掉了，请求全部走数据库。</li><li>缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！</li></ul><h1 id="如何解决缓存雪崩"><a href="#如何解决缓存雪崩" class="headerlink" title="如何解决缓存雪崩"></a>如何解决缓存雪崩</h1><ul><li>使用锁或队列、设置过期标志更新缓存、为key设置不同的缓存失效时间</li><li>在缓存的时候给过期时间加上一个随机值，这样就会大幅度的减少缓存在同一时间过期。</li><li>大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上</li><li>一般并发量不是特别多的时候，使用最多的解决方案是加锁排队，加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。</li><li>还有一个解决办法解决方案是：给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存</li><li>对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：<ul><li>事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。</li><li>事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)</li><li>事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。</li></ul></li></ul><h1 id="什么是缓存穿透"><a href="#什么是缓存穿透" class="headerlink" title="什么是缓存穿透"></a>什么是缓存穿透</h1><ul><li>缓存穿透是指查询一个一定不存在的数据</li><li>由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存</li><li>这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。</li><li>这就是缓存穿透：请求的数据在缓存大量不命中，导致请求走数据库。</li><li>缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！</li></ul><h1 id="如何解决缓存穿透"><a href="#如何解决缓存穿透" class="headerlink" title="如何解决缓存穿透"></a>如何解决缓存穿透</h1><ul><li>解决缓存穿透也有两种方案：<ul><li>由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！</li><li>当我们从数据库找不到的时候，我们也将这个空对象设置到缓存里边去。下次再请求的时候，就可以从缓存里边获取了。这种情况我们一般会将空对象设置一个较短的过期时间</li></ul></li></ul><h1 id="缓存与数据库双写一致"><a href="#缓存与数据库双写一致" class="headerlink" title="缓存与数据库双写一致"></a>缓存与数据库双写一致</h1><ul><li>对于读操作，流程是这样的<ul><li>如果我们的数据在缓存里边有，那么就直接取缓存的。</li><li>如果缓存里没有我们想要的数据，我们会先去查询数据库，然后将数据库查出来的数据写到缓存中。最后将数据返回给请求</li></ul></li></ul><h1 id="什么是缓存与数据库双写一致问题"><a href="#什么是缓存与数据库双写一致问题" class="headerlink" title="什么是缓存与数据库双写一致问题"></a>什么是缓存与数据库双写一致问题</h1><ul><li>如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要更新时候呢？各种情况很可能就造成数据库和缓存的数据不一致了。</li><li>这里不一致指的是：数据库的数据跟缓存的数据不一致</li><li>从理论上说，只要我们设置了键的过期时间，我们就能保证缓存和数据库的数据最终是一致的。</li><li>因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。</li></ul><h1 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h1><ul><li>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统</li><li>这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</li><li>解决思路：<ul><li>直接写个缓存刷新页面，上线时手工操作下；</li><li>数据量不大，可以在项目启动的时候自动进行加载；</li><li>定时刷新缓存；</li></ul></li></ul><h1 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h1><ul><li>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：<ul><li>定时去清理过期的缓存；</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</li></ul></li><li>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂</li></ul><h1 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h1><ul><li>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。</li><li>系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</li><li>降级的最终目的是保证核心服务可用，即使是有损的</li><li>而且有些服务是无法降级的（如加入购物车、结算）。</li><li>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅，从而梳理出哪些必须誓死保护，哪些可降级</li><li>比如可以参考日志级别设置预案：<ul><li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li><li>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</li><li>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li><li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li></ul></li></ul><h1 id="为什么使用-Redis"><a href="#为什么使用-Redis" class="headerlink" title="为什么使用 Redis"></a>为什么使用 Redis</h1><ul><li>主要是从两个角度去考虑：性能和并发。</li><li>当然，Redis 还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件，如 ZooKpeer 等代替，并不是非要使用 Redis</li><li>因此，这个问题主要从性能和并发两个角度去答</li></ul><h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><ul><li>我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存</li><li>这样，后面的请求就去缓存中读取，使得请求能够迅速响应。</li></ul><h4 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h4><ul><li>在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。</li><li>这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。</li></ul><h4 id="使用-Redis-有什么缺点"><a href="#使用-Redis-有什么缺点" class="headerlink" title="使用 Redis 有什么缺点"></a>使用 Redis 有什么缺点</h4><ul><li>回答主要是四个问题：<ul><li>缓存和数据库双写一致性问题</li><li>缓存雪崩问题</li><li>缓存击穿问题</li><li>缓存的并发竞争问题</li></ul></li></ul><h4 id="单线程的-Redis-为什么这么快"><a href="#单线程的-Redis-为什么这么快" class="headerlink" title="单线程的 Redis 为什么这么快"></a>单线程的 Redis 为什么这么快</h4><ul><li>回答主要是以下三点：<ul><li>纯内存操作</li><li>单线程操作，避免了频繁的上下文切换</li><li>采用了非阻塞 I&#x2F;O 多路复用机制</li></ul></li></ul><h4 id="I-O-多路复用机制"><a href="#I-O-多路复用机制" class="headerlink" title="I&#x2F;O 多路复用机制"></a>I&#x2F;O 多路复用机制</h4><ul><li>简单来说，就是我们的 redis-client 在操作的时候，会产生具有不同事件类型的 Socket。</li><li>在服务端，有一段 I&#x2F;O 多路复用程序，将其置入队列之中</li><li>然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。</li><li>需要说明的是，这个 I&#x2F;O 多路复用机制，Redis 还提供了 select、epoll、evport、kqueue 等多路复用函数库，大家可以自行去了解。</li></ul><h1 id="Redis-的数据类型，以及每种数据类型的使用场景"><a href="#Redis-的数据类型，以及每种数据类型的使用场景" class="headerlink" title="Redis 的数据类型，以及每种数据类型的使用场景"></a>Redis 的数据类型，以及每种数据类型的使用场景</h1><h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><ul><li>常规的 set&#x2F;get 操作，Value 可以是 String 也可以是数字</li><li>一般做一些复杂的计数功能的缓存</li></ul><h4 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h4><ul><li>这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。</li><li>我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果</li></ul><h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><ul><li>使用 List 的数据结构，可以做简单的消息队列的功能</li><li>可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。</li></ul><h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4><ul><li>因为 Set 堆放的是一堆不重复值的集合，所以可以做全局去重的功能</li><li>为什么不用 JVM 自带的 Set 进行去重？因为我们的系统一般都是集群部署，使用 JVM 自带的 Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。</li><li>另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。</li></ul><h4 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h4><ul><li>Sorted Set多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。</li><li>可以做排行榜应用，取 TOP N 操作</li><li>Sorted Set 可以用来做延时任务</li><li>最后一个应用就是可以做范围查找。</li></ul><h1 id="Redis-的过期策略以及内存淘汰机制"><a href="#Redis-的过期策略以及内存淘汰机制" class="headerlink" title="Redis 的过期策略以及内存淘汰机制"></a>Redis 的过期策略以及内存淘汰机制</h1><ul><li>Redis 采用的是定期删除+惰性删除策略。</li></ul><h4 id="为什么不用定时删除策略"><a href="#为什么不用定时删除策略" class="headerlink" title="为什么不用定时删除策略"></a>为什么不用定时删除策略</h4><ul><li>定时删除，用一个定时器来负责监视 Key，过期则自动删除</li><li>虽然内存及时释放，但是十分消耗 CPU 资源。</li><li>在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。</li></ul><h4 id="定期删除-惰性删除是如何工作"><a href="#定期删除-惰性删除是如何工作" class="headerlink" title="定期删除+惰性删除是如何工作"></a>定期删除+惰性删除是如何工作</h4><ul><li>定期删除，Redis 默认每隔 100ms 检查，是否有过期的 Key，有过期 Key 则删除。</li><li>需要说明的是，Redis 不是每隔 100ms 将所有的 Key 检查一次，而是随机抽取进行检查(如果每隔 100ms，全部 Key 进行检查，Redis 岂不是卡死)。</li><li>如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。</li><li>也就是说在你获取某个 Key 的时候，Redis 会检查一下，这个 Key 如果设置了过期时间，那么是否过期了？如果过期了此时就会删除。</li><li>采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除 Key。然后你也没即时去请求 Key，也就是说惰性删除也没生效。这样，Redis的内存会越来越高。那么就应该采用内存淘汰机制。</li><li>在 redis.conf 中有一行配置：maxmemory-policy volatile-lru</li><li>该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)：<ul><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。</li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。</li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。</li><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。</li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。</li></ul></li><li>PS：如果没有设置 expire 的 Key，不满足先决条件(prerequisites)；那么 volatile-lru，volatile-random 和 volatile-ttl 策略的行为，和 noeviction(不删除) 基本上一致。</li></ul><h1 id="Redis-和数据库双写一致性问题"><a href="#Redis-和数据库双写一致性问题" class="headerlink" title="Redis 和数据库双写一致性问题"></a>Redis 和数据库双写一致性问题</h1><ul><li>一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性</li><li>数据库和缓存双写，就必然会存在不一致的问题。</li><li>首先，采取正确更新策略，先更新数据库，再删缓存</li><li>其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</li></ul><h1 id="如何解决-Redis-的并发竞争-Key-问题"><a href="#如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="如何解决 Redis 的并发竞争 Key 问题"></a>如何解决 Redis 的并发竞争 Key 问题</h1><h4 id="如果对这个-Key-操作，不要求顺序"><a href="#如果对这个-Key-操作，不要求顺序" class="headerlink" title="如果对这个 Key 操作，不要求顺序"></a>如果对这个 Key 操作，不要求顺序</h4><ul><li>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</li></ul><h4 id="如果对这个-Key-操作，要求顺序"><a href="#如果对这个-Key-操作，要求顺序" class="headerlink" title="如果对这个 Key 操作，要求顺序"></a>如果对这个 Key 操作，要求顺序</h4><ul><li>假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。</li><li>期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化</li><li>这种时候我们在数据写入数据库的时候，需要保存一个时间戳。</li><li>假设时间戳如下：<ul><li>系统A key 1 {valueA 3:00}</li><li>系统B key 1 {valueB 3:05}</li><li>系统C key 1 {valueC 3:10}</li></ul></li><li>那么，假设这会系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。</li><li>其他方法，比如利用队列，将 set 方法变成串行访问也可以。总之，灵活变通。</li></ul><h1 id="分布式缓存，⼀致性hash"><a href="#分布式缓存，⼀致性hash" class="headerlink" title="分布式缓存，⼀致性hash"></a>分布式缓存，⼀致性hash</h1><ul><li>⼀致性hash算法：⼀致性hash算法是对我们要存储数据的服务器进⾏hash计算，进⽽确认每个key的存储位置</li><li>这⾥提到的⼀致性hash算法ketama的做法是：选择具体的机器节点不在只依赖需要缓存数据的key的hash本身了，⽽是机器节点本身也进⾏了hash运<br>算。</li><li>⼀致性hash算法是分布式系统中常⽤算法，设计⽬的是为了解决因特⽹中的热点(hot spot)问题</li><li>解决了P2P环境最为关键问题—如何在动态⽹络拓扑中分布存储和路由；</li><li>⼀致性hash算法引⼊虚拟节点机制，解决服务节点少时数据倾斜问题(即对每⼀个服务节点计算多个哈希，每个计算结果位置都放置⼀个此服务节点，称为虚拟节点。)；</li><li>具体做法：如果有⼀个写⼊缓存的请求，其中Key值为K，计算器hash值Hash(K)， Hash(K) 对应于图 – 1环中的某⼀个点，如果该点对应没有映射到具体的某⼀个机器节点，那么顺时针查找，直到第⼀次找到有映射机器的节点，该节点就是确定的⽬标节点，如果超过了2^32仍然找不到节点，则命中第⼀个机器节点</li><li>⽐如 Hash(K) 的值介于A~B之间，那么命中的机器节点应该是B节点（如上图 ）。</li><li>数据保存流程：<ul><li>⾸先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。</li><li>然后采⽤同样的⽅法求出存储数据的键的哈希值，并映射到相同的圆上。</li><li>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第⼀个服务器上。如果超过232仍然找不到服务器，就会保存到第⼀台memcached服务器上。</li></ul></li></ul><h1 id="如何解决缓存单机热点问题"><a href="#如何解决缓存单机热点问题" class="headerlink" title="如何解决缓存单机热点问题"></a>如何解决缓存单机热点问题</h1><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ul><li>缓存服务器⾃身有限流保持<ul><li>缓存服务器数量 * 单机能够承受的qps &gt; ⽤户最⼤的QPS 就会触发限流保护</li><li>针对这个原因：可以做横向扩容。加机器即可</li></ul></li><li>⽤户访问过来cache服务器集中打到⼀台上⾯了<ul><li>⼤流量并没有按预期的那样分摊到不同的cache机器上导致出现单机热点。(热点数据)</li><li>针对这个原因：只要计算cache-hash算法不出问题，那基本上可以做到缓存的随机分布均匀的</li></ul></li><li>缓存⾥⾯的value过⼤<ul><li>导致虽然QPS不⾼，但⽹络流量（qps * 单个value的⼤⼩）还是过⼤，触发了cache机器单台机器的⽹络流量限流；</li><li>针对这个原因：需要把⼤value进⾏精简，部分可以放在本机内存⽽不需要⾛远程获取这种⽅式的。</li></ul></li></ul><h4 id="解决⽅法"><a href="#解决⽅法" class="headerlink" title="解决⽅法"></a>解决⽅法</h4><ul><li>针对cache中元素key的访问监控</li><li>⼀旦发现cache有qps限流或⽹络⼤⼩限流时，能够通过监控看到到底是哪个key并发访问量过⼤导致，或者哪些key返回的value⼤⼩较⼤</li><li>再结合cache散列算法，通过⼀定的规则动态修改key值去平摊到各个cache机器上去。</li></ul><h1 id="memcache与redis的区别"><a href="#memcache与redis的区别" class="headerlink" title="memcache与redis的区别"></a>memcache与redis的区别</h1><ul><li>Redis中，并不是所有的数据都⼀直存储在内存中的，这是和Memcached相⽐⼀个最⼤的区别。</li><li>Memcache仅仅⽀持简单的k&#x2F;v类型的数据，Redis同时还提供String, list，set，hash等数据结构的存储。</li><li>Redis⽀持数据的备份，即master-slave模式的数据备份。</li><li>Redis⽀持数据的持久化，可以将内存中的数据保持在磁盘中（rdb定时快照和aof实时记录操作命令的⽇志备<br>份），重启的时候可以再次加载进⾏使⽤。Redis在很多⽅⾯具备数据库的特征，或者说就是⼀个数据库系统，⽽<br>Memcached只是简单的K&#x2F;V缓存</li><li>Redis可以做⼀些聚合、排序操作。</li><li>memcache使⽤cas乐观锁做⼀致性：拿版本号，操作，对⽐版本号，如果⼀致就操作，不⼀致就放弃任何操作；</li><li>⼤数据memcached性能更⾼。由于Redis只使⽤单核，⽽Memcached可以使⽤多核，所以平均每⼀个核上<br>Redis在存储⼩数据时⽐Memcached性能更⾼。⽽在100k以上的数据中，Memcached性能要⾼于Redis 。</li></ul><h1 id="redis-本身有持久化，为什么还要写进-mysql-呢？"><a href="#redis-本身有持久化，为什么还要写进-mysql-呢？" class="headerlink" title="redis 本身有持久化，为什么还要写进 mysql 呢？"></a>redis 本身有持久化，为什么还要写进 mysql 呢？</h1><ul><li>RDB：快照形式是直接把内存中的数据保存到⼀个 dump ⽂件中，定时保存，保存策略。</li><li>AOF：把所有的对Redis的服务器进⾏修改的命令都存到⼀个⽂件⾥，命令的集合。</li><li>RDB会丢数据，AOF性能不⾏</li><li>有改动先插⼊数据库，再插缓存，⽐较靠谱但性能⼀般；</li><li>有改动先插缓存，批量更新到数据库，靠谱度略差，但性能好。</li></ul><h1 id="redis的数据结构和各种应⽤场景？"><a href="#redis的数据结构和各种应⽤场景？" class="headerlink" title="redis的数据结构和各种应⽤场景？"></a>redis的数据结构和各种应⽤场景？</h1><ul><li>更多的数据结构；</li><li>可持久化；</li><li>计数器；</li><li>发布-订阅功能；</li><li>事务功能；</li><li>过期回调功能；</li><li>队列功能；</li><li>排序、聚合查询功能。</li></ul><h1 id="redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高"><a href="#redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高" class="headerlink" title="redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高"></a>redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高</h1><ul><li>区别：<ul><li>mc可缓存图片和视频。rd支持除k&#x2F;v更多的数据结构;</li><li>rd可以使用虚拟内存，rd可持久化和aof灾难恢复，rd通过主从支持数据备份;</li><li>rd可以做消息队列。</li></ul></li><li>原因：mc多线程模型引入了缓存一致性和锁，加锁带来了性能损耗。</li></ul><h1 id="redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？"><a href="#redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？" class="headerlink" title="redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？"></a>redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？</h1><ul><li>主从复制实现<ul><li>主节点将自己内存中的数据做一份快照，将快照发给从节点，从节点将数据恢复到内存中</li><li>之后再每次增加新数据的时候，主节点以类似于mysql的二进制日志方式将语句发送给从节点，从节点拿到主节点发送过来的语句进行重放。</li></ul></li><li>分片方式：<ul><li>客户端分片</li><li>基于代理的分片<ul><li>Twemproxy</li><li>codis</li></ul></li><li>路由查询分片</li></ul></li><li>Redis-cluster（本身提供了自动将数据分散到Redis Cluster不同节点的能力，整个数据集合的某个数据子集存储在哪个节点对于用户来说是透明的）</li><li>redis-cluster分片原理<ul><li>Cluster中有一个16384长度的槽(虚拟槽)，编号分别为0-16383</li><li>每个Master节点都会负责一部分的槽，当有某个key被映射到某个Master负责的槽，那么这个Master负责为这个key提供服务</li><li>至于哪个Master节点负责哪个槽，可以由用户指定，也可以在初始化的时候自动生成，只有Master才拥有槽的所有权</li><li>Master节点维护着一个16384&#x2F;8字节的位序列，Master节点用bit来标识对于某个槽自己是否拥有</li><li>比如对于编号为1的槽，Master只要判断序列的第二位（索引从0开始）是不是为1即可</li><li>这种结构很容易添加或者删除节点</li><li>比如如果我想新添加个节点D, 我需要从节点A、B、 C中得部分槽到D上。</li></ul></li></ul><h1 id="使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？"><a href="#使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？" class="headerlink" title="使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？"></a>使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？</h1><ul><li>redis:<ul><li>线程A setnx(上锁的对象,超时时的时间戳t1)，如果返回true，获得锁。</li><li>线程B 用get获取t1,与当前时间戳比较,判断是是否超时,没超时false,若超时执行第3步;</li><li>计算新的超时时间t2,使用getset命令返回t3(该值可能其他线程已经修改过),如果t1&#x3D;&#x3D;t3，获得锁，如果t1!&#x3D;t3说明锁被其他线程获取了。</li><li>获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）。</li></ul></li><li>zk:<ul><li>客户端对某个方法加锁时，在zk上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点node1;</li><li>客户端获取该路径下所有已经创建的子节点，如果发现自己创建的node1的序号是最小的，就认为这个客户端获得了锁。</li><li>如果发现node1不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待。</li><li>获取锁后，处理完逻辑，删除自己创建的node1即可。</li></ul></li><li>区别:zk性能差一些，开销大，实现简单。</li></ul><h1 id="知道redis的持久化吗？底层如何实现的？有什么优点缺点？"><a href="#知道redis的持久化吗？底层如何实现的？有什么优点缺点？" class="headerlink" title="知道redis的持久化吗？底层如何实现的？有什么优点缺点？"></a>知道redis的持久化吗？底层如何实现的？有什么优点缺点？</h1><ul><li>RDB(Redis DataBase:在不同的时间点将redis的数据生成的快照同步到磁盘等介质上)<ul><li>内存到硬盘的快照，定期更新</li><li>缺点：耗时，耗性能(fork+io操作)，易丢失数据。</li></ul></li><li>AOF(Append Only File：将redis所执行过的所有指令都记录下来，在下次redis重启时，只需要执行指令就可以了)<ul><li>写日志</li><li>缺点：体积大，恢复速度慢。</li></ul></li><li>bgsave做镜像全量持久化，aof做增量持久化</li><li>因为bgsave会消耗比较长的时间，不够实时，在停机的时候会导致大量的数据丢失，需要aof来配合</li><li>在redis实例重启时，优先使用aof来恢复内存的状态，如果没有aof日志，就会使用rdb文件来恢复</li><li>Redis会定期做aof重写，压缩aof文件日志大小</li><li>Redis4.0之后有了混合持久化的功能，将bgsave的全量和aof的增量做了融合处理，这样既保证了恢复的效率又兼顾了数据的安全性</li><li>bgsave的原理，fork和cow,</li><li>fork是指redis通过创建子进程来进行bgsave操作</li><li>cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。</li></ul><h1 id="redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？"><a href="#redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？" class="headerlink" title="redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？"></a>redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？</h1><ul><li>过期策略:<ul><li>定时过期(一key一定时器)</li><li>惰性过期：只有使用key时才判断key是否已过期，过期则清除</li><li>定期过期：前两者折中。</li></ul></li><li>LRU:new LinkedHashMap&lt;K, V&gt;(capacity, DEFAULT_LOAD_FACTORY, true);&#x2F;&#x2F;第三个参数置为true，代表linkedlist按访问顺序排序，可作为LRU缓存；设为false代表按插入顺序排序，可作为FIFO缓存</li><li>LRU算法实现<ul><li>通过双向链表来实现，新数据插入到链表头部</li><li>每当缓存命中（即缓存数据被访问），则将数据移到链表头部</li><li>当链表满的时候，将链表尾部的数据丢弃。</li></ul></li><li>LinkedHashMap：HashMap和双向链表合二为一即是LinkedHashMap。HashMap是无序的，LinkedHashMap通过维护一个额外的双向链表保证了迭代顺序。该迭代顺序可以是插入顺序（默认），也可以是访问顺序。</li></ul><h1 id="在选择缓存时，什么时候选择redis，什么时候选择memcached"><a href="#在选择缓存时，什么时候选择redis，什么时候选择memcached" class="headerlink" title="在选择缓存时，什么时候选择redis，什么时候选择memcached"></a>在选择缓存时，什么时候选择redis，什么时候选择memcached</h1><h4 id="选择redis的情况"><a href="#选择redis的情况" class="headerlink" title="选择redis的情况"></a>选择redis的情况</h4><ul><li>复杂数据结构，value的数据是哈希，列表，集合，有序集合等这种情况下，会选择redis, 因为memcache无法满足这些数据结构，最典型的的使用场景是，用户订单列表，用户消息，帖子评论等。</li><li>需要进行数据的持久化功能，但是注意，不要把redis当成数据库使用，如果redis挂了，内存能够快速恢复热数据，不会将压力瞬间压在数据库上，没有cache预热的过程。对于只读和数据一致性要求不高的场景可以采用持久化存储</li><li>高可用，redis支持集群，可以实现主动复制，读写分离，而对于memcache如果想要实现高可用，需要进行二次开发。</li><li>存储的内容比较大，memcache存储的value最大为1M。</li></ul><h4 id="选择memcache的场景"><a href="#选择memcache的场景" class="headerlink" title="选择memcache的场景"></a>选择memcache的场景</h4><ul><li>纯KV,数据量非常大的业务，使用memcache更合适，原因是，<ul><li>memcache的内存分配采用的是预分配内存池的管理方式，能够省去内存分配的时间，redis是临时申请空间，可能导致碎片化。</li><li>虚拟内存使用，memcache将所有的数据存储在物理内存里，redis有自己的vm机制，理论上能够存储比物理内存更多的数据，当数据超量时，引发swap,把冷数据刷新到磁盘上，从这点上，数据量大时，memcache更快</li><li>网络模型，memcache使用非阻塞的IO复用模型，redis也是使用非阻塞的IO复用模型，但是redis还提供了一些非KV存储之外的排序，聚合功能，复杂的CPU计算，会阻塞整个IO调度，从这点上由于redis提供的功能较多，memcache更快些</li><li>线程模型，memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程可能存在锁冲突。redis使用的单线程，虽然无锁冲突，但是难以利用多核的特性提升吞吐量。</li></ul></li></ul><h1 id="Redis常见的性能问题和解决方案"><a href="#Redis常见的性能问题和解决方案" class="headerlink" title="Redis常见的性能问题和解决方案"></a>Redis常见的性能问题和解决方案</h1><ul><li>master最好不要做持久化工作，如RDB内存快照和AOF日志文件</li><li>如果数据比较重要，某个slave开启AOF备份，策略设置成每秒同步一次</li><li>为了主从复制的速度和连接的稳定性，master和Slave最好在一个局域网内</li><li>尽量避免在压力大得主库上增加从库</li><li>主从复制不要采用网状结构，尽量是线性结构，<code>Master&lt;-- Slave1 &lt;--Slave2</code></li></ul><h1 id="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来"><a href="#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来" class="headerlink" title="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来</h1><ul><li>使用keys指令可以扫出指定模式的key列表。</li><li>对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</li><li>这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复</li><li>这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</li></ul><h1 id="使用Redis做过异步队列吗，是如何实现的"><a href="#使用Redis做过异步队列吗，是如何实现的" class="headerlink" title="使用Redis做过异步队列吗，是如何实现的"></a>使用Redis做过异步队列吗，是如何实现的</h1><ul><li>使用list类型保存数据信息</li><li>rpush生产消息</li><li>lpop消费消息</li><li>当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息</li><li>如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来</li><li>redis可以通过pub&#x2F;sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</li></ul><h1 id="Redis如何实现延时队列"><a href="#Redis如何实现延时队列" class="headerlink" title="Redis如何实现延时队列"></a>Redis如何实现延时队列</h1><ul><li>使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理</li></ul><h1 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h1><ul><li>通常会采取的一种方式是主从架构Master&#x2F;Slave，Master 以写为主，Slave 以读为主，Master 主节点更新后根据配置，自动同步到从机Slave 节点。</li><li>redis-server –port 6380 –slaveof<master-ip><master-port>，配置当前服务为某Redis服务的Slave</master-port></master-ip></li><li>SLAVEOF host port命令，将当前服务器状态从Master修改为别的服务器的Slave</li><li>redis&gt;SLAVEOF 192.169.0.110 6379，将服务器转换为Slave</li><li>redis&gt;SLAVEOF NO ONE 将服务器状态重新恢复到Master，不会丢弃已同步的数据</li><li>配置方式：启动时，服务器读取配置文件，并自动成为指定服务器的从服务器</li><li>slaveof <master-ip><master-port></master-port></master-ip></li><li>slaveof 127.0.0.1 6379</li></ul><h1 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h1><ul><li>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： <ul><li>从服务器连接主服务器，发送SYNC命令； </li><li>主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； </li><li>主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； </li><li>从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； </li><li>主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； </li><li>从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</li></ul></li></ul><h1 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h1><ul><li>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 </li><li>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。</li></ul><p> </p><h1 id="Redis主从同步策略"><a href="#Redis主从同步策略" class="headerlink" title="Redis主从同步策略"></a>Redis主从同步策略</h1><ul><li>主从刚刚连接的时候，进行全量同步；</li><li>全同步结束后，进行增量同步</li><li>当然，如果有需要，slave 在任何时候都可以发起全量同步</li><li>redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</li><li>如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机。</li><li>在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。</li><li>不持久化的主服务器自动重启非常危险呢？</li></ul><h1 id="哨兵模式（sentinel）"><a href="#哨兵模式（sentinel）" class="headerlink" title="哨兵模式（sentinel）"></a>哨兵模式（sentinel）</h1><ul><li>反客为主的自动版，能够后台监控Master库是否故障，如果故障了根据投票数自动将slave库转换为主库</li><li>一组sentinel能同时监控多个Master。</li><li>使用步骤：<ul><li>在Master对应redis.conf同目录下新建sentinel.conf文件，名字绝对不能错；</li><li>配置哨兵，在sentinel.conf文件中填入内容：<ul><li>sentinel monitor 被监控数据库名字（自己起名字） ip port 1</li><li>说明：上面最后一个数字1，表示主机挂掉后slave投票看让谁接替成为主机，得票数多少后成为主机。</li></ul></li><li>启动哨兵模式：<ul><li>命令键入：redis-sentinel  &#x2F;myredis&#x2F;sentinel.conf</li><li>注：上述sentinel.conf路径按各自实际情况配置</li></ul></li></ul></li></ul><h1 id="复制的缺点"><a href="#复制的缺点" class="headerlink" title="复制的缺点"></a>复制的缺点</h1><ul><li>延时，由于所有的写操作都是在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟</li><li>当系统很繁忙的时候，延迟问题会更加严重</li><li>Slave机器数量的增加也会使得这个问题更加严重。</li></ul><h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><ul><li>redis cluster在设计的时候，就考虑到了去中心化，去中间件</li><li>也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态</li><li>每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。</li><li>Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的</li><li>redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384</li><li>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步</li><li>当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据</li><li>只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。</li><li>需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。</li></ul><h1 id="什么是-Redis？"><a href="#什么是-Redis？" class="headerlink" title="什么是 Redis？"></a>什么是 Redis？</h1><ul><li>Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存</li><li>因为纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。</li><li>Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能，比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务，用他的 Set 可以做高性能的 tag 系统等等</li><li>另外 Redis 也可以对存入的Key-Value 设置 expire 时间，因此也可以被当作一 个功能加强版的 memcached 来用。</li><li>Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。</li></ul><h1 id="Redis-相比-memcached-有哪些优势？"><a href="#Redis-相比-memcached-有哪些优势？" class="headerlink" title="Redis 相比 memcached 有哪些优势？"></a>Redis 相比 memcached 有哪些优势？</h1><ul><li>memcached 所有的值均是简单的字符串，Redis 作为其替代者，支持更为丰富的数据类型</li><li>Redis 的速度比 memcached 快很多</li><li>Redis 可以持久化其数据</li></ul><h1 id="Redis-主要消耗什么物理资源？"><a href="#Redis-主要消耗什么物理资源？" class="headerlink" title="Redis 主要消耗什么物理资源？"></a>Redis 主要消耗什么物理资源？</h1><ul><li>内存。</li></ul><h1 id="Redis-的全称是什么？"><a href="#Redis-的全称是什么？" class="headerlink" title="Redis 的全称是什么？"></a>Redis 的全称是什么？</h1><ul><li>Remote Dictionary Server。</li></ul><h1 id="Redis-官方为什么不提供-Windows-版本？"><a href="#Redis-官方为什么不提供-Windows-版本？" class="headerlink" title="Redis 官方为什么不提供 Windows 版本？"></a>Redis 官方为什么不提供 Windows 版本？</h1><ul><li>因为目前 Linux 版本已经相当稳定，而且用户量很大，无需开发 windows 版本，反而会带来兼容性等问题。</li></ul><h1 id="一个字符串类型的值能存储最大容量是多少？"><a href="#一个字符串类型的值能存储最大容量是多少？" class="headerlink" title="一个字符串类型的值能存储最大容量是多少？"></a>一个字符串类型的值能存储最大容量是多少？</h1><ul><li>512M</li></ul><h1 id="为什么-Redis-需要把所有数据放到内存中？"><a href="#为什么-Redis-需要把所有数据放到内存中？" class="headerlink" title="为什么 Redis 需要把所有数据放到内存中？"></a>为什么 Redis 需要把所有数据放到内存中？</h1><ul><li>Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。</li><li>所以 Redis 具有快速和数据持久化的特征</li><li>如果不将数据放在内存中，磁盘 I&#x2F;O 速度为严重影响 Redis 的性能</li><li>在内存越来越便宜的今天，Redis 将会越来越受欢迎。</li><li>如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。</li></ul><h1 id="Redis-集群方案应该怎么做？都有哪些方案？"><a href="#Redis-集群方案应该怎么做？都有哪些方案？" class="headerlink" title="Redis 集群方案应该怎么做？都有哪些方案？"></a>Redis 集群方案应该怎么做？都有哪些方案？</h1><ul><li>twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通 Redis 无任何区别，设置好它下属的多个 Redis 实例后，使用时在本需要连接 Redis 的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性 hash 算法，将请求转接到具体 Redis，将结果再返回 twemproxy。使用方式简便(相对 Redis 只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy 自身单端口实例的压力，使用一致性 hash 后，对Redis 节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。</li><li>codis，目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新 hash 节点。</li><li>Redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。</li><li>在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 key 进行 hash 计算，然后去对应的 Redis 实例操作数据。 这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。</li></ul><h1 id="Redis-集群方案什么情况下会导致整个集群不可用？"><a href="#Redis-集群方案什么情况下会导致整个集群不可用？" class="headerlink" title="Redis 集群方案什么情况下会导致整个集群不可用？"></a>Redis 集群方案什么情况下会导致整个集群不可用？</h1><ul><li>有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。</li></ul><h1 id="MySQL-里有-2000w-数据，Redis-中只存-20w-的数据，如何保证-Redis-中的数据都是热点数据？"><a href="#MySQL-里有-2000w-数据，Redis-中只存-20w-的数据，如何保证-Redis-中的数据都是热点数据？" class="headerlink" title="MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？"></a>MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？</h1><ul><li>Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</li></ul><h1 id="Redis-有哪些适合的场景？"><a href="#Redis-有哪些适合的场景？" class="headerlink" title="Redis 有哪些适合的场景？"></a>Redis 有哪些适合的场景？</h1><h4 id="会话缓存（Session-Cache）"><a href="#会话缓存（Session-Cache）" class="headerlink" title="会话缓存（Session Cache）"></a>会话缓存（Session Cache）</h4><ul><li>最常用的一种使用 Redis 的情景是会话缓存（session cache）</li><li>用 Redis 缓存会话比其他存储（如 Memcached）的优势在于：Redis 提供持久化</li><li>当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？</li><li>幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文档</li><li>甚至广为人知的商业平台 Magento 也提供 Redis 的插件。</li></ul><h4 id="全页缓存（FPC）"><a href="#全页缓存（FPC）" class="headerlink" title="全页缓存（FPC）"></a>全页缓存（FPC）</h4><ul><li>除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台</li><li>回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。</li><li>再次以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。</li><li>此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-Redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</li></ul><h4 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h4><ul><li>Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作</li><li>这使得 Redis 能作为一个很好的消息队列平台来使用</li><li>Redis 作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push&#x2F;pop 操作。</li><li>如果你快速的在 Google 中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用 Redis 创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用 Redis 作为 broker，你可以从这里去查看。</li></ul><h4 id="排行榜-计数器"><a href="#排行榜-计数器" class="headerlink" title="排行榜&#x2F;计数器"></a>排行榜&#x2F;计数器</h4><ul><li>Redis在内存中对数字进行递增或递减的操作实现的非常好</li><li>集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构</li><li>所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：</li><li>当然，这是假定你是根据你用户的分数做递增的排序</li><li>如果你想返回用户及用户的分数，你需要这样执行：ZRANGE user_scores 0 10 WITHSCORES</li><li>Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可以在这里看到。</li></ul><h4 id="发布-订阅"><a href="#发布-订阅" class="headerlink" title="发布&#x2F;订阅"></a>发布&#x2F;订阅</h4><ul><li>最后（但肯定不是最不重要的）是 Redis 的发布&#x2F;订阅功能</li><li>发布&#x2F;订阅的使用场景确实非常多</li><li>我已看见人们在社交网络连接中使用，还可作为基于发布&#x2F;订阅的脚本触发器，甚至用 Redis 的发布&#x2F;订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。</li></ul><h1 id="Redis-支持的-Java-客户端都有哪些？官方推荐用哪个？"><a href="#Redis-支持的-Java-客户端都有哪些？官方推荐用哪个？" class="headerlink" title="Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？"></a>Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？</h1><ul><li>Redisson、Jedis、lettuce 等等，官方推荐使用 Redisson。</li></ul><h1 id="Redis-和-Redisson-有什么关系？"><a href="#Redis-和-Redisson-有什么关系？" class="headerlink" title="Redis 和 Redisson 有什么关系？"></a>Redis 和 Redisson 有什么关系？</h1><ul><li>Redisson 是一个高级的分布式协调 Redis 客服端，能帮助用户在分布式环境中轻松实现一些 Java 的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish &#x2F; Subscribe, HyperLogLog)。</li></ul><h1 id="Jedis-与-Redisson-对比有什么优缺点？"><a href="#Jedis-与-Redisson-对比有什么优缺点？" class="headerlink" title="Jedis 与 Redisson 对比有什么优缺点？"></a>Jedis 与 Redisson 对比有什么优缺点？</h1><ul><li>Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持；</li><li>Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性</li><li>Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</li></ul><h1 id="Redis-如何设置密码及验证密码？"><a href="#Redis-如何设置密码及验证密码？" class="headerlink" title="Redis 如何设置密码及验证密码？"></a>Redis 如何设置密码及验证密码？</h1><ul><li>设置密码：config set requirepass 123456</li><li>授权密码：auth 123456</li></ul><h1 id="说说-Redis-哈希槽的概念？"><a href="#说说-Redis-哈希槽的概念？" class="headerlink" title="说说 Redis 哈希槽的概念？"></a>说说 Redis 哈希槽的概念？</h1><ul><li>Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念</li><li>Redis 集群有 16384 个哈希槽，</li><li>每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分hash 槽。</li></ul><h1 id="Redis-集群的主从复制模型是怎样的？"><a href="#Redis-集群的主从复制模型是怎样的？" class="headerlink" title="Redis 集群的主从复制模型是怎样的？"></a>Redis 集群的主从复制模型是怎样的？</h1><ul><li>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有 N-1 个复制品</li></ul><h1 id="Redis-集群会有写操作丢失吗？为什么？"><a href="#Redis-集群会有写操作丢失吗？为什么？" class="headerlink" title="Redis 集群会有写操作丢失吗？为什么？"></a>Redis 集群会有写操作丢失吗？为什么？</h1><ul><li>Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。</li></ul><h1 id="Redis-集群之间是如何复制的？"><a href="#Redis-集群之间是如何复制的？" class="headerlink" title="Redis 集群之间是如何复制的？"></a>Redis 集群之间是如何复制的？</h1><ul><li>异步复制</li></ul><h1 id="Redis-集群最大节点个数是多少？"><a href="#Redis-集群最大节点个数是多少？" class="headerlink" title="Redis 集群最大节点个数是多少？"></a>Redis 集群最大节点个数是多少？</h1><ul><li>16384 个。</li></ul><h1 id="Redis-集群如何选择数据库？"><a href="#Redis-集群如何选择数据库？" class="headerlink" title="Redis 集群如何选择数据库？"></a>Redis 集群如何选择数据库？</h1><ul><li>Redis 集群目前无法做数据库选择，默认在 0 数据库。</li></ul><h1 id="怎么测试-Redis-的连通性？"><a href="#怎么测试-Redis-的连通性？" class="headerlink" title="怎么测试 Redis 的连通性？"></a>怎么测试 Redis 的连通性？</h1><ul><li>ping</li></ul><h1 id="Redis-中的管道有什么用？"><a href="#Redis-中的管道有什么用？" class="headerlink" title="Redis 中的管道有什么用？"></a>Redis 中的管道有什么用？</h1><ul><li>一次请求&#x2F;响应服务器能实现处理新的请求即使旧的请求还未被响应</li><li>这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复</li><li>这就是管道（pipelining），是一种几十年来广泛使用的技术</li><li>例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。</li></ul><h1 id="怎么理解-Redis-事务？"><a href="#怎么理解-Redis-事务？" class="headerlink" title="怎么理解 Redis 事务？"></a>怎么理解 Redis 事务？</h1><ul><li>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行</li><li>事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li><li>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</li></ul><h1 id="Redis-事务相关的命令有哪几个？"><a href="#Redis-事务相关的命令有哪几个？" class="headerlink" title="Redis 事务相关的命令有哪几个？"></a>Redis 事务相关的命令有哪几个？</h1><ul><li>MULTI、EXEC、DISCARD、WATCH</li></ul><h1 id="Redis-key-的过期时间和永久有效分别怎么设置？"><a href="#Redis-key-的过期时间和永久有效分别怎么设置？" class="headerlink" title="Redis key 的过期时间和永久有效分别怎么设置？"></a>Redis key 的过期时间和永久有效分别怎么设置？</h1><ul><li>EXPIRE 和 PERSIST 命令。</li></ul><h1 id="Redis-如何做内存优化？"><a href="#Redis-如何做内存优化？" class="headerlink" title="Redis 如何做内存优化？"></a>Redis 如何做内存优化？</h1><ul><li>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小</li><li>所以你应该尽可能的将你的数据模型抽象到一个散列表里面</li><li>比如你的 web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key,而是应该把这个用户的所有信息存储到一张散列表里面</li></ul><h1 id="Redis-回收进程如何工作的？"><a href="#Redis-回收进程如何工作的？" class="headerlink" title="Redis 回收进程如何工作的？"></a>Redis 回收进程如何工作的？</h1><ul><li>一个客户端运行了新的命令，添加了新的数据。</li><li>Redi 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。</li><li>一个新的命令被执行，等等。</li><li>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。</li><li>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。</li></ul><h1 id="Redis-回收使用的是什么算法？"><a href="#Redis-回收使用的是什么算法？" class="headerlink" title="Redis 回收使用的是什么算法？"></a>Redis 回收使用的是什么算法？</h1><ul><li>LRU 算法</li></ul><h1 id="Redis-如何做大量数据插入？"><a href="#Redis-如何做大量数据插入？" class="headerlink" title="Redis 如何做大量数据插入？"></a>Redis 如何做大量数据插入？</h1><ul><li>Redis2.6 开始 Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工作。</li></ul><h1 id="为什么要做-Redis-分区？"><a href="#为什么要做-Redis-分区？" class="headerlink" title="为什么要做 Redis 分区？"></a>为什么要做 Redis 分区？</h1><ul><li>分区可以让 Redis 管理更大的内存，Redis 将可以使用所有机器的内存</li><li>如果没有分区，你最多只能使用一台机器的内存</li><li>分区使 Redis 的计算能力通过简单地增加计算机得到成倍提升</li><li>Redis 的网络带宽也会随着计算机和网卡的增加而成倍增长。</li></ul><h1 id="你知道有哪些-Redis-分区实现方案？"><a href="#你知道有哪些-Redis-分区实现方案？" class="headerlink" title="你知道有哪些 Redis 分区实现方案？"></a>你知道有哪些 Redis 分区实现方案？</h1><ul><li>客户端分区就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节点读取</li><li>大多数客户端已经实现了客户端分区。</li><li>代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。</li><li>代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。</li><li>Redis 和 memcached 的一种代理实现就是 Twemproxy</li><li>查询路由(Query routing) 的意思是客户端随机地请求任意一个 Redis 实例，然后由 Redis将请求转发给正确的 Redis 节点</li><li>Redis Cluster 实现了一种混合形式的查询路由，但并不是直接将请求从一个 Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接redirected 到正确的 Redis 节点。</li></ul><h1 id="Redis-分区有什么缺点？"><a href="#Redis-分区有什么缺点？" class="headerlink" title="Redis 分区有什么缺点？"></a>Redis 分区有什么缺点？</h1><ul><li>涉及多个 key 的操作通常不会被支持</li><li>例如你不能对两个集合求交集，因为他们可能被存储到不同的 Redis 实例（实际上这种情况也有办法，但是不能直接使用交集指令）。</li><li>同时操作多个 key,则不能使用 Redis 事务</li><li>分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning<br>granularity is the key, so it is not possible to shard a dataset with a single huge<br>key like a very big sorted set）</li><li>当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的 Redis 实例和主机同时收集 RDB &#x2F; AOF 文件。</li><li>分区时动态扩容或缩容可能非常复杂</li><li>Redis 集群在运行时增加或者删除 Redis 节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性</li><li>然而，有一种预分片的技术也可以较好的解决这个问题。</li></ul><h1 id="Redis-持久化数据和缓存怎么做扩容？"><a href="#Redis-持久化数据和缓存怎么做扩容？" class="headerlink" title="Redis 持久化数据和缓存怎么做扩容？"></a>Redis 持久化数据和缓存怎么做扩容？</h1><ul><li>如果 Redis 被当做缓存使用，使用一致性哈希实现动态扩容缩容。</li><li>如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关系，节点的数量一旦确定不能变化。否则的话(即 Redis 节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis 集群可以做到这样。</li></ul><h1 id="分布式-Redis-是前期做还是后期规模上来了再做好？为什么？"><a href="#分布式-Redis-是前期做还是后期规模上来了再做好？为什么？" class="headerlink" title="分布式 Redis 是前期做还是后期规模上来了再做好？为什么？"></a>分布式 Redis 是前期做还是后期规模上来了再做好？为什么？</h1><ul><li>既然 Redis 是如此的轻量（单实例只使用 1M 内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。- 即便你只有一台服务器，你也可以一开始就让 Redis 以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</li><li>一开始就多设置几个 Redis 实例，例如 32 或者 64 个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</li><li>这样的话，当你的数据不断增长，需要更多的 Redis 服务器时，你需要做的就是仅仅将 Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）</li><li>一旦你添加了另一台服务器，你需要将你一半的 Redis 实例从第一台机器迁移到第二台机器。</li></ul><h1 id="Twemproxy-是什么？"><a href="#Twemproxy-是什么？" class="headerlink" title="Twemproxy 是什么？"></a>Twemproxy 是什么？</h1><ul><li>Twemproxy 是 Twitter 维护的（缓存）代理系统，代理 Memcached 的 ASCII 协议和 Redis协议</li><li>它是单线程程序，使用 c 语言编写，运行起来非常快</li><li>它是采用 Apache 2.0 license的开源软件。</li><li>Twemproxy 支持自动分区，如果其代理的其中一个 Redis 节点不可用时，会自动将该节点排除（这将改变原来的 keys-instances 的映射关系，所以你应该仅在把 Redis 当缓存时使用 Twemproxy)。</li><li>Twemproxy 本身不存在单点问题，因为你可以启动多个 Twemproxy 实例，然后让你的客户端去连接任意一个 Twemproxy 实例。</li><li>Twemproxy 是 Redis 客户端和服务器端的一个中间层，由它来处理分区功能应该不算复杂，并且应该算比较可靠的。</li></ul><h1 id="支持一致性哈希的客户端有哪些？"><a href="#支持一致性哈希的客户端有哪些？" class="headerlink" title="支持一致性哈希的客户端有哪些？"></a>支持一致性哈希的客户端有哪些？</h1><ul><li>Redis-rb、PRedis 等。</li></ul><h1 id="Redis-与其他-key-value-存储有什么不同？"><a href="#Redis-与其他-key-value-存储有什么不同？" class="headerlink" title="Redis 与其他 key-value 存储有什么不同？"></a>Redis 与其他 key-value 存储有什么不同？</h1><ul><li>Redis 有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径</li><li>Redis 的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。</li><li>Redis 运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存</li><li>在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样 Redis 可以做很多内部复杂性很强的事情</li><li>同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问</li></ul><h1 id="Redis-的内存占用情况怎么样？"><a href="#Redis-的内存占用情况怎么样？" class="headerlink" title="Redis 的内存占用情况怎么样？"></a>Redis 的内存占用情况怎么样？</h1><ul><li>给你举个例子： 100 万个键值对（键是 0 到 999999 值是字符串“hello world”）在我的32 位的 Mac 笔记本上 用了 100MB</li><li>同样的数据放到一个 key 里只需要 16MB， 这是因为键值有一个很大的开销</li><li>在 Memcached 上执行也是类似的结果，但是相对 Redis的开销要小一点点，因为 Redis 会记录类型信息引用计数等等。</li><li>当然，大键值对时两者的比例要好很多。</li><li>64 位的系统比 32 位的需要更多的内存开销，尤其是键值对都较小时，这是因为 64 位的系统里指针占用了 8 个字节</li><li>但是，当然，64 位系统支持更大的内存，所以为了运行大型的 Redis 服务器或多或少的需要使用 64 位的系统。</li></ul><h1 id="都有哪些办法可以降低-Redis-的内存使用情况呢？"><a href="#都有哪些办法可以降低-Redis-的内存使用情况呢？" class="headerlink" title="都有哪些办法可以降低 Redis 的内存使用情况呢？"></a>都有哪些办法可以降低 Redis 的内存使用情况呢？</h1><ul><li>如果你使用的是 32 位的 Redis 实例，可以好好利用 Hash,list,sorted set,set 等集合类型数据，</li><li>因为通常情况下很多小的 Key-Value 可以用更紧凑的方式存放到一起。</li></ul><h1 id="查看-Redis-使用情况及状态信息用什么命令？"><a href="#查看-Redis-使用情况及状态信息用什么命令？" class="headerlink" title="查看 Redis 使用情况及状态信息用什么命令？"></a>查看 Redis 使用情况及状态信息用什么命令？</h1><ul><li>info</li></ul><h1 id="Redis-的内存用完了会发生什么？"><a href="#Redis-的内存用完了会发生什么？" class="headerlink" title="Redis 的内存用完了会发生什么？"></a>Redis 的内存用完了会发生什么？</h1><ul><li>如果达到设置的上限，Redis 的写命令会返回错误信息（但是读命令还可以正常返回。）</li><li>或者你可以将 Redis 当缓存来使用配置淘汰机制，当 Redis 达到内存上限时会冲刷掉旧的内容。</li></ul><h1 id="Redis-是单线程的，如何提高多核-CPU-的利用率？"><a href="#Redis-是单线程的，如何提高多核-CPU-的利用率？" class="headerlink" title="Redis 是单线程的，如何提高多核 CPU 的利用率？"></a>Redis 是单线程的，如何提高多核 CPU 的利用率？</h1><ul><li>可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的，</li><li>所以，如果你想使用多个 CPU，你可以考虑一下分片（shard）。</li></ul><h1 id="一个-Redis-实例最多能存放多少的-keys？List、Set、Sorted-Set-他们最多能存放多少元素？"><a href="#一个-Redis-实例最多能存放多少的-keys？List、Set、Sorted-Set-他们最多能存放多少元素？" class="headerlink" title="一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？"></a>一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？</h1><ul><li>理论上 Redis 可以处理多达 232 的 keys，并且在实际中进行了测试，每个实例至少存放了 2亿 5 千万的 keys</li><li>任何 list、set、和 sorted set 都可以放 232 个元素。</li><li>换句话说，Redis 的存储极限是系统中的可用内存值。</li></ul><h1 id="Redis-常见性能问题和解决方案？"><a href="#Redis-常见性能问题和解决方案？" class="headerlink" title="Redis 常见性能问题和解决方案？"></a>Redis 常见性能问题和解决方案？</h1><ul><li>Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件</li><li>如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次</li><li>为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网内</li><li>尽量避免在压力很大的主库上增加从库</li><li>主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2<br>&lt;- Slave3… 这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可<br>以立刻启用 Slave1 做 Master，其他不变。</li></ul><h1 id="如何选择合适的持久化方式？"><a href="#如何选择合适的持久化方式？" class="headerlink" title="如何选择合适的持久化方式？"></a>如何选择合适的持久化方式？</h1><ul><li>一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能</li><li>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。</li><li>有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug。</li></ul><h1 id="修改配置不重启-Redis-会实时生效吗？"><a href="#修改配置不重启-Redis-会实时生效吗？" class="headerlink" title="修改配置不重启 Redis 会实时生效吗？"></a>修改配置不重启 Redis 会实时生效吗？</h1><ul><li>针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启</li><li>从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis</li><li>检索 ‘CONFIG GET *’ 命令获取更多信息。</li><li>但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前CONFIG 命令还不支持的配置参数的时候。</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/b9efb3c36627.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/b9efb3c36627.html" class="post-title-link" itemprop="url">Dubbo</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:22:55" itemprop="dateCreated datePublished" datetime="2023-12-20T16:22:55+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-28 12:34:57" itemprop="dateModified" datetime="2023-12-28T12:34:57+08:00">2023-12-28</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>9.3k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>8 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="Dubbo是什么？"><a href="#Dubbo是什么？" class="headerlink" title="Dubbo是什么？"></a>Dubbo是什么？</h1><ul><li>Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案</li><li>简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的东东，说白了就是个远程服务调用的分布式框架（告别Web Service模式中的WSdl，以服务者与消费者的方式在dubbo上注册）</li><li>其核心部分包含:<ul><li>远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。</li><li>集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li><li>自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li></ul></li></ul><h1 id="Dubbo能做什么？"><a href="#Dubbo能做什么？" class="headerlink" title="Dubbo能做什么？"></a>Dubbo能做什么？</h1><ul><li>透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。</li><li>软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。</li><li>服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。</li><li>Dubbo采用全spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。</li><li>之前使用Web Service，我想测试接口可以通过模拟消息的方式通过soapui或LR进行功能测试或性能测试。但现在使用Dubbo，接口之间不能直接交互，我尝试通过模拟消费者地址测试，结果不堪入目，再而使用jmeter通过junit进行测试，但还是需要往dubbo上去注册，如果再不给提供源代码的前提下，这个测试用例不好写啊….</li></ul><h1 id="dubbo的架构"><a href="#dubbo的架构" class="headerlink" title="dubbo的架构"></a>dubbo的架构</h1><ul><li>Provider: 暴露服务的服务提供方。</li><li>Consumer: 调用远程服务的服务消费方。</li><li>Registry: 服务注册与发现的注册中心。</li><li>Monitor: 统计服务的调用次调和调用时间的监控中心。</li><li>Container: 服务运行容器。</li><li>这点我觉得非常好，角色分明，可以根据每个节点角色的状态来确定该服务是否正常。</li><li>调用关系说明：<ul><li>服务容器负责启动，加载，运行服务提供者。</li><li>服务提供者在启动时，向注册中心注册自己提供的服务。</li><li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li><li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li><li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li></ul></li></ul><h1 id="Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么"><a href="#Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么" class="headerlink" title="Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么"></a>Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么</h1><ul><li>可以通信的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用；</li><li>注册中心对等集群，任意一台宕机后，将会切换到另一台；注册中心全部宕机后，服务的提供者和消费者仍能通过本地缓存通讯。服务提供者无状态，任一台 宕机后，不影响使用；服务提供者全部宕机，服务消费者会无法使用，并无限次重连等待服务者恢复；</li><li>挂掉是不要紧的，但前提是你没有增加新的服务，如果你要调用新的服务，则是不能办到的。</li></ul><h1 id="dubbo服务负载均衡策略"><a href="#dubbo服务负载均衡策略" class="headerlink" title="dubbo服务负载均衡策略"></a>dubbo服务负载均衡策略</h1><ul><li>随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。(权重可以在dubbo管控台配置)</li><li>轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</li><li>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</li><li>一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。缺省只对第一个参数Hash，如果要修改，请配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt;</span><br></pre></td></tr></table></figure></li></ul><p>缺省用160份虚拟节点，如果要修改，请配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt;</span><br></pre></td></tr></table></figure><h1 id="Dubbo在安全机制方面是如何解决的"><a href="#Dubbo在安全机制方面是如何解决的" class="headerlink" title="Dubbo在安全机制方面是如何解决的"></a>Dubbo在安全机制方面是如何解决的</h1><ul><li>Dubbo通过Token令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。Dubbo还提供服务黑白名单，来控制服务所允许的调用方。</li></ul><h1 id="dubbo连接注册中心和直连的区别"><a href="#dubbo连接注册中心和直连的区别" class="headerlink" title="dubbo连接注册中心和直连的区别"></a>dubbo连接注册中心和直连的区别</h1><ul><li>在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，<br>点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表，</li><li>服务注册中心，动态的注册和发现服务，使服务的位置透明，并通过在消费方获取服务提供方地址列表，实现软负载均衡和Failover， 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外，注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者</li><li>注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表</li><li>注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。</li></ul><h1 id="dubbo服务集群配置（集群容错模式）"><a href="#dubbo服务集群配置（集群容错模式）" class="headerlink" title="dubbo服务集群配置（集群容错模式）"></a>dubbo服务集群配置（集群容错模式）</h1><ul><li>在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。可以自行扩展集群容错策略</li></ul><h4 id="Failover-Cluster-默认"><a href="#Failover-Cluster-默认" class="headerlink" title="Failover Cluster(默认)"></a>Failover Cluster(默认)</h4><ul><li>失败自动切换，当出现失败，重试其它服务器。(缺省)通常用于读操作，但重试会带来更长延迟。可通过retries&#x3D;”2”来设置重试次数(不含第一次)。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:service retries=&quot;2&quot; cluster=&quot;failover&quot;/&gt;</span><br><span class="line">         或：</span><br><span class="line">         &lt;dubbo:reference retries=&quot;2&quot; cluster=&quot;failover&quot;/&gt;</span><br><span class="line">         cluster=&quot;failover&quot;可以不用写,因为默认就是failover</span><br></pre></td></tr></table></figure></li></ul><h4 id="Failfast-Cluster"><a href="#Failfast-Cluster" class="headerlink" title="Failfast Cluster"></a>Failfast Cluster</h4><ul><li>快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dubbo:service cluster=&quot;failfast&quot; /&gt;</span><br><span class="line">         或：</span><br><span class="line">         &lt;dubbo:reference cluster=&quot;failfast&quot; /&gt;</span><br><span class="line">    cluster=&quot;failfast&quot;和 把cluster=&quot;failover&quot;、retries=&quot;0&quot;是一样的效果,retries=&quot;0&quot;就是不重试</span><br></pre></td></tr></table></figure></li></ul><h4 id="Failsafe-Cluster"><a href="#Failsafe-Cluster" class="headerlink" title="Failsafe Cluster"></a>Failsafe Cluster</h4><ul><li>失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;</span><br><span class="line">         或：</span><br><span class="line">         &lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Failback-Cluster"><a href="#Failback-Cluster" class="headerlink" title="Failback Cluster"></a>Failback Cluster</h4><ul><li>失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:service cluster=&quot;failback&quot; /&gt;</span><br><span class="line">         或：</span><br><span class="line">         &lt;dubbo:reference cluster=&quot;failback&quot; /&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Forking-Cluster"><a href="#Forking-Cluster" class="headerlink" title="Forking Cluster"></a>Forking Cluster</h4><ul><li>并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过forks&#x3D;”2”来设置最大并行数。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;dubbo:service cluster=“forking&quot; forks=&quot;2&quot;/&gt;</span><br><span class="line">         或：</span><br><span class="line">         &lt;dubbo:reference cluster=“forking&quot; forks=&quot;2&quot;/&gt;</span><br><span class="line">服务端服务级别</span><br><span class="line">　　　　&lt;dubbo:service interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;</span><br><span class="line">　　客户端服务级别</span><br><span class="line">　　　　&lt;dubbo:reference interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;</span><br><span class="line">　　服务端方法级别　　　&lt;dubbo:service interface=&quot;...&quot;&gt; &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt; &lt;/dubbo:service&gt;</span><br><span class="line">客户端方法级别　        &lt;dubbo:reference interface=&quot;...&quot;&gt; &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt; &lt;/dubbo:reference&gt;</span><br></pre></td></tr></table></figure></li></ul><h1 id="dubbo通信协议dubbo协议为什么要消费者比提供者个数多："><a href="#dubbo通信协议dubbo协议为什么要消费者比提供者个数多：" class="headerlink" title="dubbo通信协议dubbo协议为什么要消费者比提供者个数多："></a>dubbo通信协议dubbo协议为什么要消费者比提供者个数多：</h1><ul><li>因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit&#x3D;128MByte)，根据测试经验数据每条连接最多只能压满7MByte(不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。</li></ul><h1 id="dubbo通信协议dubbo协议为什么不能传大包"><a href="#dubbo通信协议dubbo协议为什么不能传大包" class="headerlink" title="dubbo通信协议dubbo协议为什么不能传大包"></a>dubbo通信协议dubbo协议为什么不能传大包</h1><ul><li>因dubbo协议采用单一长连接，</li><li>如果每次请求的数据包大小为500KByte，假设网络为千兆网卡(1024Mbit&#x3D;128MByte)，每条连接最大7MByte(不同的环境可能不一样，供参考)，</li><li>单个服务提供者的TPS(每秒处理事务数)最大为：128MByte &#x2F; 500KByte &#x3D; 262。</li><li>单个消费者调用单个服务提供者的TPS(每秒处理事务数)最大为：7MByte &#x2F; 500KByte &#x3D; 14。</li><li>如果能接受，可以考虑使用，否则网络将成为瓶颈。</li></ul><h1 id="dubbo通信协议dubbo协议为什么采用异步单一长连接"><a href="#dubbo通信协议dubbo协议为什么采用异步单一长连接" class="headerlink" title="dubbo通信协议dubbo协议为什么采用异步单一长连接"></a>dubbo通信协议dubbo协议为什么采用异步单一长连接</h1><ul><li>因为服务的现状大都是服务提供者少，通常只有几台机器，</li><li>而服务的消费者多，可能整个网站都在访问该服务，</li><li>比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，</li><li>如果采用常规的hessian服务，服务提供者很容易就被压跨，</li><li>通过单一连接，保证单一消费者不会压死提供者，</li><li>长连接，减少连接握手验证等，</li><li>并使用异步IO，复用线程池，防止C10K问题。</li></ul><h1 id="dubbo通信协议dubbo协议适用范围和适用场景"><a href="#dubbo通信协议dubbo协议适用范围和适用场景" class="headerlink" title="dubbo通信协议dubbo协议适用范围和适用场景"></a>dubbo通信协议dubbo协议适用范围和适用场景</h1><ul><li>适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。</li><li>适用场景：常规远程服务方法调用</li><li>dubbo协议补充：<ul><li>连接个数：单连接</li><li>连接方式：长连接</li><li>传输协议：TCP</li><li>传输方式：NIO异步传输</li><li>序列化：Hessian二进制序列化</li></ul></li></ul><h1 id="RMI协议"><a href="#RMI协议" class="headerlink" title="RMI协议"></a>RMI协议</h1><ul><li>RMI协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式，Java标准的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：TCP</li><li>传输方式：同步传输</li><li>序列化：Java标准二进制序列化</li><li>适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。</li><li>适用场景：常规远程服务方法调用，与原生RMI服务互操作</li></ul><h1 id="Hessian协议"><a href="#Hessian协议" class="headerlink" title="Hessian协议"></a>Hessian协议</h1><ul><li>Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现</li><li>基于Hessian的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：Hessian二进制序列化</li><li>适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。</li><li>适用场景：页面传输，文件传输，或与原生hessian服务互操作</li></ul><h1 id="http"><a href="#http" class="headerlink" title="http"></a>http</h1><ul><li>采用Spring的HttpInvoker实现</li><li>基于http表单的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：表单序列化（JSON）</li><li>适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。</li><li>适用场景：需同时给应用程序和浏览器JS使用的服务。</li></ul><h1 id="Webservice"><a href="#Webservice" class="headerlink" title="Webservice"></a>Webservice</h1><ul><li>基于CXF的frontend-simple和transports-http实现</li><li>基于WebService的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：SOAP文本序列化</li><li>适用场景：系统集成，跨语言调用。</li></ul><h1 id="Thrif"><a href="#Thrif" class="headerlink" title="Thrif"></a>Thrif</h1><ul><li>Thrift是Facebook捐给Apache的一个RPC框架，当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如service name，magic number等</li></ul><h1 id="为什么要⽤Dubbo？"><a href="#为什么要⽤Dubbo？" class="headerlink" title="为什么要⽤Dubbo？"></a>为什么要⽤Dubbo？</h1><ul><li>因为是阿⾥开源项⽬，国内很多互联⽹公司都在⽤，已经经过很多线上考验。</li><li>内部使⽤了 Netty、Zookeeper，保证了⾼性能⾼可⽤性。</li><li>使⽤ Dubbo 可以将核⼼业务抽取出来，作为独⽴的服务，逐渐形成稳定的服务中⼼，可⽤于提⾼业务复⽤灵活扩展，使前端应⽤能更快速的响应多变的市场需求。</li><li>最重要的⼀点是，分布式架构可以承受更⼤规模的并发流量。</li></ul><h1 id="Dubbo-和-Spring-Cloud-有什么区别？"><a href="#Dubbo-和-Spring-Cloud-有什么区别？" class="headerlink" title="Dubbo 和 Spring Cloud 有什么区别？"></a>Dubbo 和 Spring Cloud 有什么区别？</h1><ul><li>两个没关联，如果硬要说区别，有以下⼏点。<ul><li><p>通信⽅式不同</p><ul><li>Dubbo 使⽤的是 RPC 通信，⽽ Spring Cloud 使⽤的是 HTTP RESTFul ⽅式。</li><li>dubbo由于是⼆进制的传输，占⽤带宽会更少（基于netty等）；springCloud是http协议传输，带宽会⽐较多，同时使⽤http协议（http+restful api）⼀般会使⽤JSON报⽂，消耗会更⼤。</li></ul></li><li><p>dubbo的开发难度较⼤，原因是dubbo的jar包依赖（存在代码级别的强依赖）问题很多⼤型⼯程⽆法解决；</p></li><li><p>springcloud的接⼝协议约定⽐较⾃由且松散，需要有强有⼒的⾏政措施来限制接⼝⽆序升级。</p></li><li><p>dubbo的改进是通过dubbofilter，很多东⻄没有，需要⾃⼰继承，如监控，如⽇志，如限流，如追踪。</p></li><li><p>springcloud具有配置管理、服务发现、断路器、智能路由、微代理、控制总线、⼀次性token、全局锁、选主、分布式会话和集群状态等，满⾜了构建微服务所需的所有解决⽅案。</p></li><li><p>组成部分不同</p></li></ul></li></ul><h1 id="dubbo都⽀持什么协议，推荐⽤哪种？"><a href="#dubbo都⽀持什么协议，推荐⽤哪种？" class="headerlink" title="dubbo都⽀持什么协议，推荐⽤哪种？"></a>dubbo都⽀持什么协议，推荐⽤哪种？</h1><ul><li>dubbo:&#x2F;&#x2F;（推荐）</li><li>rmi:&#x2F;&#x2F;</li><li>hessian:&#x2F;&#x2F;</li><li>http:&#x2F;&#x2F;</li><li>webservice:&#x2F;&#x2F;</li><li>thrift:&#x2F;&#x2F;</li><li>memcached:&#x2F;&#x2F;</li><li>redis:&#x2F;&#x2F;</li><li>rest:&#x2F;&#x2F;</li></ul><h1 id="Dubbo需要-Web-容器吗？"><a href="#Dubbo需要-Web-容器吗？" class="headerlink" title="Dubbo需要 Web 容器吗？"></a>Dubbo需要 Web 容器吗？</h1><ul><li>不需要，如果硬要⽤ Web 容器，只会增加复杂性，也浪费资源。</li></ul><h1 id="Dubbo内置了哪⼏种服务容器？"><a href="#Dubbo内置了哪⼏种服务容器？" class="headerlink" title="Dubbo内置了哪⼏种服务容器？"></a>Dubbo内置了哪⼏种服务容器？</h1><ul><li>Spring Container</li><li>Jetty Container</li><li>Log4j Container</li><li>Dubbo 的服务容器只是⼀个简单的 Main ⽅法，并加载⼀个简单的 Spring 容器，⽤于暴露服务。</li></ul><h1 id="Dubbo默认使⽤什么注册中⼼，还有别的选择吗？"><a href="#Dubbo默认使⽤什么注册中⼼，还有别的选择吗？" class="headerlink" title="Dubbo默认使⽤什么注册中⼼，还有别的选择吗？"></a>Dubbo默认使⽤什么注册中⼼，还有别的选择吗？</h1><ul><li>推荐使⽤ Zookeeper 作为注册中⼼，还有 Redis、Multicast、Simple 注册中⼼，但不推荐。</li><li>redis⽅案需要服务器时间同步，且性能消耗过⼤。</li></ul><h1 id="Dubbo有哪⼏种配置⽅式？"><a href="#Dubbo有哪⼏种配置⽅式？" class="headerlink" title="Dubbo有哪⼏种配置⽅式？"></a>Dubbo有哪⼏种配置⽅式？</h1><ul><li>Spring 配置⽅式</li><li>Java API 配置⽅式</li></ul><h1 id="在-Provider-上可以配置的-Consumer-端的属性有哪些？"><a href="#在-Provider-上可以配置的-Consumer-端的属性有哪些？" class="headerlink" title="在 Provider 上可以配置的 Consumer 端的属性有哪些？"></a>在 Provider 上可以配置的 Consumer 端的属性有哪些？</h1><ul><li>timeout：⽅法调⽤超时</li><li>retries：失败重试次数，默认重试 2 次</li><li>loadbalance：负载均衡算法，默认随机</li><li>actives 消费者端，最⼤并发调⽤限制</li></ul><h1 id="Dubbo启动时如果依赖的服务不可⽤会怎样？"><a href="#Dubbo启动时如果依赖的服务不可⽤会怎样？" class="headerlink" title="Dubbo启动时如果依赖的服务不可⽤会怎样？"></a>Dubbo启动时如果依赖的服务不可⽤会怎样？</h1><ul><li>Dubbo 缺省会在启动时检查依赖的服务是否可⽤，不可⽤时会抛出异常，阻⽌ Spring 初始化完成，默认 check&#x3D;”true”，可以通过 check&#x3D;”false” 关闭检查。</li></ul><h1 id="Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？"><a href="#Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？" class="headerlink" title="Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？"></a>Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？</h1><ul><li>推荐使⽤Hessian序列化，还有Duddo、FastJson、Java⾃带序列化。</li></ul><h1 id="Dubbo默认使⽤的是什么通信框架，还有别的选择吗？"><a href="#Dubbo默认使⽤的是什么通信框架，还有别的选择吗？" class="headerlink" title="Dubbo默认使⽤的是什么通信框架，还有别的选择吗？"></a>Dubbo默认使⽤的是什么通信框架，还有别的选择吗？</h1><ul><li>Dubbo 默认使⽤ Netty 框架，也是推荐的选择，另外内容还集成有Mina、Grizzly。</li></ul><h1 id="注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？"><a href="#注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？" class="headerlink" title="注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？"></a>注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？</h1><ul><li>可以配置环境点对点直连，绕过注册中⼼，将以服务接⼝为单位，忽略注册中⼼的提供者列表。</li></ul><h1 id="Dubbo⽀持服务多协议吗？"><a href="#Dubbo⽀持服务多协议吗？" class="headerlink" title="Dubbo⽀持服务多协议吗？"></a>Dubbo⽀持服务多协议吗？</h1><ul><li>Dubbo 允许配置多协议，在不同服务上⽀持不同协议或者同⼀服务上同时⽀持多种协议。</li></ul><h1 id="当⼀个服务接⼝有多种实现时怎么做？"><a href="#当⼀个服务接⼝有多种实现时怎么做？" class="headerlink" title="当⼀个服务接⼝有多种实现时怎么做？"></a>当⼀个服务接⼝有多种实现时怎么做？</h1><ul><li>当⼀个接⼝有多种实现时，可以⽤ group 属性来分组，服务提供⽅和消费⽅都指定同⼀个 group 即可。</li></ul><h1 id="服务上线怎么兼容旧版本？"><a href="#服务上线怎么兼容旧版本？" class="headerlink" title="服务上线怎么兼容旧版本？"></a>服务上线怎么兼容旧版本？</h1><ul><li>可以⽤版本号（version）过渡，多个不同版本的服务注册到注册中⼼，版本号不同的服务相互间不引⽤。这个和服务分组的概念有⼀点类似。</li></ul><h1 id="Dubbo可以对结果进⾏缓存吗？"><a href="#Dubbo可以对结果进⾏缓存吗？" class="headerlink" title="Dubbo可以对结果进⾏缓存吗？"></a>Dubbo可以对结果进⾏缓存吗？</h1><ul><li>可以，Dubbo 提供了声明式缓存，⽤于加速热⻔数据的访问速度，以减少⽤户加缓存的⼯作量。</li></ul><h1 id="Dubbo服务之间的调⽤是阻塞的吗？"><a href="#Dubbo服务之间的调⽤是阻塞的吗？" class="headerlink" title="Dubbo服务之间的调⽤是阻塞的吗？"></a>Dubbo服务之间的调⽤是阻塞的吗？</h1><ul><li>默认是同步等待结果阻塞的，⽀持异步调⽤。</li><li>Dubbo 是基于 NIO 的⾮阻塞实现并⾏调⽤，客户端不需要启动多线程即可完成并⾏调⽤多个远程服务，相对多线程开销较⼩，异步调⽤会返回⼀个 Future 对象。</li></ul><h1 id="Dubbo⽀持分布式事务吗？"><a href="#Dubbo⽀持分布式事务吗？" class="headerlink" title="Dubbo⽀持分布式事务吗？"></a>Dubbo⽀持分布式事务吗？</h1><ul><li>⽬前暂时不⽀持，后续可能采⽤基于 JTA&#x2F;XA 规范实现，如以图所示。</li></ul><h1 id="Dubbo-telnet-命令能做什么？"><a href="#Dubbo-telnet-命令能做什么？" class="headerlink" title="Dubbo telnet 命令能做什么？"></a>Dubbo telnet 命令能做什么？</h1><ul><li>dubbo 通过 telnet 命令来进⾏服务治理</li><li>telnet localhost 8090</li></ul><h1 id="Dubbo⽀持服务降级吗？"><a href="#Dubbo⽀持服务降级吗？" class="headerlink" title="Dubbo⽀持服务降级吗？"></a>Dubbo⽀持服务降级吗？</h1><ul><li>Dubbo 2.2.0 以上版本⽀持。</li></ul><h1 id="Dubbo如何优雅停机？"><a href="#Dubbo如何优雅停机？" class="headerlink" title="Dubbo如何优雅停机？"></a>Dubbo如何优雅停机？</h1><ul><li>Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果使⽤ kill -9 PID 等强制关闭指令，是不会执⾏优雅停机的，只有通过 kill PID 时，才会执⾏。</li></ul><h1 id="服务提供者能实现失效踢出是什么原理？"><a href="#服务提供者能实现失效踢出是什么原理？" class="headerlink" title="服务提供者能实现失效踢出是什么原理？"></a>服务提供者能实现失效踢出是什么原理？</h1><ul><li>服务失效踢出基于 Zookeeper 的临时节点原理。 （服务机器会在zk上注册⼀个临时节点，服务失效则临时节点被删除）</li></ul><h1 id="如何解决服务调⽤链过⻓的问题？"><a href="#如何解决服务调⽤链过⻓的问题？" class="headerlink" title="如何解决服务调⽤链过⻓的问题？"></a>如何解决服务调⽤链过⻓的问题？</h1><ul><li>Dubbo 可以使⽤ Pinpoint 和 Apache Skywalking(Incubator) 实现分布式服务追踪，当然还有其他很多⽅案。</li></ul><h1 id="服务读写推荐的容错策略是怎样的？"><a href="#服务读写推荐的容错策略是怎样的？" class="headerlink" title="服务读写推荐的容错策略是怎样的？"></a>服务读写推荐的容错策略是怎样的？</h1><ul><li>读操作建议使⽤ Failover 失败⾃动切换，默认重试两次其他服务器。</li><li>写操作建议使⽤ Failfast 快速失败，发⼀次调⽤失败就⽴即报错。</li></ul><h1 id="Dubbo必须依赖的包有哪些？"><a href="#Dubbo必须依赖的包有哪些？" class="headerlink" title="Dubbo必须依赖的包有哪些？"></a>Dubbo必须依赖的包有哪些？</h1><ul><li>Dubbo 必须依赖 JDK，其他为可选。</li></ul><h1 id="Dubbo的管理控制台能做什么？"><a href="#Dubbo的管理控制台能做什么？" class="headerlink" title="Dubbo的管理控制台能做什么？"></a>Dubbo的管理控制台能做什么？</h1><ul><li>管理控制台主要包含：路由规则，动态配置，服务降级，访问控制，权重调整，负载均衡，等管理功能。</li></ul><h1 id="说说-Dubbo-服务暴露的过程。"><a href="#说说-Dubbo-服务暴露的过程。" class="headerlink" title="说说 Dubbo 服务暴露的过程。"></a>说说 Dubbo 服务暴露的过程。</h1><ul><li>Dubbo 会在 Spring 实例化完 bean 之后，</li><li>在刷新容器最后⼀步发布 ContextRefreshEvent 事件的时候，</li><li>通知实现了ApplicationListener 的 ServiceBean 类进⾏回调 onApplicationEvent 事件⽅法，</li><li>Dubbo 会在这个⽅法中调⽤ ServiceBean ⽗类ServiceConfig 的 export ⽅法，</li><li>⽽该⽅法真正实现了服务的（异步或者⾮异步）发布。</li></ul><h1 id="Dubbo-停⽌维护了吗？"><a href="#Dubbo-停⽌维护了吗？" class="headerlink" title="Dubbo 停⽌维护了吗？"></a>Dubbo 停⽌维护了吗？</h1><ul><li>2014 年开始停⽌维护过⼏年，17 年开始重新维护，并进⼊了 Apache 项⽬。</li></ul><h1 id="Dubbo-和-Dubbox-有什么区别？"><a href="#Dubbo-和-Dubbox-有什么区别？" class="headerlink" title="Dubbo 和 Dubbox 有什么区别？"></a>Dubbo 和 Dubbox 有什么区别？</h1><ul><li>Dubbox 是继 Dubbo 停⽌维护后，当当⽹基于 Dubbo 做的⼀个扩展项⽬，如加了服务可 Restful 调⽤，更新了开源组件等。</li></ul><h1 id="你还了解别的分布式框架吗？"><a href="#你还了解别的分布式框架吗？" class="headerlink" title="你还了解别的分布式框架吗？"></a>你还了解别的分布式框架吗？</h1><ul><li>别的还有 Spring cloud、Facebook 的 Thrift、Twitter 的 Finagle 等。</li></ul><h1 id="Dubbo-能集成-Spring-Boot-吗？"><a href="#Dubbo-能集成-Spring-Boot-吗？" class="headerlink" title="Dubbo 能集成 Spring Boot 吗？"></a>Dubbo 能集成 Spring Boot 吗？</h1><ul><li>可以的，项⽬地址如下。</li><li><a target="_blank" rel="noopener" href="https://github.com/apache/incubator-dubbo-spring-boot-project">https://github.com/apache/incubator-dubbo-spring-boot-project</a></li></ul><h1 id="在使⽤过程中都遇到了些什么问题？"><a href="#在使⽤过程中都遇到了些什么问题？" class="headerlink" title="在使⽤过程中都遇到了些什么问题？"></a>在使⽤过程中都遇到了些什么问题？</h1><ul><li>单⼀⻓连接和NIO异步通讯，适合⼤并发⼩数据量的服务调⽤，以及消费者远⼤于提供者。Dubbo 的设计⽬的是为了满⾜⾼并发⼩数据量的 rpc 调⽤，在⼤数据量下的性能表现并不好，建议使⽤ rmi 或 http 协议。</li></ul><h1 id="你觉得⽤-Dubbo-好还是-Spring-Cloud-好？"><a href="#你觉得⽤-Dubbo-好还是-Spring-Cloud-好？" class="headerlink" title="你觉得⽤ Dubbo 好还是 Spring Cloud 好？"></a>你觉得⽤ Dubbo 好还是 Spring Cloud 好？</h1><ul><li>扩展性的问题，没有好坏，只有适合不适合，不过我好像更倾向于使⽤ Dubbo, Spring Cloud 版本升级太快，组件更新替换太频繁，配置太繁琐，还有很多我觉得是没有 Dubbo 顺⼿的地⽅……</li></ul><h1 id="Dubbo-是什么"><a href="#Dubbo-是什么" class="headerlink" title="Dubbo 是什么"></a>Dubbo 是什么</h1><ul><li>Dubbo 是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。</li><li>主要核心部件：<ul><li>Remoting: 网络通信框架，实现了 sync-over-async 和 request-response 消息机制. RPC: 一个远程过程调用的抽象，支持负载均衡、容灾和集群功能</li><li>Registry: 服务目录框架用于服务的注册和服务事件发布和订阅</li><li>Dubbo服务集群-集群容错模式</li><li>Dubbo 服务提供者集群与负载均衡</li></ul></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/dffc02696193.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/dffc02696193.html" class="post-title-link" itemprop="url">MySQL</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:21:32" itemprop="dateCreated datePublished" datetime="2023-12-20T16:21:32+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-26 21:21:54" itemprop="dateModified" datetime="2023-12-26T21:21:54+08:00">2023-12-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.3k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="不可重复读和幻读到底有什么区别呢？"><a href="#不可重复读和幻读到底有什么区别呢？" class="headerlink" title="不可重复读和幻读到底有什么区别呢？"></a>不可重复读和幻读到底有什么区别呢？</h1><ul><li>不可重复读是读取了其他事务更改的数据，针对update操作</li><li>解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。</li><li>幻读是读取了其他事务新增的数据，针对insert操作</li><li>解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。</li></ul><h1 id="MySQL千万级的大表要怎么优化"><a href="#MySQL千万级的大表要怎么优化" class="headerlink" title="MySQL千万级的大表要怎么优化"></a>MySQL千万级的大表要怎么优化</h1><ul><li>读写分离、水平拆分、垂直拆分</li><li>如何设计或优化千万级别的大表？此外无其他信息，个人觉得这个话题有点范，就只好简单说下该如何做，对于一个存储设计，必须考虑业务特点，收集的信息如下：<ul><li>数据的容量：1-3年内会大概多少条数据，每条数据大概多少字节；</li><li>数据项：是否有大字段，那些字段的值是否经常被更新；</li><li>数据查询SQL条件：哪些数据项的列名称经常出现在WHERE、GROUP BY、ORDER BY子句中等；</li><li>数据更新类SQL条件：有多少列经常出现UPDATE或DELETE 的WHERE子句中；</li><li>SQL量的统计比，如：SELECT：UPDATE+DELETE：INSERT&#x3D;多少？</li><li>预计大表及相关联的SQL，每天总的执行量在何数量级？</li><li>表中的数据：更新为主的业务 还是 查询为主的业务 ？</li><li>打算采用什么数据库物理服务器，以及数据库服务器架构？</li><li>并发如何？</li><li>存储引擎选择InnoDB还是MyISAM？</li></ul></li><li>大致明白以上10个问题，至于如何设计此类的大表，应该什么都清楚了！</li><li>至于优化若是指创建好的表，不能变动表结构的话，那建议InnoDB引擎，多利用点内存，减轻磁盘IO负载，因为IO往往是数据库服务器的瓶颈</li><li>另外对优化索引结构去解决性能问题的话，建议优先考虑修改类SQL语句，使他们更快些，不得已只靠索引组织结构的方式，当然此话前提是， 索引已经创建的非常好，若是读为主，可以考虑打开query_cache，以及调整一些参数值：sort_buffer_size,read_buffer_size,read_rnd_buffer_size,join_buffer_size</li><li>以及调整一些参数值：sort_buffer_size,read_buffer_size,read_rnd_buffer_size,join_buffer_size</li></ul><h1 id="union和union-all有什么不同"><a href="#union和union-all有什么不同" class="headerlink" title="union和union all有什么不同?"></a>union和union all有什么不同?</h1><ul><li>Union和Union All的区别之一在于对重复结果的处理。</li><li>UNION在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION</li><li>而UNION ALL只是简单的将两个结果合并后就返回。这样，如果返回的两个结果集中有重复的数据，那么返回的结果集就会包含重复的数据了。</li><li>从效率上说，UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复的数据的话，那么就使用UNION ALL，</li></ul><h1 id="oracle中除了数据库备份，还有什么方法备份？"><a href="#oracle中除了数据库备份，还有什么方法备份？" class="headerlink" title="oracle中除了数据库备份，还有什么方法备份？"></a>oracle中除了数据库备份，还有什么方法备份？</h1><ul><li>Oracle数据库有三种标准的备份方法，它们分别是导出&#x2F;导入(EXP&#x2F;IMP)、热备份和冷备份</li><li>导出备份是一种逻辑备份，冷备份和热备份是物理备份。</li></ul><h1 id="truncate与delete的区别？（delete-from-table和truncate-table-tablea的区别！）"><a href="#truncate与delete的区别？（delete-from-table和truncate-table-tablea的区别！）" class="headerlink" title="truncate与delete的区别？（delete from table和truncate table tablea的区别！）"></a>truncate与delete的区别？（delete from table和truncate table tablea的区别！）</h1><ul><li>truncate是DDL語言</li><li>delete是DML語言 DDL語言是自動提交的，命令完成就不可回滾.truncate的速度也比delete要快得多.</li><li>相同点:truncate和不带where子句的delete, 以及drop都会删除表内的数据</li><li>不同点:<ul><li>truncate和 delete只删除数据不删除表的结构(定义)</li><li>drop语句将删除表的结构被依赖的约束(constrain),触发器(trigger),索引(index); 依赖于该表的存储过程&#x2F;函数将保留,但是变为invalid状态.</li><li>delete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效;如果有相应的trigger,执行的时候将被触发.</li><li>truncate,drop是ddl, 操作立即生效,原数据不放到rollback segment中,不能回滚. 操作不触发trigger.</li><li>delete语句不影响表所占用的extent, 高水线(high watermark)保持原位置不动</li><li>显然drop语句将表所占用的空间全部释放</li><li>truncate 语句缺省情况下见空间释放到 minextents个 extent,除非使用reuse storage; truncate会将高水线复位(回到最开始).</li></ul></li><li>速度,一般来说: drop&gt; truncate &gt; delete</li><li>安全性:小心使用drop 和truncate,尤其没有备份的时候.否则哭都来不及</li><li>使用上,想删除部分数据行用delete,注意带上where子句. 回滚段要足够大.</li><li>想删除表,当然用drop</li><li>想保留表而将所有数据删除. 如果和事务无关,用truncate即可. 如果和事务有关,或者想触发trigger,还是用delete.</li></ul><h1 id="Oracle冷备份的通常步骤"><a href="#Oracle冷备份的通常步骤" class="headerlink" title="Oracle冷备份的通常步骤"></a>Oracle冷备份的通常步骤</h1><ul><li>正常关闭数据库</li><li>备份所有重要的文件到备份目录（数据文件、控制文件、重做日志文件等）</li><li>完成备份后启动数据库用冷备份进行恢复时，只需要将所有文件恢复到原有位置，就可以启动数据库了</li><li>关闭数据库 SQL&gt;shutdown</li><li>备份文件到备份的目录</li><li>然后启动数据库 ＃sqlplus “&#x2F;as sysdba”SQL&gt;startup</li><li>冷备份完毕！！</li></ul><h1 id="对数据库的访问是怎么实现的"><a href="#对数据库的访问是怎么实现的" class="headerlink" title="对数据库的访问是怎么实现的"></a>对数据库的访问是怎么实现的</h1><ul><li>将对持久层数据库的基本添加，修改，查找等操作提取到BaseDAO中</li><li>采用JavaBean对数据进行封装，以便对持久层的数据能够很好的处理，实现BaseDAO设计对数据库访问的便捷</li><li>业务组件通过DAO 的委托接口调用DAO对象，使得上层组件不 直接依赖于DAO的实现类.</li></ul><h1 id="Mysql-的技术特点是什么？"><a href="#Mysql-的技术特点是什么？" class="headerlink" title="Mysql 的技术特点是什么？"></a>Mysql 的技术特点是什么？</h1><ul><li>Mysql 数据库软件是一个客户端或服务器系统，其中包括：支持各种客户端程序和库的多线程 SQL 服务器、不同的后端、广泛的应用程序编程接口和管理工具。</li></ul><h1 id="Heap-表是什么？"><a href="#Heap-表是什么？" class="headerlink" title="Heap 表是什么？"></a>Heap 表是什么？</h1><ul><li>HEAP 表存在于内存中，用于临时高速存储。</li><li>BLOB 或 TEXT 字段是不允许的</li><li>只能使用比较运算符&#x3D;，&lt;，&gt;，&#x3D;&gt;，&#x3D; &lt;</li><li>HEAP 表不支持 AUTO_INCREMENT</li><li>索引不可为 NULL</li></ul><h1 id="Mysql-服务器默认端口是什么？"><a href="#Mysql-服务器默认端口是什么？" class="headerlink" title="Mysql 服务器默认端口是什么？"></a>Mysql 服务器默认端口是什么？</h1><ul><li>Mysql 服务器的默认端口是 3306。</li></ul><h1 id="与-Oracle-相比，Mysql-有什么优势？"><a href="#与-Oracle-相比，Mysql-有什么优势？" class="headerlink" title="与 Oracle 相比，Mysql 有什么优势？"></a>与 Oracle 相比，Mysql 有什么优势？</h1><ul><li>Mysql 是开源软件，随时可用，无需付费。</li><li>Mysql 是便携式的</li><li>带有命令提示符的 GUI。</li><li>使用 Mysql 查询浏览器支持管理</li></ul><h1 id="如何区分-FLOAT-和-DOUBLE？"><a href="#如何区分-FLOAT-和-DOUBLE？" class="headerlink" title="如何区分 FLOAT 和 DOUBLE？"></a>如何区分 FLOAT 和 DOUBLE？</h1><ul><li>以下是 FLOAT 和 DOUBLE 的区别：<ul><li>浮点数以 8 位精度存储在 FLOAT 中，并且有四个字节。</li><li>浮点数存储在 DOUBLE 中，精度为 18 位，有八个字节。</li></ul></li></ul><h1 id="区分-CHAR-LENGTH-和-LENGTH？"><a href="#区分-CHAR-LENGTH-和-LENGTH？" class="headerlink" title="区分 CHAR_LENGTH 和 LENGTH？"></a>区分 CHAR_LENGTH 和 LENGTH？</h1><ul><li>CHAR_LENGTH 是字符数，而 LENGTH 是字节数</li><li>Latin 字符的这两个数据是相同的，但是对于 Unicode 和其他编码，它们是不同的。</li></ul><h1 id="在-Mysql-中-ENUM-的用法是什么？"><a href="#在-Mysql-中-ENUM-的用法是什么？" class="headerlink" title="在 Mysql 中 ENUM 的用法是什么？"></a>在 Mysql 中 ENUM 的用法是什么？</h1><ul><li>ENUM 是一个字符串对象，用于指定一组预定义的值，并可在创建表时使用。</li><li>Create table size(name ENUM(‘Smail,’Medium’,’Large’));</li></ul><h1 id="如何定义-REGEXP？"><a href="#如何定义-REGEXP？" class="headerlink" title="如何定义 REGEXP？"></a>如何定义 REGEXP？</h1><ul><li>REGEXP 是模式匹配，其中匹配模式在搜索值的任何位置。</li></ul><h1 id="列的字符串类型可以是什么？"><a href="#列的字符串类型可以是什么？" class="headerlink" title="列的字符串类型可以是什么？"></a>列的字符串类型可以是什么？</h1><ul><li>字符串类型是：<ul><li>SET</li><li>BLOB</li><li>ENUM</li><li>CHAR</li><li>TEXT</li><li>VARCHAR</li></ul></li></ul><h1 id="如何获取当前的-Mysql-版本？"><a href="#如何获取当前的-Mysql-版本？" class="headerlink" title="如何获取当前的 Mysql 版本？"></a>如何获取当前的 Mysql 版本？</h1><ul><li>SELECT VERSION();用于获取当前 Mysql 的版本。</li></ul><h1 id="Mysql-中使用什么存储引擎？"><a href="#Mysql-中使用什么存储引擎？" class="headerlink" title="Mysql 中使用什么存储引擎？"></a>Mysql 中使用什么存储引擎？</h1><ul><li>存储引擎称为表类型，数据使用各种技术存储在文件中。</li><li>技术涉及：<ul><li>Storage mechanism</li><li>Locking levels</li><li>Indexing</li><li>Capabilities and functions.</li></ul></li></ul><h1 id="Mysql-驱动程序是什么？"><a href="#Mysql-驱动程序是什么？" class="headerlink" title="Mysql 驱动程序是什么？"></a>Mysql 驱动程序是什么？</h1><ul><li>以下是 Mysql 中可用的驱动程序：<ul><li>PHP 驱动程序</li><li>JDBC 驱动程序</li><li>ODBC 驱动程序</li><li>CWRAPPER PYTHON驱动程序</li><li>PERL 驱动程序</li><li>RUBY 驱动程序</li><li>CAP11PHP 驱动程序</li></ul></li></ul><h1 id="TIMESTAMP-在-UPDATE-CURRENT-TIMESTAMP-数据类型上做什么？"><a href="#TIMESTAMP-在-UPDATE-CURRENT-TIMESTAMP-数据类型上做什么？" class="headerlink" title="TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据类型上做什么？"></a>TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据类型上做什么？</h1><ul><li>创建表时 TIMESTAMP 列用 Zero 更新</li><li>只要表中的其他字段发生更改，UPDATE CURRENT_TIMESTAMP 修饰符就将时间戳字段更新为当前时间。</li></ul><h1 id="如何使用-Unix-shell-登录-Mysql？"><a href="#如何使用-Unix-shell-登录-Mysql？" class="headerlink" title="如何使用 Unix shell 登录 Mysql？"></a>如何使用 Unix shell 登录 Mysql？</h1><ul><li>mysql -h hostname -u</li></ul><h1 id="如何控制-HEAP-表的最大尺寸？"><a href="#如何控制-HEAP-表的最大尺寸？" class="headerlink" title="如何控制 HEAP 表的最大尺寸？"></a>如何控制 HEAP 表的最大尺寸？</h1><ul><li>Heal 表的大小可通过称为 max_heap_table_size 的 Mysql 配置变量来控制。</li></ul><h1 id="federated-表是什么？"><a href="#federated-表是什么？" class="headerlink" title="federated 表是什么？"></a>federated 表是什么？</h1><ul><li>federated 表，允许访问位于其他服务器数据库上的表。</li></ul><h1 id="怎样才能找出最后一次插入时分配了哪个自动增量？"><a href="#怎样才能找出最后一次插入时分配了哪个自动增量？" class="headerlink" title="怎样才能找出最后一次插入时分配了哪个自动增量？"></a>怎样才能找出最后一次插入时分配了哪个自动增量？</h1><ul><li>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。</li></ul><h1 id="你怎么看到为表格定义的所有索引？"><a href="#你怎么看到为表格定义的所有索引？" class="headerlink" title="你怎么看到为表格定义的所有索引？"></a>你怎么看到为表格定义的所有索引？</h1><ul><li>索引是通过以下方式为表格定义的：SHOW INDEX FROM</li></ul><h1 id="LIKE-声明中的％和-是什么意思？"><a href="#LIKE-声明中的％和-是什么意思？" class="headerlink" title="LIKE 声明中的％和_是什么意思？"></a>LIKE 声明中的％和_是什么意思？</h1><ul><li>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。</li></ul><h1 id="如何在-Unix-和-Mysql-时间戳之间进行转换？"><a href="#如何在-Unix-和-Mysql-时间戳之间进行转换？" class="headerlink" title="如何在 Unix 和 Mysql 时间戳之间进行转换？"></a>如何在 Unix 和 Mysql 时间戳之间进行转换？</h1><ul><li>UNIX_TIMESTAMP 是从 Mysql 时间戳转换为 Unix 时间戳的命令</li><li>FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql 时间戳的命令</li></ul><h1 id="列对比运算符是什么？"><a href="#列对比运算符是什么？" class="headerlink" title="列对比运算符是什么？"></a>列对比运算符是什么？</h1><ul><li>在 SELECT 语句的列比较中使用&#x3D;，&lt;&gt;，&lt;&#x3D;，&lt;，&gt; &#x3D;，&gt;，&lt;&lt;，&gt;&gt;，&lt;&#x3D;&gt;，AND，OR 或 LIKE 运算符。</li></ul><h1 id="LIKE-和-REGEXP-操作有什么区别？"><a href="#LIKE-和-REGEXP-操作有什么区别？" class="headerlink" title="LIKE 和 REGEXP 操作有什么区别？"></a>LIKE 和 REGEXP 操作有什么区别？</h1><ul><li>LIKE 和 REGEXP 运算符用于表示^和％。</li><li>SELECT * FROM employee WHERE emp_name REGEXP “^b”;</li><li>SELECT * FROM employee WHERE emp_name LIKE “%b”;</li></ul><h1 id="BLOB-和-TEXT-有什么区别？"><a href="#BLOB-和-TEXT-有什么区别？" class="headerlink" title="BLOB 和 TEXT 有什么区别？"></a>BLOB 和 TEXT 有什么区别？</h1><ul><li>BLOB 是一个二进制对象，可以容纳可变数量的数据</li><li>有四种类型的 BLOB<ul><li>TINYBLOB</li><li>BLOB</li><li>MEDIUMBLOB</li><li>LONGBLOB</li></ul></li><li>它们只能在所能容纳价值的最大长度上有所不同。</li><li>TEXT 是一个不区分大小写的 BLOB</li><li>四种 TEXT 类型<ul><li>TINYTEXT</li><li>TEXT</li><li>MEDIUMTEXT</li><li>LONGTEXT</li></ul></li><li>它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。</li><li>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT值不区分大小写。</li></ul><h1 id="mysql-fetch-array-和-mysql-fetch-object-的区别是什么？"><a href="#mysql-fetch-array-和-mysql-fetch-object-的区别是什么？" class="headerlink" title="mysql_fetch_array 和 mysql_fetch_object 的区别是什么？"></a>mysql_fetch_array 和 mysql_fetch_object 的区别是什么？</h1><ul><li>mysql_fetch_array（） - 将结果行作为关联数组或来自数据库的常规数组返回。</li><li>mysql_fetch_object - 从数据库返回结果行作为对象。</li></ul><h1 id="我们如何在-mysql-中运行批处理模式？"><a href="#我们如何在-mysql-中运行批处理模式？" class="headerlink" title="我们如何在 mysql 中运行批处理模式？"></a>我们如何在 mysql 中运行批处理模式？</h1><ul><li>以下命令用于在批处理模式下运行：<ul><li>mysql;</li><li>mysql mysql.out</li></ul></li></ul><h1 id="MyISAM-表格将在哪里存储，并且还提供其存储格式？"><a href="#MyISAM-表格将在哪里存储，并且还提供其存储格式？" class="headerlink" title="MyISAM 表格将在哪里存储，并且还提供其存储格式？"></a>MyISAM 表格将在哪里存储，并且还提供其存储格式？</h1><ul><li>每个 MyISAM 表格以三种格式存储在磁盘上：<ul><li>·“.frm”文件存储表定义</li><li>·数据文件具有“.MYD”（MYData）扩展名</li><li>索引文件具有“.MYI”（MYIndex）扩展名</li></ul></li></ul><h1 id="Mysql-中有哪些不同的表格？"><a href="#Mysql-中有哪些不同的表格？" class="headerlink" title="Mysql 中有哪些不同的表格？"></a>Mysql 中有哪些不同的表格？</h1><ul><li>共有 5 种类型的表格：<ul><li>MyISAM</li><li>Heap</li><li>Merge</li><li>INNODB</li><li>ISAM</li></ul></li><li>MyISAM 是 Mysql 的默认存储引擎。</li></ul><h1 id="ISAM-是什么？"><a href="#ISAM-是什么？" class="headerlink" title="ISAM 是什么？"></a>ISAM 是什么？</h1><ul><li>ISAM 简称为索引顺序访问方法</li><li>它是由 IBM 开发的，用于在磁带等辅助存储系统上存储和检索数据。</li></ul><h1 id="InnoDB-是什么？"><a href="#InnoDB-是什么？" class="headerlink" title="InnoDB 是什么？"></a>InnoDB 是什么？</h1><ul><li>lnnoDB 是一个由 Oracle 公司开发的 Innobase Oy 事务安全存储引擎。</li></ul><h1 id="Mysql-如何优化-DISTINCT？"><a href="#Mysql-如何优化-DISTINCT？" class="headerlink" title="Mysql 如何优化 DISTINCT？"></a>Mysql 如何优化 DISTINCT？</h1><ul><li>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。</li><li>SELECT DISTINCT t1.a FROM t1,t2 where t1.a&#x3D;t2.a;</li></ul><h1 id="如何输入字符为十六进制数字？"><a href="#如何输入字符为十六进制数字？" class="headerlink" title="如何输入字符为十六进制数字？"></a>如何输入字符为十六进制数字？</h1><ul><li>如果想输入字符为十六进制数字，可以输入带有单引号的十六进制数字和前缀（X），或者只用（Ox）前缀输入十六进制数字。</li><li>如果表达式上下文是字符串，则十六进制数字串将自动转换为字符串。</li></ul><h1 id="如何显示前-50-行？"><a href="#如何显示前-50-行？" class="headerlink" title="如何显示前 50 行？"></a>如何显示前 50 行？</h1><ul><li>在 Mysql 中，使用以下代码查询显示前 50 行：</li><li>SELECT*FROM LIMIT 0,50;</li></ul><h1 id="可以使用多少列创建索引？"><a href="#可以使用多少列创建索引？" class="headerlink" title="可以使用多少列创建索引？"></a>可以使用多少列创建索引？</h1><ul><li>任何标准表最多可以创建 16 个索引列。</li></ul><h1 id="NOW（）和-CURRENT-DATE（）有什么区别？"><a href="#NOW（）和-CURRENT-DATE（）有什么区别？" class="headerlink" title="NOW（）和 CURRENT_DATE（）有什么区别？"></a>NOW（）和 CURRENT_DATE（）有什么区别？</h1><ul><li>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。</li><li>CURRENT_DATE（）仅显示当前年份，月份和日期。</li></ul><h1 id="Mysql-表中允许有多少个-TRIGGERS？"><a href="#Mysql-表中允许有多少个-TRIGGERS？" class="headerlink" title="Mysql 表中允许有多少个 TRIGGERS？"></a>Mysql 表中允许有多少个 TRIGGERS？</h1><ul><li>在 Mysql 表中允许有六个触发器，如下：<ul><li>BEFORE INSERT</li><li>AFTER INSERT</li><li>BEFORE UPDATE</li><li>AFTER UPDATE</li><li>BEFORE DELETE</li><li>AFTER DELETE</li></ul></li></ul><h1 id="什么是非标准字符串类型？"><a href="#什么是非标准字符串类型？" class="headerlink" title="什么是非标准字符串类型？"></a>什么是非标准字符串类型？</h1><ul><li>以下是非标准字符串类型：<ul><li>TINYTEXT</li><li>TEXT</li><li>MEDIUMTEXT</li><li>LONGTEXT</li></ul></li></ul><h1 id="解释访问控制列表"><a href="#解释访问控制列表" class="headerlink" title="解释访问控制列表"></a>解释访问控制列表</h1><ul><li>ACL（访问控制列表）是与对象关联的权限列表</li><li>这个列表是 Mysql 服务器安全模型的基础，它有助于排除用户无法连接的问题。</li><li>Mysql 将 ACL（也称为授权表）缓存在内存中</li><li>当用户尝试认证或运行命令时，Mysql 会按照预定的顺序检查 ACL 的认证信息和权限。</li></ul><h1 id="MYSQL-支持事务吗？"><a href="#MYSQL-支持事务吗？" class="headerlink" title="MYSQL 支持事务吗？"></a>MYSQL 支持事务吗？</h1><ul><li>在缺省模式下，MYSQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，所以在缺省情况下，mysql 是不支持事务的。</li><li>但是如果你的 MYSQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的 MYSQL 就可以使用事务处理,使用 SET AUTOCOMMIT&#x3D;0 就可以使 MYSQL 允许在非 autocommit 模式，在非autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK 来回滚你的更改。</li></ul><h1 id="mysql-里记录货币用什么字段类型好"><a href="#mysql-里记录货币用什么字段类型好" class="headerlink" title="mysql 里记录货币用什么字段类型好"></a>mysql 里记录货币用什么字段类型好</h1><ul><li>NUMERIC 和 DECIMAL 类型被 Mysql 实现为同样的类型，这在 SQL92 标准允许</li><li>他们被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据</li><li>当声明一个类是这些类型之一时，精度和规模的能被(并且通常是)指定；点击这里有一套最全阿里面试题总结。</li></ul><h1 id="MYSQL-数据表在什么情况下容易损坏？"><a href="#MYSQL-数据表在什么情况下容易损坏？" class="headerlink" title="MYSQL 数据表在什么情况下容易损坏？"></a>MYSQL 数据表在什么情况下容易损坏？</h1><ul><li>服务器突然断电导致数据文件损坏。</li><li>强制关机，没有先关闭 mysql 服务等。</li></ul><h1 id="mysql-有关权限的表都有哪几个？"><a href="#mysql-有关权限的表都有哪几个？" class="headerlink" title="mysql 有关权限的表都有哪几个？"></a>mysql 有关权限的表都有哪几个？</h1><ul><li>Mysql 服务器通过权限表来控制用户对数据库的访问，权限表存放在 mysql 数据库里</li><li>由mysql_install_db 脚本初始化</li><li>这些权限表分别 user，db，table_priv，columns_priv 和host。</li></ul><h1 id="一张表，里面有-ID-自增主键，当-insert-了-17-条记录之后，"><a href="#一张表，里面有-ID-自增主键，当-insert-了-17-条记录之后，" class="headerlink" title="一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，"></a>一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，</h1><ul><li>删除了第 15,16,17 条记录，再把 Mysql 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15 ？</li><li>如果表的类型是MylSAM，那么是18因为MyISAM表会把自增主键的最大ID记录到数据文件里，重启MySQL自增主键的最大ID也不会丢失</li><li>如果表的类型是InnoDB，那么是15InnoDB表只是把自增主键的最大ID记录到内存中，所以重启数据库或者是对表进行OPTIMIZE操作，都会导致最大ID丢失。</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/554d7a59d68c.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/554d7a59d68c.html" class="post-title-link" itemprop="url">Zookeeper</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:19:03" itemprop="dateCreated datePublished" datetime="2023-12-20T16:19:03+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-24 19:23:57" itemprop="dateModified" datetime="2023-12-24T19:23:57+08:00">2023-12-24</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.1k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="zookeeper-都有哪些使用场景？"><a href="#zookeeper-都有哪些使用场景？" class="headerlink" title="zookeeper 都有哪些使用场景？"></a>zookeeper 都有哪些使用场景？</h1><ul><li>大致来说，zookeeper 的使用场景如下，我就举几个简单的，大家能说几个就好了：<ul><li>分布式协调</li><li>分布式锁</li><li>元数据&#x2F;配置信息管理</li><li>HA高可用性</li></ul></li></ul><h4 id="分布式协调"><a href="#分布式协调" class="headerlink" title="分布式协调"></a>分布式协调</h4><ul><li>这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值注册个监听器，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。</li></ul><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><ul><li>对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也尝试去创建那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</li></ul><h4 id="元数据-配置信息管理"><a href="#元数据-配置信息管理" class="headerlink" title="元数据&#x2F;配置信息管理"></a>元数据&#x2F;配置信息管理</h4><ul><li>ookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？</li></ul><h4 id="HA高可用性"><a href="#HA高可用性" class="headerlink" title="HA高可用性"></a>HA高可用性</h4><ul><li>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个重要进程一般会做主备两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。</li></ul><h1 id="什么是-ZooKeeper"><a href="#什么是-ZooKeeper" class="headerlink" title="什么是 ZooKeeper"></a>什么是 ZooKeeper</h1><h4 id="ZooKeeper-的由来"><a href="#ZooKeeper-的由来" class="headerlink" title="ZooKeeper 的由来"></a>ZooKeeper 的由来</h4><ul><li>Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。</li></ul><h4 id="ZooKeeper-概览"><a href="#ZooKeeper-概览" class="headerlink" title="ZooKeeper 概览"></a>ZooKeeper 概览</h4><ul><li>ZooKeeper 是一个开源的分布式协调服务，ZooKeeper框架最初是在“Yahoo!”上构建的，用于以简单而稳健的方式访问他们的应用程序。 后来，Apache ZooKeeper成为Hadoop，HBase和其他分布式框架使用的有组织服务的标准。 例如，Apache HBase使用ZooKeeper跟踪分布式数据的状态</li><li>ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</li><li>原语： 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。</li><li>ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布&#x2F;订阅、负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和分布式队列等功能。</li><li>Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心。服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。</li></ul><h4 id="结合个人使用情况的讲一下-ZooKeeper"><a href="#结合个人使用情况的讲一下-ZooKeeper" class="headerlink" title="结合个人使用情况的讲一下 ZooKeeper"></a>结合个人使用情况的讲一下 ZooKeeper</h4><ul><li>在我自己做过的项目中，主要使用到了 ZooKeeper 作为 Dubbo 的注册中心(Dubbo 官方推荐使用 ZooKeeper注册中心)。</li><li>另外在搭建 solr 集群的时候，我使用 ZooKeeper 作为 solr 集群的管理工具。这时，ZooKeeper 主要提供下面几个功能：<ul><li>集群管理：容错、负载均衡</li><li>配置文件的集中管理</li><li>集群的入口</li></ul></li><li>我个人觉得在使用 ZooKeeper 的时候，最好是使用 集群版的 ZooKeeper 而不是单机版的。官网给出的架构图就描述的是一个集群版的 ZooKeeper 。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。</li></ul><h1 id="为什么最好使用奇数台服务器构成-ZooKeeper-集群？"><a href="#为什么最好使用奇数台服务器构成-ZooKeeper-集群？" class="headerlink" title="为什么最好使用奇数台服务器构成 ZooKeeper 集群？"></a>为什么最好使用奇数台服务器构成 ZooKeeper 集群？</h1><ul><li>我们知道在Zookeeper中 Leader 选举算法采用了Zab协议</li><li>Zab核心思想是当多数 Server 写成功，则任务数据写成功<ul><li>如果有3个Server，则最多允许1个Server 挂掉。</li><li>如果有4个Server，则同样最多允许1个Server挂掉。</li><li>既然3个或者4个Server，同样最多允许1个Server挂掉，那么它们的可靠性是一样的，所以选择奇数个ZooKeeper Server即可，这里选择3个Server。</li></ul></li></ul><h1 id="关于-ZooKeeper-的一些重要概念"><a href="#关于-ZooKeeper-的一些重要概念" class="headerlink" title="关于 ZooKeeper 的一些重要概念"></a>关于 ZooKeeper 的一些重要概念</h1><h4 id="重要概念总结"><a href="#重要概念总结" class="headerlink" title="重要概念总结"></a>重要概念总结</h4><ul><li>ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。</li><li>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。</li><li>ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。</li><li>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</li><li>ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。</li><li>ZooKeeper 底层其实只提供了两个功能：<ul><li>管理（存储、读取）用户程序提交的数据；</li><li>为用户程序提交数据节点监听服务。</li></ul></li></ul><h4 id="会话（Session）"><a href="#会话（Session）" class="headerlink" title="会话（Session）"></a>会话（Session）</h4><ul><li>Session 指的是 ZooKeeper 服务器与客户端会话</li><li>在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接</li><li>客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</li><li>在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</li></ul><h4 id="Znode"><a href="#Znode" class="headerlink" title="Znode"></a>Znode</h4><ul><li>在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类<ul><li>第一类同样是指构成集群的机器，我们称之为机器节点</li><li>第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。</li></ul></li><li>Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree），由斜杠（&#x2F;）的进行分割的路径，就是一个Znode，例如&#x2F;foo&#x2F;path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。</li><li>在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</li></ul><h4 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h4><ul><li>在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 cversion（当前ZNode的ACL版本）。</li></ul><h4 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a>Watcher</h4><ul><li>Watcher（事件监听器），是Zookeeper中的一个很重要的特性</li><li>Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。</li></ul><h4 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h4><ul><li>Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。</li><li>Zookeeper 定义了5种权限。</li><li>其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。</li></ul><h1 id="ZooKeeper-特点"><a href="#ZooKeeper-特点" class="headerlink" title="ZooKeeper 特点"></a>ZooKeeper 特点</h1><ul><li>顺序一致性： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</li><li>原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</li><li>单一系统映像 ： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</li><li>可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</li></ul><h1 id="ZooKeeper-设计目标"><a href="#ZooKeeper-设计目标" class="headerlink" title="ZooKeeper 设计目标"></a>ZooKeeper 设计目标</h1><h4 id="简单的数据模型"><a href="#简单的数据模型" class="headerlink" title="简单的数据模型"></a>简单的数据模型</h4><ul><li>ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似</li><li>名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录</li><li>与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。</li></ul><h4 id="可构建集群"><a href="#可构建集群" class="headerlink" title="可构建集群"></a>可构建集群</h4><ul><li>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的</li><li>客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。</li><li>组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信</li><li>集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。</li></ul><h4 id="顺序访问"><a href="#顺序访问" class="headerlink" title="顺序访问"></a>顺序访问</h4><ul><li>对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）</li></ul><h4 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h4><ul><li>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</li></ul><h1 id="ZooKeeper-集群角色介绍"><a href="#ZooKeeper-集群角色介绍" class="headerlink" title="ZooKeeper 集群角色介绍"></a>ZooKeeper 集群角色介绍</h1><ul><li>最典型集群模式： Master&#x2F;Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</li><li>在 ZooKeeper 中没有选择传统的 Master&#x2F;Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。</li><li>ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器</li><li>Leader 既可以为客户端提供写服务又能提供读服务</li><li>除了 Leader 外，Follower 和 Observer 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。</li></ul><h1 id="ZooKeeper-ZAB-协议-Paxos算法"><a href="#ZooKeeper-ZAB-协议-Paxos算法" class="headerlink" title="ZooKeeper &amp;ZAB 协议&amp;Paxos算法"></a>ZooKeeper &amp;ZAB 协议&amp;Paxos算法</h1><h4 id="ZAB-协议-Paxos算法"><a href="#ZAB-协议-Paxos算法" class="headerlink" title="ZAB 协议&amp;Paxos算法"></a>ZAB 协议&amp;Paxos算法</h4><ul><li>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。</li></ul><h4 id="ZAB-协议介绍"><a href="#ZAB-协议介绍" class="headerlink" title="ZAB 协议介绍"></a>ZAB 协议介绍</h4><ul><li>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议</li><li>在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</li></ul><h4 id="ZAB-协议两种基本的模式：崩溃恢复和消息广播"><a href="#ZAB-协议两种基本的模式：崩溃恢复和消息广播" class="headerlink" title="ZAB 协议两种基本的模式：崩溃恢复和消息广播"></a>ZAB 协议两种基本的模式：崩溃恢复和消息广播</h4><ul><li>ZAB协议包括两种基本的模式，分别是 崩溃恢复和消息广播</li><li>当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器</li><li>当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式</li><li>其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。</li><li>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了</li><li>当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去</li><li>正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理</li><li>Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/4f75e46c0d1c.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/4f75e46c0d1c.html" class="post-title-link" itemprop="url">设计模式</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:17:58" itemprop="dateCreated datePublished" datetime="2023-12-20T16:17:58+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-25 13:49:27" itemprop="dateModified" datetime="2023-12-25T13:49:27+08:00">2023-12-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">设计模式</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="⼯⼚⽅法模式"><a href="#⼯⼚⽅法模式" class="headerlink" title="⼯⼚⽅法模式"></a>⼯⼚⽅法模式</h1><ul><li>利⽤创建同⼀接⼝的不同实例</li></ul><h4 id="普通⼯⼚模式"><a href="#普通⼯⼚模式" class="headerlink" title="普通⼯⼚模式"></a>普通⼯⼚模式</h4><ul><li>建⽴⼀个⼯⼚类，对实现了同⼀接⼝的⼀些类进⾏实例的创建；<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class SendFactory &#123;</span><br><span class="line">    public Sender produce(String type) &#123;</span><br><span class="line">        if (&quot;mail&quot;.equals(type)) &#123;</span><br><span class="line">            return new MailSender();</span><br><span class="line">        &#125; else if (&quot;sms&quot;.equals(type)) &#123;</span><br><span class="line">            return new SmsSender();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            System.out.println(&quot;请输⼊正确的类型!&quot;);</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="多个⼯⼚⽅法模式"><a href="#多个⼯⼚⽅法模式" class="headerlink" title="多个⼯⼚⽅法模式"></a>多个⼯⼚⽅法模式</h4><ul><li>提供多个⼯⼚⽅法，分别创建对象；<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class SendFactory &#123;</span><br><span class="line">    public Sender produceMail()&#123;</span><br><span class="line">        return new MailSender();</span><br><span class="line">    &#125;</span><br><span class="line">    public Sender produceSms()&#123;</span><br><span class="line">        return new SmsSender();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="静态⼯⼚⽅法模式"><a href="#静态⼯⼚⽅法模式" class="headerlink" title="静态⼯⼚⽅法模式"></a>静态⼯⼚⽅法模式</h4><ul><li>将上⾯的多个⼯⼚⽅法置为静态的，不需要创建⼯⼚实例，直接调⽤即可；</li></ul><h4 id="适⽤场景"><a href="#适⽤场景" class="headerlink" title="适⽤场景"></a>适⽤场景</h4><ul><li>凡是出现了⼤量不同种类的产品需要创建，并且具有共同的接⼝时，可以通过⼯⼚⽅法模式进⾏创建</li><li>在以上的三种模式中，第⼀种如果传⼊的字符串有误，不能正确创建对象，第三种相对于第⼆种，不需要实例化⼯⼚类，所以，⼤多数情况下，我们会选⽤第三种——静态⼯⼚⽅法模式。</li></ul><h1 id="抽象⼯⼚模式"><a href="#抽象⼯⼚模式" class="headerlink" title="抽象⼯⼚模式"></a>抽象⼯⼚模式</h1><ul><li>多个⼯⼚</li><li>创建多个⼯⼚类，提⾼⼯⼚的扩展性，不⽤像上⾯⼀样如果增加产品则要去修改唯⼀的⼯⼚类；</li></ul><h1 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h1><ul><li>保证对象只有⼀个实例</li><li>保证在⼀个 JVM 中，该对象只有⼀个实例存在；</li></ul><h4 id="适⽤场景："><a href="#适⽤场景：" class="headerlink" title="适⽤场景："></a>适⽤场景：</h4><ul><li>某些类创建⽐较频繁，对于⼀些⼤型的对象，这是⼀笔很⼤的系统开销。</li><li>省去了 new 操作符，降低了系统内存的使⽤频率，减轻 GC 压⼒。</li><li>有些类如交易所的核⼼交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。所以只有使⽤单例模式，才能保证核⼼交易服务器独⽴控制整个流程。</li></ul><h4 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h4><ul><li>类初始化时创建单例，线程安全，适⽤于单例占内存⼩的场景，否则推荐使⽤懒汉式延迟加载；<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class Singleton&#123;</span><br><span class="line">    private static Singleton instance = new Singleton();</span><br><span class="line">    private Singleton()&#123;&#125;</span><br><span class="line">    public static Singleton newInstance()&#123;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h4><ul><li>需要创建单例实例的时候再创建，需要考虑线程安全(性能不太好)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class Singleton&#123;</span><br><span class="line">    private static Singleton instance = null;</span><br><span class="line">    private Singleton()&#123;&#125;</span><br><span class="line">    public static synchronized Singleton newInstance()&#123;</span><br><span class="line">        if(null == instance)&#123;</span><br><span class="line">            instance = new Singleton();</span><br><span class="line">        &#125;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="双重检验锁"><a href="#双重检验锁" class="headerlink" title="双重检验锁"></a>双重检验锁</h4><ul><li>效率⾼</li><li>解决问题：假如两个线程 A、B，A 执⾏了 if (instance &#x3D;&#x3D; null)语句，它会认为单例对象没有创建，此时线程切到 B 也执⾏了同样的语句，B 也认为单例对象没有创建，然后两个线程依次执⾏同步代码块，并分别创建了⼀个单例对象。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class Singleton &#123;</span><br><span class="line">    private static volatile Singleton instance = null;//volatile 的⼀个语义是禁⽌指令重排序优化</span><br><span class="line">    private Singleton()&#123;&#125;</span><br><span class="line">    public static Singleton getInstance() &#123;</span><br><span class="line">        if (instance == null) &#123;</span><br><span class="line">            synchronized (Singleton.class) &#123;</span><br><span class="line">                if (instance == null) &#123;//2</span><br><span class="line">                    instance = new Singleton();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="静态内部类⽅式"><a href="#静态内部类⽅式" class="headerlink" title="静态内部类⽅式"></a>静态内部类⽅式</h4><ul><li>可以同时保证延迟加载和线程安全<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class Singleton&#123;</span><br><span class="line">    private static class SingletonHolder&#123;</span><br><span class="line">        public static Singleton instance = new Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    private Singleton()&#123;&#125;</span><br><span class="line">    public static Singleton newInstance()&#123;</span><br><span class="line">        return SingletonHolder.instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h4><ul><li>使⽤枚举除了线程安全和防⽌反射调⽤构造器之外，还提供了⾃动序列化机制，防⽌反序列化的时候创建新的对象。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public enum Singleton&#123;</span><br><span class="line">    instance;</span><br><span class="line">    public void whateverMethod()&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h1><ul><li>将⼀个对象作为原型，对其进⾏复制、克隆，产⽣⼀个和元对象类似的新对象；</li><li>核⼼：它的核⼼是原型类 Prototype，需要实现 Cloneable 接⼝，和重写 Object 类中的 clone ⽅法；</li><li>作⽤：使⽤原型模式创建对象⽐直接 new ⼀个对象在性能上要好的多，因为 Object 类的 clone ⽅法是⼀个本地⽅法，它直接操作内存<br>中的⼆进制流，特别是复制⼤对象时，性能的差别⾮常明显。</li></ul><h1 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h1><ul><li>接⼝兼容</li><li>将某个类的接⼝转换成客户端期望的另⼀个接⼝表示，⽬的是消除由于接⼝不匹配所造成的类的兼容性问题。</li><li>类的适配器模式</li><li>对象的适配器模式</li><li>接⼝的适配器模式</li></ul><h4 id="使⽤场景"><a href="#使⽤场景" class="headerlink" title="使⽤场景"></a>使⽤场景</h4><ul><li>类的适配器模式：当希望将⼀个类转换成满⾜另⼀个新接⼝的类时，可以使⽤类的适配器模式，创建⼀个新类，继承原有的类，<br>实现新的接⼝即可。</li><li>对象的适配器模式：当希望将⼀个对象转换成满⾜另⼀个新接⼝的对象时，可以创建⼀个 Wrapper 类，持有原类的⼀个实例，在<br>Wrapper 类的⽅法中，调⽤实例的⽅法就⾏。</li><li>接⼝的适配器模式：当不希望实现⼀个接⼝中所有的⽅法时，可以创建⼀个抽象类 Wrapper，实现所有⽅法，我们写别的类的时<br>候，继承抽象类即可。</li></ul><h1 id="装饰模式"><a href="#装饰模式" class="headerlink" title="装饰模式"></a>装饰模式</h1><ul><li>装饰模式就是给⼀个对象增加⼀些新的功能，⽽且是动态的，要求装饰对象和被装饰对象实现同⼀个接⼝，装饰对象持有被装饰对象的实例：</li></ul><h4 id="使⽤场景："><a href="#使⽤场景：" class="headerlink" title="使⽤场景："></a>使⽤场景：</h4><ul><li>需要扩展⼀个类的功能</li><li>动态的为⼀个对象增加功能，⽽且还能动态撤销。（继承不能做到这⼀点，继承的功能是静态的，不能动态增删。）</li></ul><h1 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h1><ul><li>持有被代理类的实例，进⾏操作前后控制</li><li>采⽤⼀个代理类调⽤原有的⽅法，且对产⽣的结果进⾏控制。</li></ul><h1 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h1><ul><li>集合所有操作到⼀个类</li><li>外观模式是为了解决类与类之间的依赖关系的，像 spring ⼀样，可以将类和类之间的关系配置到配置⽂件中</li><li>⽽外观模式就是将他们的关系放在⼀个 Facade 类中，降低了类类之间的耦合度。</li></ul><h1 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h1><ul><li>数据库驱动桥接</li><li>桥接模式就是把事物和其具体实现分开，使他们可以各⾃独⽴的变化</li><li>桥接的⽤意是：将抽象化与实现化解耦，使得⼆者可以独⽴变化，像我们常⽤的 JDBC 桥 DriverManager ⼀样，JDBC 进⾏连接数据库的时候，在各个数据库之间进⾏切换，基本不需要动太多的代码，甚⾄丝毫不⽤动，原因就是 JDBC 提供统⼀接⼝，每个数据库提供各⾃的实现，⽤⼀个叫做数据库驱动的程序来桥接就⾏了。</li></ul><h1 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h1><ul><li>部分整体模式</li><li>组合模式有时⼜叫部分-整体模式在处理类似树形结构的问题时⽐较⽅便。</li></ul><h1 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h1><ul><li>共享池、数据库连接池</li><li>享元模式的主要⽬的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与⼯⼚模式⼀起使⽤</li><li>当⼀个客户端请求时，⼯⼚需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建⼀个新对象，如数据库连接池；</li></ul><h1 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h1><ul><li>多种算法封装</li><li>策略模式定义了⼀系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使⽤算法的客户</li><li>需要设计⼀个接⼝，为⼀系列实现类提供统⼀的⽅法，多个实现类实现该接⼝：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ICalculator cal = new Plus(); //ICalculator 是统⼀接⼝，Plus 是实现类(多个)</span><br><span class="line">int result = cal.calculate(exp); //jvm 根据实现类不同⽽调⽤不同实现类的⽅法</span><br></pre></td></tr></table></figure></li></ul><h1 id="模板⽅法模式"><a href="#模板⽅法模式" class="headerlink" title="模板⽅法模式"></a>模板⽅法模式</h1><ul><li>抽象⽅法作为⻣架，具体逻辑让⼦类实现</li><li>定义⼀个操作中算法的框架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改变算法的结构即可重定义该算法中的某些特定步骤</li><li>完成公共动作和特殊动作的分离。</li></ul><h1 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h1><ul><li>发布-订阅模式</li><li>当⼀个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是⼀种⼀对多的关系</li><li>类似于邮件订阅和 RSS 订阅，当你订阅了该⽂章，如果后续有更新，会及时通知你。</li></ul><h1 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h1><ul><li>遍历集合</li><li>迭代器模式就是顺序访问聚集中的对象</li></ul><h1 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h1><ul><li>多任务形成⼀条链，请求在链上传递</li><li>有多个对象，每个对象持有对下⼀个对象的引⽤，这样就会形成⼀条链，请求在这条链上传递，直到某⼀对象决定处理该请求</li><li>但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进⾏动态的调整。</li></ul><h1 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h1><ul><li>实现请求和执⾏的解耦</li><li>命令模式的⽬的就是达到命令的发出者和执⾏者之间解耦，实现请求和执⾏分开，熟悉 Struts 的同学应该知道，Struts 其实就是⼀种将请求和呈现分离的技术，其中必然涉及命令模式的思想！</li></ul><h1 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h1><ul><li>保存和恢复对象状态</li><li>主要⽬的是保存⼀个对象的某个状态，以便在适当的时候恢复对象</li></ul><h1 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h1><ul><li>对象状态改变时改变其⾏为</li><li>当对象的状态改变时，同时改变其⾏为</li><li>状态模式就两点<ul><li>可以通过改变状态来获得不同的⾏为</li><li>你的好友能同时看到你的变化</li></ul></li></ul><h1 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h1><ul><li>数据接⼝稳定，但算法易变</li><li>访问者模式把数据结构和作⽤于结构上的操作解耦合，使得操作集合可相对⾃由地演化</li><li>访问者模式适⽤于数据结构相对稳定算法⼜易变化的系统</li><li>因为访问者模式使得算法操作增加变得容易</li><li>访问者模式就是⼀种分离对象数据结构与⾏为的⽅法，通过这种分离，可达到为⼀个被访问者动态添加新的操作⽽⽆需做其它的修改的效果</li></ul><h1 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h1><ul><li>中介者模式也是⽤来降低类类之间的耦合的</li><li>如果使⽤中介者模式，只需关⼼和 Mediator 类的关系</li><li>具体类类之间的关系及调度交给 Mediator 就⾏，这有点像 spring 容器的作⽤。</li></ul><h1 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h1><ul><li>对于⼀些固定⽂法构建⼀个解释句⼦的解释器，如正则表达式</li><li>解释器模式⽤来做各种各样的解释器，如正则表达式等的解释器。</li></ul><h1 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h1><ul><li>创建复合对象</li><li>⼯⼚类模式提供的是创建单个类的模式，⽽建造者模式则是将各种产品集中起来进⾏管理，⽤来创建复合对象，所谓复合对象就是指某个类具有不同的属性</li></ul><h1 id="设计模式的六⼤原则："><a href="#设计模式的六⼤原则：" class="headerlink" title="设计模式的六⼤原则："></a>设计模式的六⼤原则：</h1><h4 id="开闭原则（Open-Close-Principle）"><a href="#开闭原则（Open-Close-Principle）" class="headerlink" title="开闭原则（Open Close Principle）"></a>开闭原则（Open Close Principle）</h4><ul><li>开闭原则就是说对扩展开放，对修改关闭</li><li>在程序需要进⾏拓展的时候，不能去修改原有的代码，实现⼀个热插拔的效果。</li><li>所以⼀句话概括就是：为了使程序的扩展性好，易于维护和升级</li><li>想要达到这样的效果，我们需要使⽤接⼝和抽象类，后⾯的具体设计中我们会提到这点。</li></ul><h4 id="⾥⽒代换原则（Liskov-Substitution-Principle-LSP）"><a href="#⾥⽒代换原则（Liskov-Substitution-Principle-LSP）" class="headerlink" title="⾥⽒代换原则（Liskov Substitution Principle LSP）"></a>⾥⽒代换原则（Liskov Substitution Principle LSP）</h4><ul><li>⾥⽒代换原则⾯向对象设计的基本原则之⼀</li><li>⾥⽒代换原则中说，任何基类可以出现的地⽅，⼦类⼀定可以出现</li><li>LSP 是继承复⽤的基⽯，只有当衍⽣类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复⽤，⽽衍⽣类也能够在基类的基础上增加新的⾏为</li><li>⾥⽒代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化</li><li>⽽基类与⼦类的继承关系就是抽象化的具体实现，所以⾥⽒代换原则是对实现抽象化的具体步骤的规范</li></ul><h4 id="依赖倒转原则（Dependence-Inversion-Principle）"><a href="#依赖倒转原则（Dependence-Inversion-Principle）" class="headerlink" title="依赖倒转原则（Dependence Inversion Principle）"></a>依赖倒转原则（Dependence Inversion Principle）</h4><ul><li>这个是开闭原则的基础，具体内容：真对接⼝编程，依赖于抽象⽽不依赖于具体。</li></ul><h4 id="接⼝隔离原则（Interface-Segregation-Principle）"><a href="#接⼝隔离原则（Interface-Segregation-Principle）" class="headerlink" title="接⼝隔离原则（Interface Segregation Principle）"></a>接⼝隔离原则（Interface Segregation Principle）</h4><ul><li>使⽤多个隔离的接⼝，⽐使⽤单个接⼝要好</li><li>还是⼀个降低类之间的耦合度的意思</li><li>从这⼉我们看出，其实设计模式就是⼀个软件的设计思想，从⼤型软件架构出发，为了升级和维护⽅便</li><li>所以上⽂中多次出现：降低依赖，降低耦合。</li></ul><h4 id="迪⽶特法则（最少知道原则）（Demeter-Principle）"><a href="#迪⽶特法则（最少知道原则）（Demeter-Principle）" class="headerlink" title="迪⽶特法则（最少知道原则）（Demeter Principle）"></a>迪⽶特法则（最少知道原则）（Demeter Principle）</h4><ul><li>为什么叫最少知道原则，就是说：⼀个实体应当尽量少的与其他实体之间发⽣相互作⽤，使得系统功能模块相对独⽴。</li></ul><h4 id="合成复⽤原则（Composite-Reuse-Principle）"><a href="#合成复⽤原则（Composite-Reuse-Principle）" class="headerlink" title="合成复⽤原则（Composite Reuse Principle）"></a>合成复⽤原则（Composite Reuse Principle）</h4><ul><li>原则是尽量使⽤合成&#x2F;聚合的⽅式，⽽不是使⽤继承</li></ul><h1 id="jdk-中的设计模式"><a href="#jdk-中的设计模式" class="headerlink" title="jdk 中的设计模式"></a>jdk 中的设计模式</h1><h4 id="单例模式-1"><a href="#单例模式-1" class="headerlink" title="单例模式"></a>单例模式</h4><ul><li>java.lang.Runtime#getRuntime()</li><li>java.awt.Desktop#getDesktop()</li><li>java.lang.System#getSecurityManager()</li></ul><h4 id="责任链模式-1"><a href="#责任链模式-1" class="headerlink" title="责任链模式"></a>责任链模式</h4><ul><li>java.util.logging.Logger#log()</li><li>javax.servlet.Filter#doFilter()</li></ul><h4 id="观察者模式："><a href="#观察者模式：" class="headerlink" title="观察者模式："></a>观察者模式：</h4><ul><li>java.util.Observer&#x2F; java.util.Observable（很少在现实世界中使⽤）</li><li>所有实现 java.util.EventListener（因此实际上各地的 Swing）</li><li>javax.servlet.http.HttpSessionBindingListener</li><li>javax.servlet.http.HttpSessionAttributeListener</li><li>javax.faces.event.PhaseListener</li></ul><h1 id="spring-中的设计模式："><a href="#spring-中的设计模式：" class="headerlink" title="spring 中的设计模式："></a>spring 中的设计模式：</h1><h4 id="简单⼯⼚"><a href="#简单⼯⼚" class="headerlink" title="简单⼯⼚"></a>简单⼯⼚</h4><ul><li>spring 中的 BeanFactory 就是简单⼯⼚模式的体现，根据传⼊⼀个唯⼀的标识来获得 bean 对象，但是否是在传⼊ 参数后创建还是传⼊参数前创建这个要根据具体情况来定。</li><li>单例模式：Spring 下默认的 bean 均为 singleton。</li><li>代理模式：为其他对象提供⼀种代理以控制对这个对象的访问。 从结构上来看和 Decorator 模式类似，但 Proxy 是控制，更像 是⼀种对功能的限制，⽽ Decorator 是增加职责。 spring 的 Proxy 模式在 aop 中有体现，⽐如 JdkDynamicAopProxy 和 Cglib2AopProxy。</li><li>观察者模式：定义对象间的⼀种⼀对多的依赖关系，当⼀个对象的状态发⽣改变时，所有依赖于它的对象都得到通知并被⾃动更新。spring 中 Observer 模式常⽤的地⽅是 listener 的实现。如 ApplicationListener。</li></ul><h1 id="什么是设计模式"><a href="#什么是设计模式" class="headerlink" title="什么是设计模式"></a>什么是设计模式</h1><ul><li>设计模式是世界上各种各样程序员用来解决特定设计问题的尝试和测试的方法</li><li>设计模式是代码可用性的延伸</li></ul><h1 id="使用工厂模式最主要的好处是什么？在哪里使用？"><a href="#使用工厂模式最主要的好处是什么？在哪里使用？" class="headerlink" title="使用工厂模式最主要的好处是什么？在哪里使用？"></a>使用工厂模式最主要的好处是什么？在哪里使用？</h1><ul><li>工厂模式的最大好处是增加了创建对象时的封装层次</li><li>如果你使用工厂来创建对象，之后你可以使用更高级和更高性能的实现来替换原始的产品实现或类，这不需要在调用层做任何修改。</li></ul><h1 id="举一个用-Java-实现的装饰模式-decorator-design-pattern-？它是作用于对象层次还是类层次？"><a href="#举一个用-Java-实现的装饰模式-decorator-design-pattern-？它是作用于对象层次还是类层次？" class="headerlink" title="举一个用 Java 实现的装饰模式(decorator design pattern)？它是作用于对象层次还是类层次？"></a>举一个用 Java 实现的装饰模式(decorator design pattern)？它是作用于对象层次还是类层次？</h1><ul><li>装饰模式增加强了单个对象的能力</li><li>Java IO 到处都使用了装饰模式，典型例子就是 Buffered 系列类如 BufferedReader 和 BufferedWriter，它们增强了 Reader 和 Writer 对象，以实现提升性能的 Buffer 层次的读取和写入。</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/372274a5b315.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/372274a5b315.html" class="post-title-link" itemprop="url">搜索引擎</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:16:06" itemprop="dateCreated datePublished" datetime="2023-12-20T16:16:06+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-24 16:49:14" itemprop="dateModified" datetime="2023-12-24T16:49:14+08:00">2023-12-24</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" itemprop="url" rel="index"><span itemprop="name">搜索引擎</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>11k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>10 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="lucene-和-es"><a href="#lucene-和-es" class="headerlink" title="lucene 和 es"></a>lucene 和 es</h1><ul><li>lucene 是最先进、功能最强大的搜索库</li><li>如果直接基于 lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。</li><li>elasticsearch 基于 lucene，隐藏了 lucene 的复杂性，提供了简单易用的 restful api &#x2F; Java api 接口（另外还有其他语言的 api 接口）<ul><li>分布式的文档存储引擎</li><li>分布式的搜索引擎和分析引擎</li><li>分布式，支持 PB 级数据</li></ul></li></ul><h1 id="es-的核心概念"><a href="#es-的核心概念" class="headerlink" title="es 的核心概念"></a>es 的核心概念</h1><h4 id="Near-Realtime"><a href="#Near-Realtime" class="headerlink" title="Near Realtime"></a>Near Realtime</h4><ul><li>近实时，有两层意思：<ul><li>从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）</li><li>基于 es 执行搜索和分析可以达到秒级</li></ul></li></ul><h4 id="Cluster-集群"><a href="#Cluster-集群" class="headerlink" title="Cluster 集群"></a>Cluster 集群</h4><ul><li>集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。</li></ul><h4 id="Node-节点"><a href="#Node-节点" class="headerlink" title="Node 节点"></a>Node 节点</h4><ul><li>Node 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 elasticsearch 的集群。</li><li>如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。</li></ul><h4 id="Document-field"><a href="#Document-field" class="headerlink" title="Document &amp; field"></a>Document &amp; field</h4><ul><li>文档是 es 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。</li><li>每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;product_id&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;product_name&quot;: &quot;iPhone X&quot;,</span><br><span class="line">    &quot;product_desc&quot;: &quot;苹果手机&quot;,</span><br><span class="line">    &quot;category_id&quot;: &quot;2&quot;,</span><br><span class="line">    &quot;category_name&quot;: &quot;电子产品&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h4><ul><li>索引包含了一堆有相似结构的文档数据，比如商品索引<br>一个索引包含很多 document，一个索引就代表了一类相似或者相同的 ducument。</li></ul><h4 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h4><ul><li>类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。</li><li>每个 type 下的 document 的 field 可能不太一样。</li></ul><h4 id="shard"><a href="#shard" class="headerlink" title="shard"></a>shard</h4><ul><li>单台机器无法存储大量数据，es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储</li><li>有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能</li><li>每个 shard 都是一个 lucene index。</li></ul><h4 id="replica"><a href="#replica" class="headerlink" title="replica"></a>replica</h4><ul><li>任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。</li><li>replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。</li><li>primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5个 replica shard，最小的高可用配置，是 2 台服务器。</li><li>这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。</li></ul><h1 id="es-核心概念-vs-db-核心概念"><a href="#es-核心概念-vs-db-核心概念" class="headerlink" title="es 核心概念 vs. db 核心概念"></a>es 核心概念 vs. db 核心概念</h1><ul><li>es	dbindex	数据库type	数据表docuemnt	一行数据以上是一个简单的类比。</li></ul><h1 id="es-的分布式架构原理能说一下么（es-是如何实现分布式的啊）？"><a href="#es-的分布式架构原理能说一下么（es-是如何实现分布式的啊）？" class="headerlink" title="es 的分布式架构原理能说一下么（es 是如何实现分布式的啊）？"></a>es 的分布式架构原理能说一下么（es 是如何实现分布式的啊）？</h1><ul><li>ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。</li><li>核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。</li><li>es 中存储数据的基本单位是索引，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql 里的一张表。</li><li>index -&gt; type -&gt; mapping -&gt; document -&gt; field。</li><li>index 相当于 mysql 里的一张表。而 type 没法跟 mysql 里去对比，一个 index 里可以有多个 type，每个 type 的字段都是差不多的，但是有一些略微的差别。假设有一个 index，是订单 index，里面专门是放订单数据的。就好比说你在 mysql 中建表，有些订单是实物商品的订单，比如一件衣服、一双鞋子；有些订单是虚拟商品的订单，比如游戏点卡，话费充值。就两种订单大部分字段是一样的，但是少部分字段可能有略微的一些差别。<br>所以就会在订单 index 里，建两个 type，一个是实物商品订单 type，一个是虚拟商品订单 type，这两个 type 大部分字段是一样的，少部分字段是不一样的。</li><li>很多情况下，一个 index 里可能就一个 type，但是确实如果说是一个 index 里有多个 type 的情况（注意，mapping types这个概念在 ElasticSearch 7.X 已被完全移除，详细说明可以参考官方文档），你可以认为 index 是一个类别的表，具体的每个 type 代表了 mysql 中的一个表。每个 type 有一个 mapping，如果你认为一个 type 是具体的一个表，index 就代表多个 type 同属于的一个类型，而 mapping 就是这个 type 的表结构定义，你在 mysql 中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。实际上你往 index 里的一个 type 里面写的一条数据，叫做一条 document，一条 document 就代表了 mysql 中某个表里的一行，每个 document 有多个 field，每个 field 就代表了这个 document 中的一个字段的值。</li><li>你搞一个索引，这个索引可以拆分成多个 shard，每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是支持横向扩展，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是提高性能，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。接着就是这个 shard 的数据实际是有多个备份，就是说每个 shard 都有一个 primary shard，负责写入数据，但是还有几个 replica shard。primary shard 写入数据之后，会将数据同步到其他几个 replica shard 上去。</li><li>通过这个 replica 的方案，每个 shard 的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。</li><li>es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点其实就是干一些管理的工作的，比如维护索引元数据、负责切换 primary shard 和 replica shard 身份等。要是 master 节点宕机了，那么会重新选举一个节点为 master 节点。</li><li>如果是非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard。接着你要是修复了那个宕机机器，重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。</li><li>说得更简单一点，就是说如果某个非 master 节点宕机了。那么此节点上的 primary shard 不就没了。那好，master 会让 primary shard 对应的 replica shard（在其他机器上）切换为 primary shard。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。</li></ul><h1 id="es-写入数据的工作原理是什么啊？es-查询数据的工作原理是什么啊？底层的-lucene-介绍一下呗？倒排索引了解吗？"><a href="#es-写入数据的工作原理是什么啊？es-查询数据的工作原理是什么啊？底层的-lucene-介绍一下呗？倒排索引了解吗？" class="headerlink" title="es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？"></a>es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？</h1><h4 id="es-写数据过程"><a href="#es-写数据过程" class="headerlink" title="es 写数据过程"></a>es 写数据过程</h4><ul><li>客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。</li><li>coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。</li><li>实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。</li><li>coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。</li></ul><h4 id="es-读数据过程"><a href="#es-读数据过程" class="headerlink" title="es 读数据过程"></a>es 读数据过程</h4><ul><li>可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。</li><li>客户端发送请求到任意一个 node，成为 coordinate node。</li><li>coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin 随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。</li><li>接收请求的 node 返回 document 给 coordinate node。</li><li>coordinate node 返回 document 给客户端。</li></ul><h4 id="es-搜索数据过程"><a href="#es-搜索数据过程" class="headerlink" title="es 搜索数据过程"></a>es 搜索数据过程</h4><ul><li>es 最强大的是做全文检索，就是比如你有三条数据：<ul><li>java真好玩儿啊</li><li>java好难学啊</li><li>j2ee特别牛</li></ul></li><li>你根据 java 关键词来搜索，将包含 java的 document 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。</li><li>客户端发送请求到一个 coordinate node。</li><li>协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。</li><li>query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。</li><li>fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。</li><li>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。</li></ul><h4 id="写数据底层原理"><a href="#写数据底层原理" class="headerlink" title="写数据底层原理"></a>写数据底层原理</h4><ul><li>先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。</li><li>如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中，但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。</li><li>每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file，这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。</li><li>但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。</li><li>操作系统里面，磁盘文件其实都有一个东西，叫做 os cache，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 os cache，先进入操作系统级别的一个内存缓存中去。只要 buffer 中的数据被 refresh 操作刷入 os cache中，这个数据就可以被搜索到了。</li></ul><h5 id="为什么叫-es-是准实时的？"><a href="#为什么叫-es-是准实时的？" class="headerlink" title="为什么叫 es 是准实时的？"></a>为什么叫 es 是准实时的？</h5><ul><li>NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。</li><li>可以通过 es 的 restful api 或者 java api，手动执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 os cache中，让数据立马就可以被搜索到。</li><li>只要数据被输入 os cache 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。</li><li>重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 buffer 数据写入一个又一个新的 segment file 中去，每次 refresh 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 commit 操作。</li><li>commit 操作发生第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。然后，将一个 commit point 写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到磁盘文件中去。最后清空 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。</li><li>这个 commit 操作叫做 flush。默认 30 分钟自动执行一次 flush，但如果 translog 过大，也会触发 flush。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。</li><li>translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 translog 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。</li><li>translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会丢失 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。</li><li>实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的数据丢失。</li><li>总结一下，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。数据写入 segment file 之后，同时就建立好了倒排索引。</li></ul><h4 id="删除-更新数据底层原理"><a href="#删除-更新数据底层原理" class="headerlink" title="删除&#x2F;更新数据底层原理"></a>删除&#x2F;更新数据底层原理</h4><ul><li>如果是删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。</li><li>如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。</li><li>buffer 每 refresh 一次，就会产生一个 segment file，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 segment file 合并成一个，同时这里会将标识为 deleted 的 doc 给物理删除掉，然后将新的 segment file 写入磁盘，这里会写一个 commit point，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。</li></ul><h4 id="底层-lucene"><a href="#底层-lucene" class="headerlink" title="底层 lucene"></a>底层 lucene</h4><ul><li>简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。</li><li>通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。</li></ul><h4 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h4><ul><li>在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。</li><li>那么，倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。</li><li>举个栗子。<ul><li>有以下文档：<ul><li>DocId	Doc</li><li>1	谷歌地图之父跳槽 Facebook</li><li>2	谷歌地图之父加盟 Facebook</li><li>3	谷歌地图创始人拉斯离开谷歌加盟 Facebook</li><li>4	谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关</li><li>5	谷歌地图之父拉斯加盟社交网站 Facebook</li></ul></li></ul></li><li>对文档进行分词之后，得到以下倒排索引。<ul><li>WordId	Word	DocIds</li><li>1	谷歌	1,2,3,4,5</li><li>2	地图	1,2,3,4,5</li><li>3	之父	1,2,4,5</li><li>4	跳槽	1,4</li><li>5	Facebook	1,2,3,4,5</li><li>6	加盟	2,3,5</li><li>7	创始人	3</li><li>8	拉斯	3,5</li><li>9	离开	3</li><li>10	与	4</li><li>..	..	..</li></ul></li><li>另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。<br>那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 Facebook，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。</li><li>要注意倒排索引的两个重要细节：<ul><li>倒排索引中的所有词项对应一个或多个文档；</li><li>倒排索引中的词项根据字典顺序升序排列</li></ul></li><li>上面只是一个简单的栗子，并没有严格按照字典顺序升序排列。</li></ul><h1 id="es-在数据量很大的情况下（数十亿级别）如何提高查询效率啊？"><a href="#es-在数据量很大的情况下（数十亿级别）如何提高查询效率啊？" class="headerlink" title="es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？"></a>es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？</h1><ul><li>es 性能优化是没有什么银弹的，啥意思呢？就是不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景。也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。</li></ul><h4 id="性能优化的杀手锏——filesystem-cache"><a href="#性能优化的杀手锏——filesystem-cache" class="headerlink" title="性能优化的杀手锏——filesystem cache"></a>性能优化的杀手锏——filesystem cache</h4><ul><li>你往 es 里写的数据，实际上都写到磁盘文件里去了，查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。</li><li>es 的搜索引擎严重依赖于底层的 filesystem cache，你如果给 filesystem cache 更多的内存，尽量让内存可以容纳所有的 idx segment file 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。</li><li>性能差距究竟可以有多大？我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。但如果是走 filesystem cache，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。</li><li>这里有个真实的案例。某个公司 es 节点有 3 台机器，每台机器看起来内存很多，64G，总内存就是 64 * 3 &#x3D; 192G。每台机器给 es jvm heap 是 32G，那么剩下来留给 filesystem cache 的就是每台机器才 32G，总共集群里给 filesystem cache 的就是 32 * 3 &#x3D; 96G 内存。而此时，整个磁盘上索引数据文件，在 3 台机器上一共占用了 1T 的磁盘容量，es 数据量是 1T，那么每台机器的数据量是 300G。这样性能好吗？ filesystem cache 的内存才 100G，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差。</li><li>归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。</li><li>根据我们自己的生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，就是你要用来搜索的那些索引，如果内存留给 filesystem cache 的是 100G，那么你就将索引数据控制在 100G 以内，这样的话，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。</li><li>比如说你现在有一行数据。id,name,age …. 30 个字段。但是你现在搜索，只需要根据 id,name,age 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 90% 的数据是不用来搜索的，结果硬是占据了 es 机器上的 filesystem cache 的空间，单条数据的数据量越大，就会导致 filesystem cahce 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的少数几个字段就可以了，比如说就写入 es id,name,age 三个字段，然后你可以把其他的字段数据存在 mysql&#x2F;hbase 里，我们一般是建议用 es + hbase 这么一个架构。</li><li>hbase 的特点是适用于海量数据的在线存储，就是对 hbase 可以写入海量数据，但是不要做复杂的搜索，做很简单的一些根据 id 或者范围进行查询的这么一个操作就可以了。从 es 中根据 name 和 age 去搜索，拿到的结果可能就 20 个 doc id，然后根据 doc id 到 hbase 里去查询每个 doc id 对应的完整的数据，给查出来，再返回给前端。</li><li>写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms，可能你原来那么玩儿，1T 数据都放 es，会每次查询都是 5~10s，现在可能性能就会很高，每次查询就是 50ms。</li></ul><h4 id="数据预热"><a href="#数据预热" class="headerlink" title="数据预热"></a>数据预热</h4><ul><li>假如说，哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 filesystem cache 一倍，比如说你写入一台机器 60G 数据，结果 filesystem cache 就 30G，还是有 30G 数据留在了磁盘上。其实可以做数据预热。</li><li>举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 filesystem cache 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。</li><li>或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 filesystem cache 里去。</li><li>对于那些你觉得比较热的、经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据每隔一段时间，就提前访问一下，让数据进入 filesystem cache 里面去。这样下次别人访问的时候，性能一定会好很多。</li></ul><h4 id="冷热分离"><a href="#冷热分离" class="headerlink" title="冷热分离"></a>冷热分离</h4><ul><li>es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。</li><li>你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 filesystem cache 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。</li></ul><h4 id="document-模型设计"><a href="#document-模型设计" class="headerlink" title="document 模型设计"></a>document 模型设计</h4><ul><li>对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。</li><li>最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。</li><li>document 模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es 能支持的操作就那么多，不要考虑用 es 做一些它不好操作的事情。如果真的有那种操作，尽量在 document 模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如 join&#x2F;nested&#x2F;parent-child 搜索都要尽量避免，性能都很差的。</li></ul><h4 id="分页性能优化"><a href="#分页性能优化" class="headerlink" title="分页性能优化"></a>分页性能优化</h4><ul><li>es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。</li><li>分布式的，你要查第 100 页的 10 条数据，不可能说从 5 个 shard，每个 shard 就查 2 条数据，最后到协调节点合并成 10 条数据吧？你必须得从每个 shard 都查 1000 条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第 100 页的数据。你翻页的时候，翻的越深，每个 shard 返回的数据就越多，而且协调节点处理的时间越长，非常坑爹。所以用 es 做分页的时候，你会发现越翻到后面，就越是慢。</li><li>我们之前也是遇到过这个问题，用 es 作分页，前几页就几十毫秒，翻到 10 页或者几十页的时候，基本上就要 5~10 秒才能查出来一页数据了。</li><li>有什么解决方案吗？</li></ul><h5 id="不允许深度分页（默认深度分页性能很差）"><a href="#不允许深度分页（默认深度分页性能很差）" class="headerlink" title="不允许深度分页（默认深度分页性能很差）"></a>不允许深度分页（默认深度分页性能很差）</h5><ul><li>跟产品经理说，你系统不允许翻那么深的页，默认翻的越深，性能就越差。</li><li>类似于 app 里的推荐商品不断下拉出来一页一页的</li><li>类似于微博中，下拉刷微博，刷出来一页一页的，你可以用 scroll api，关于如何使用，自行上网搜索。</li><li>scroll 会一次性给你生成所有数据的一个快照，然后每次滑动向后翻页就是通过游标 scroll_id 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。</li><li>但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，不能随意跳到任何一页的场景。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。</li><li>初始化时必须指定 scroll 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。</li><li>除了用 scroll api，你也可以用 search_after 来做，search_after 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。</li></ul><h1 id="es-生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？"><a href="#es-生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？" class="headerlink" title="es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？"></a>es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？</h1><ul><li>示例<ul><li>es 生产集群我们部署了 5 台机器，每台机器是 6 核 64G 的，集群总内存是 320G。</li><li>我们 es 集群的日增量数据大概是 2000 万条，每天日增量数据大概是 500MB，每月增量数据大概是 6 亿，15G。目前系统已经运行了几个月，现在 es 集群里数据总量大概是 100G 左右。</li><li>目前线上有 5 个索引（这个结合你们自己业务来，看看自己有哪些数据可以放 es 的），每个索引的数据量大概是 20G，所以这个数据量之内，我们每个索引分配的是 8 个 shard，比默认的 5 个 shard 多了 3 个 shard。</li></ul></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/f17ba5c005d6.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/f17ba5c005d6.html" class="post-title-link" itemprop="url">Linux</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:14:12" itemprop="dateCreated datePublished" datetime="2023-12-20T16:14:12+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-24 11:46:25" itemprop="dateModified" datetime="2023-12-24T11:46:25+08:00">2023-12-24</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.6k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="使⽤两种命令创建⼀个⽂件？"><a href="#使⽤两种命令创建⼀个⽂件？" class="headerlink" title="使⽤两种命令创建⼀个⽂件？"></a>使⽤两种命令创建⼀个⽂件？</h1><ul><li>touch a.txt</li><li>vi a.txt</li><li>mkdir abc</li><li>cat &gt; a.txt 建⽴⼀⽂件，然后把接下来的键盘输⼊写⼊⽂件，直到按Ctrl+D为⽌.</li></ul><h1 id="硬链接和软连接的区别？"><a href="#硬链接和软连接的区别？" class="headerlink" title="硬链接和软连接的区别？"></a>硬链接和软连接的区别？</h1><h4 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h4><ul><li>⽂件有相同的 inode 及 data block；</li><li>只能对已存在的⽂件进⾏创建；</li><li>不能交叉⽂件系统进⾏硬链接的创建；</li><li>不能对⽬录进⾏创建，只可对⽂件创建；</li><li>删除⼀个硬链接⽂件并不影响其他有相同 inode 号的⽂件。</li></ul><h4 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h4><ul><li>软链接有⾃⼰的⽂件属性及权限等；</li><li>可对不存在的⽂件或⽬录创建软链接；</li><li>软链接可交叉⽂件系统；</li><li>软链接可对⽂件或⽬录创建；</li><li>创建软链接时，链接计数 i_nlink 不会增加；</li><li>删除软链接并不影响被指向的⽂件，但若被指向的原⽂件被删除，则相关软连接被称为死链接（即 dangling<br>link，若被指向路径⽂件被重新创建，死链接可恢复为正常的软链接）。</li></ul><h1 id="linux常⽤命令有哪些"><a href="#linux常⽤命令有哪些" class="headerlink" title="linux常⽤命令有哪些"></a>linux常⽤命令有哪些</h1><ul><li>查找关闭端⼝进程 netstat -nlp | grep :3306 kill pid</li><li>删除⽂件 rm -rf</li><li>查找⽇志 cat xx.log | grep ‘xxx’ | more</li><li>解压tar.gz tar -xzvf file.tar.gz</li><li>创建⽂件 touch filename cat &gt; filename</li><li>修改⽂件 vi</li></ul><h1 id="怎么查看⼀个java线程的资源耗⽤"><a href="#怎么查看⼀个java线程的资源耗⽤" class="headerlink" title="怎么查看⼀个java线程的资源耗⽤"></a>怎么查看⼀个java线程的资源耗⽤</h1><ul><li>linux下，所有的java内部线程，其实都对应了⼀个进程id，也就是说，linux上的jvm将java程序中的线程映射为操作系统进程。</li><li>jps -lvm或者ps -ef | grep java查看当前机器上运⾏的Java应⽤进程</li><li>top -Hp pid可以查看Java所有线程的资源耗⽤</li><li>printf “%x\n” pid等到线程ID的16进制</li><li>jstack Java应⽤进程ID | grep 线程ID的16进制</li></ul><h1 id="Load过⾼的可能性有哪些？"><a href="#Load过⾼的可能性有哪些？" class="headerlink" title="Load过⾼的可能性有哪些？"></a>Load过⾼的可能性有哪些？</h1><ul><li>cpu load的飙升，⼀⽅⾯可能和full gc的次数增⼤有关，⼀⽅⾯可能和死循环有关系</li></ul><h1 id="etc-hosts⽂件什么作⽤"><a href="#etc-hosts⽂件什么作⽤" class="headerlink" title="&#x2F;etc&#x2F;hosts⽂件什么作⽤"></a>&#x2F;etc&#x2F;hosts⽂件什么作⽤</h1><ul><li>在当前主机给ip设置别名，通过该别名可以访问到该ip地址，通过别名、ip访问的效果是⼀样的</li></ul><h1 id="如何快速的将⼀个⽂本中的”abc”转换成”xyz”？"><a href="#如何快速的将⼀个⽂本中的”abc”转换成”xyz”？" class="headerlink" title="如何快速的将⼀个⽂本中的”abc”转换成”xyz”？"></a>如何快速的将⼀个⽂本中的”abc”转换成”xyz”？</h1><ul><li>vi filename编辑⽂本，按Esc键，输⼊:%s&#x2F;abc&#x2F;xyz&#x2F;g</li></ul><h1 id="如何在log⽂件中搜索找出error的⽇志？"><a href="#如何在log⽂件中搜索找出error的⽇志？" class="headerlink" title="如何在log⽂件中搜索找出error的⽇志？"></a>如何在log⽂件中搜索找出error的⽇志？</h1><ul><li>cat xx.log | grep ‘error’</li></ul><h1 id="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件"><a href="#发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件" class="headerlink" title="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?"></a>发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?</h1><ul><li>find . -type f -size +100M | xargs du -h | sort -nr</li></ul><h1 id="Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）"><a href="#Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）" class="headerlink" title="Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）"></a>Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）</h1><h4 id="业务⽇志相关"><a href="#业务⽇志相关" class="headerlink" title="业务⽇志相关"></a>业务⽇志相关</h4><ul><li>less或者more</li><li>grep</li><li>tail -f filename</li><li>切忌vim直接打开⼤⽇志⽂件，因为会直接加载到内存的</li></ul><h4 id="数据库相关"><a href="#数据库相关" class="headerlink" title="数据库相关"></a>数据库相关</h4><ul><li>登录线上库，show processlist查看数据库连接情况</li></ul><h4 id="jvm相关："><a href="#jvm相关：" class="headerlink" title="jvm相关："></a>jvm相关：</h4><ul><li>jps显示java进程</li><li>jinfo实时查看和调整jvm参数</li><li>jstat监控jvm各种运⾏状态信息；</li><li>jstack(Stack Trace for Java)命令⽤于⽣成JVM进程当前时刻的线程的调⽤堆栈，可以⽤来定位线程间死锁、<br>锁等待、等待外部资源等</li><li>jmap(Memory Map for Java) 命令⽤于⽣成堆转储快照dump⽂件，除了这种⽅式还可以通过-<br>XX:HeapDumpOnOutOfMemoryError参数，可以在虚拟机发⽣OOM的时候⾃动⽣成堆的dump⽂件，或者kill -3<br>命令发出进程退出信号”吓唬”⼀下虚拟机，也能拿到dump⽂件。</li></ul><h4 id="oom问题："><a href="#oom问题：" class="headerlink" title="oom问题："></a>oom问题：</h4><ul><li>配置了-XX:+HeapDumpOnOutOfMemoryError, 在发⽣OOM的时候会在-XX:HeapDumpPath⽣成堆的dump⽂<br>件，结合MAT，可以对dump⽂件进⾏分析，查找出发⽣OOM的原因。</li><li>另外⼿动dump堆快照，可以使⽤命令jmap -dump:format&#x3D;b,file&#x3D;file_name pid 或者kill -3 pid</li></ul><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><ul><li>jps -v</li><li>jstack -l pid</li></ul><h4 id="线程block、线程数暴涨："><a href="#线程block、线程数暴涨：" class="headerlink" title="线程block、线程数暴涨："></a>线程block、线程数暴涨：</h4><ul><li>jstack -l pid |wc -l</li><li>jstack -l pid |grep “BLOCKED”|wc -l</li><li>jstack -l pid |grep “Waiting on condition”|wc -l<br>线程block问题⼀般是等待io、等待⽹络、等待监视器锁等造成，可能会导致请求超时、造成造成线程数暴涨导致系统502等。</li></ul><h4 id="服务器问题："><a href="#服务器问题：" class="headerlink" title="服务器问题："></a>服务器问题：</h4><h5 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h5><ul><li>top</li></ul><h5 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h5><ul><li>free -m -c10 -s1：<ul><li>-m：以MB为单位显示，其他的有-k -g -b</li><li>-s: 间隔多少秒持续观察内存使⽤状况</li><li>-c:观察多少次</li></ul></li><li>vmstat 1 10：1表示每隔1s输出⼀次,10 表示输出10次<ul><li>r: 运⾏队列中进程数量，这个值也可以判断是否需要增加CPU。（⻓期⼤于1）</li><li>b: 等待IO的进程数量。</li></ul></li></ul><h5 id="io"><a href="#io" class="headerlink" title="io"></a>io</h5><ul><li>iostat -m 1 10：<ul><li>-m：某些使⽤block为单位的列强制使⽤MB为单位</li><li>1 10：数据显示每隔1秒刷新⼀次，共显示10次</li></ul></li></ul><h5 id="⽹络"><a href="#⽹络" class="headerlink" title="⽹络"></a>⽹络</h5><ul><li>netstat -antp：<ul><li>-a (all)显示所有选项，默认不显示LISTEN相关</li><li>-t (tcp)仅显示tcp相关选项</li><li>-u (udp)仅显示udp相关选项</li><li>-n 拒绝显示别名，能显示数字的全部转化成数字。</li><li>-l 仅列出有在 Listen (监听) 的服服务状态</li><li>-p 显示建⽴相关链接的程序名</li></ul></li></ul><h1 id="Thread-dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）"><a href="#Thread-dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）" class="headerlink" title="Thread dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）"></a>Thread dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）</h1><h4 id="Thread-Dump-能诊断的问题"><a href="#Thread-Dump-能诊断的问题" class="headerlink" title="Thread Dump 能诊断的问题"></a>Thread Dump 能诊断的问题</h4><ul><li>查找内存泄露，常⻅的是程序⾥load⼤量的数据到缓存；</li><li>发现死锁线程；</li></ul><h4 id="如何抓取Thread-Dump信息："><a href="#如何抓取Thread-Dump信息：" class="headerlink" title="如何抓取Thread Dump信息："></a>如何抓取Thread Dump信息：</h4><ul><li>⼀般当服务器挂起,崩溃或者性能底下时,就需要抓取服务器的线程堆栈(Thread Dump)⽤于后续的分析. 在实际运⾏中，往往⼀次 dump的信息，还不⾜以确认问题。为了反映线程状态的动态变化，需要接连多次做threaddump，每次间隔10-20s，建议⾄少产⽣三次 dump信息，如果每次 dump都指向同⼀个问题，我们才确定问题的典型性。</li></ul><h4 id="linux命令获取"><a href="#linux命令获取" class="headerlink" title="linux命令获取"></a>linux命令获取</h4><ul><li>ps –ef | grep java</li><li>kill -3<pid></pid></li></ul><h4 id="jdk⾃带⼯具获取"><a href="#jdk⾃带⼯具获取" class="headerlink" title="jdk⾃带⼯具获取"></a>jdk⾃带⼯具获取</h4><ul><li>jps 或 ps –ef|grepjava (获取PID)</li><li>jstack [-l ]<pid>| tee -a jstack.log (获取ThreadDump)</pid></li></ul><h1 id="如何查看Java应⽤的线程信息？"><a href="#如何查看Java应⽤的线程信息？" class="headerlink" title="如何查看Java应⽤的线程信息？"></a>如何查看Java应⽤的线程信息？</h1><ul><li>通过top命令拿到线程的pid后使⽤jstack命令</li></ul><h1 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h1><ul><li>wc -l</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/fca1d6209800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/fca1d6209800.html" class="post-title-link" itemprop="url">计算机网络</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:11:54" itemprop="dateCreated datePublished" datetime="2023-12-20T16:11:54+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-30 14:24:29" itemprop="dateModified" datetime="2023-12-30T14:24:29+08:00">2023-12-30</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">网络</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>9.3k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>8 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="TCP建⽴连接的过程。"><a href="#TCP建⽴连接的过程。" class="headerlink" title="TCP建⽴连接的过程。"></a>TCP建⽴连接的过程。</h1><h4 id="三次握⼿"><a href="#三次握⼿" class="headerlink" title="三次握⼿"></a>三次握⼿</h4><ul><li>第⼀次握⼿(客户端发送syn包到服务器端)：客户端发送syn包到服务器端，进⼊syn_send状态，等待服务器端的确认；</li><li>第⼆次握⼿(服务器返回syn+ack包给客户端)：服务器端收到客户端的syn包，发送syn+ack包给客户端，进⼊syn_recv状态；</li><li>第三次握⼿(客服端返回ack包给服务端)：客户端收到服务器端的syn+ack包，发送个ack包到服务器端，⾄此，客户端与服务器端进⼊established状态；</li><li>握⼿过程中传送的包不包含任何数据，连接建⽴后才会开始传送数据，理想状态下，TCP连接⼀旦建⽴，在通信双⽅的任何⼀⽅主动关闭连接前，TCP连接都会⼀直保持下去。</li></ul><h1 id="TCP断开连接的过程。"><a href="#TCP断开连接的过程。" class="headerlink" title="TCP断开连接的过程。"></a>TCP断开连接的过程。</h1><h4 id="四次握⼿"><a href="#四次握⼿" class="headerlink" title="四次握⼿"></a>四次握⼿</h4><ul><li>第⼀次握⼿：主动关闭⽅发送fin包到被动关闭⽅，告诉被动关闭⽅我不会再给你发送数据了；</li><li>第⼆次握⼿：被动关闭⽅收到syn包，发送ack给对⽅，确认序号为收到序号+1；</li><li>第三次握⼿：被动关闭⽅也也发送fin包给主动关闭⽅，告诉对⽅我也不会给你发送数据了；</li><li>第四次握⼿：主动关闭⽅收到syn包，发送ack给对⽅，⾄此，完成四次握⼿；</li></ul><h1 id="浏览器发⽣302跳转背后的逻辑"><a href="#浏览器发⽣302跳转背后的逻辑" class="headerlink" title="浏览器发⽣302跳转背后的逻辑"></a>浏览器发⽣302跳转背后的逻辑</h1><ul><li>浏览器在原请求地址的响应的Location域找到要跳转的URI执⾏跳转。</li></ul><h4 id="浏览器输⼊URL后发⽣了什么"><a href="#浏览器输⼊URL后发⽣了什么" class="headerlink" title="浏览器输⼊URL后发⽣了什么"></a>浏览器输⼊URL后发⽣了什么</h4><ul><li>DNS域名解析；</li><li>建⽴TCP连接；</li><li>发送HTTP请求；</li><li>服务器处理请求；</li><li>返回响应结果；</li><li>关闭TCP连接；</li><li>浏览器解析HTML；</li><li>浏览器布局渲染；</li></ul><h1 id="HTTP协议的交互流程。-HTTP和HTTPS的差异，-SSL的交互流程？"><a href="#HTTP协议的交互流程。-HTTP和HTTPS的差异，-SSL的交互流程？" class="headerlink" title="HTTP协议的交互流程。 HTTP和HTTPS的差异， SSL的交互流程？"></a>HTTP协议的交互流程。 HTTP和HTTPS的差异， SSL的交互流程？</h1><h4 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h4><ul><li>建⽴TCP连接；</li><li>发送HTTP请求；</li><li>服务器处理请求；</li><li>返回响应结果；</li><li>关闭TCP连接；</li></ul><h5 id="http三次握⼿："><a href="#http三次握⼿：" class="headerlink" title="http三次握⼿："></a>http三次握⼿：</h5><ul><li>第⼀次握⼿：客户端发送syn包(syn&#x3D;j)到服务器，并进⼊SYN_SEND状态，等待服务器确认；</li><li>第⼆次握⼿：服务器收到syn包，必须确认客户的SYN（ack&#x3D;j+1），同时⾃⼰也发送⼀个SYN包（syn&#x3D;k），即<br>SYN+ACK包，此时服务器进⼊SYN_RECV状态；</li><li>第三次握⼿：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack&#x3D;k+1)，此包发送完毕，客户端和服务器进⼊ESTABLISHED状态，完成三次握⼿。</li></ul><h4 id="HTTPS协议"><a href="#HTTPS协议" class="headerlink" title="HTTPS协议"></a>HTTPS协议</h4><ul><li>TTPS协议就是基于SSL的HTTP协议</li><li>HTTPS使⽤与HTTP不同的端⼝（HTTPS80 ， HTTPSS443）</li><li>提供了身份验证与加密通信⽅法，被⼴泛⽤于互联⽹上安全敏感的通信。</li><li>客户端请求SSL连接，并将⾃⼰⽀持的加密规则发给⽹站。</li><li>服务器端将⾃⼰的身份信息以证书形式发回给客户端。证书⾥⾯包含了⽹站地址，加密公钥，以及证书的颁发机构。</li><li>获得证书后，客户要做以下⼯作<ul><li>验证证书合法性</li><li>如果证书受信任，客户端会⽣成⼀串随机数的密码，并⽤证书提供的公钥进⾏加密。</li><li>将加密好的随机数发给服务器。</li><li>获得到客户端发的加密了的随机数之后，服务器⽤⾃⼰的私钥进⾏解密，得到这个随机数，把这个随机数作为对称加密的密钥。（利⽤⾮对称加密传输对称加密的密钥）</li><li>之后服务器与客户之间就可以⽤随机数对各⾃的信息进⾏加密，解密。</li></ul></li><li>注意的是：证书是⼀个公钥，这个公钥是进⾏加密⽤的。⽽私钥是进⾏解密⽤的。公钥任何都知道，私钥只有⾃⼰知道。这是⾮对称加密。⽽对称加密就是钥匙只有⼀把，我们都知道。</li><li>之所以⽤到对称加密，是因为对称加密的速度更快。⽽⾮对称加密的可靠性更⾼。</li><li>客户端请求–服务端发送证书（公钥）–客户端验证证书，并⽣成随机数，通过公钥加密后发送给服务端–服务端⽤私钥解密出随机数–对称加密传输数据。</li></ul><h4 id="HTTP与HTTPS的区别"><a href="#HTTP与HTTPS的区别" class="headerlink" title="HTTP与HTTPS的区别"></a>HTTP与HTTPS的区别</h4><ul><li>HTTPS协议需要申请证书。</li><li>HTTP是明⽂传输；HTTPS使⽤的是具有安全性的SSL加密传输协议</li><li>HTTP端⼝是80；HTTPS端⼝号是443</li><li>HTTP连接简单⽆状态；HTTPS由SSL+HTTP协议构件的可进⾏加密传输、身份验证的⽹络协议。</li></ul><h4 id="Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解"><a href="#Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解" class="headerlink" title="Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解?"></a>Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解?</h4><ul><li>Http是⼀种协议，Rest是⼀种软件架构⻛格。</li><li>URL定位资源，⽤HTTP动词（GET,POST,DELETE,DETC）描述操作。</li><li>GET表示查询、POST表示新建、PUT表示更新、DELETE表示删除等。<ul><li>GET &#x2F;api&#x2F;v1&#x2F;user 获取⽤户列表</li><li>GET &#x2F;api&#x2F;v1&#x2F;user&#x2F;1 获取ID为1的⽤户</li><li>POST &#x2F;api&#x2F;v1&#x2F;user 新建⽤户</li><li>PUT &#x2F;api&#x2F;v1&#x2F;user&#x2F;1 更新ID为1的⽤户信息</li><li>DELETE &#x2F;api&#x2F;v1&#x2F;user&#x2F;1 删除ID为1的⽤户</li></ul></li><li>概念：REST（英⽂：Representational State Transfer，简称REST，表现层状态转化），指的是⼀组架构约束条件和原则。满⾜这些约束条件和原则的应⽤程序或设计就是 RESTful。</li><li>⼀种软件架构⻛格，设计⻛格⽽不是标准，只是提供了⼀组设计原则和约束条件。它主要⽤于客户端和服务器交互类的软件。基于这个⻛格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。</li><li>Restful架构：<ul><li>每⼀个URI代表⼀种资源；</li><li>客户端和服务器之间，传递这种资源的某种表现层；</li><li>客户端通过四个HTTP动词(GET⽤来获取资源，POST⽤来新建资源（也可以⽤于更新资源），PUT⽤来更新资源，DELETE⽤来删除资源。)，对服务器端资源进⾏操作，实现”表现层状态转化”。</li></ul></li></ul><h1 id="TCP的滑动窗⼝协议有什么⽤？讲讲原理。"><a href="#TCP的滑动窗⼝协议有什么⽤？讲讲原理。" class="headerlink" title="TCP的滑动窗⼝协议有什么⽤？讲讲原理。"></a>TCP的滑动窗⼝协议有什么⽤？讲讲原理。</h1><ul><li>滑动窗⼝协议是传输层进⾏流控的⼀种措施，接收⽅通过通告发送⽅⾃⼰的窗⼝⼤⼩，从⽽控制发送⽅的发送速度，从⽽达到防⽌发送⽅发送速度过快⽽导致来不及接受。</li></ul><h1 id="HTTP协议都有哪些⽅法？"><a href="#HTTP协议都有哪些⽅法？" class="headerlink" title="HTTP协议都有哪些⽅法？"></a>HTTP协议都有哪些⽅法？</h1><ul><li>GET 请求获取由Request-URI所标识的资源。</li><li>POST 在Request-URI所标识的资源后附加新的数据。</li><li>HEAD 请求获取由Request-URI所标识的资源的响应消息报头。</li><li>OPTIONS 请求查询服务器的性能，或查询与资源相关的选项和需求。</li><li>PUT 请求服务器存储⼀个资源，并⽤Request-URI作为其标识。</li><li>DELETE 请求服务器删除由Request-URI所标识的资源。</li><li>TRACE 请求服务器回送收到的请求信息，主要⽤语测试或诊断。</li></ul><h1 id="交换机与路由器的区别？"><a href="#交换机与路由器的区别？" class="headerlink" title="交换机与路由器的区别？"></a>交换机与路由器的区别？</h1><h4 id="⼯作层次不同"><a href="#⼯作层次不同" class="headerlink" title="⼯作层次不同"></a>⼯作层次不同</h4><ul><li>最初的交换机⼯作在OSI模型中的数据链路层，⼯作原理简单</li><li>路由器⼯作在OSI模型中的⽹络层，得更多协议信息，做更智能的转发决策</li></ul><h4 id="数据转发所依据的对象不同"><a href="#数据转发所依据的对象不同" class="headerlink" title="数据转发所依据的对象不同"></a>数据转发所依据的对象不同</h4><ul><li>交换机是利⽤物理地址（MAC地址），确定转发的⽬的地址。（MAC固化硬件，⼀般不可更改）</li><li>路由器是利⽤IP地址，确定转发的⽬的地址。（IP通常为⽹关或p系统⾃动分配的）</li></ul><h4 id="是否可以分割⼴播域"><a href="#是否可以分割⼴播域" class="headerlink" title="是否可以分割⼴播域"></a>是否可以分割⼴播域</h4><ul><li>传统的交换机可以分割冲突域，不能分割⼴播域，⽽路由器可以分割⼴播域</li><li>由交换机连接的⽹段仍然属于同⼀⼴播域，⼴播数据报会在交换机连接的所有⽹段上传播，某些情况导致通信拥堵和安全漏洞。</li><li>连接到路由器上的⽹段被分配成不同的⼴播域，所以，⼴播数据不穿过路由器</li><li>虽然三层交换机可以分割⼴播域，但是⼦⼴播域之间不能通信，还是需要路由器</li></ul><h4 id="路由器提供了防⽕墙的服务"><a href="#路由器提供了防⽕墙的服务" class="headerlink" title="路由器提供了防⽕墙的服务"></a>路由器提供了防⽕墙的服务</h4><ul><li>路由器仅仅转发特定地址的数据包，不传送不⽀持路由协议的数据包，不传送未知⽬标⽹络数据包，从⽽可以防⽌⼴播⻛暴</li></ul><h4 id="表"><a href="#表" class="headerlink" title="表"></a>表</h4><ul><li>⼆层交换机上存在MAC表，三层交换机上存在路由表、MAC表、ARP表，路由器上存在路由表和ARP表。</li><li>总之，交换机在具体的城域⽹中扮演着VLAN透传的⻆⾊，就是桥。</li><li>路由器的每⼀个端⼝都是⼀个独⽴的⼴播域和冲突域，⽽交换机是只有⼀个⼴播域和端⼝数量的冲突域。</li></ul><h1 id="Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？"><a href="#Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？" class="headerlink" title="Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？"></a>Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？</h1><h4 id="socket⽹络通信"><a href="#socket⽹络通信" class="headerlink" title="socket⽹络通信"></a>socket⽹络通信</h4><ul><li>NIO流以及多线程处理技术：</li><li>BIO:阻塞式，线程池初始时创建⼀定量线程，超过则等待；</li><li>NIO:⾮阻塞式，不同的线程⼲专业的事情，提⾼系统吞吐量；</li><li>NIO+异步处理：让少量的线程做⼤量的事情；</li></ul><h4 id="Mina"><a href="#Mina" class="headerlink" title="Mina"></a>Mina</h4><ul><li>Apache Mina是⼀个能够帮助⽤户开发⾼性能和⾼伸缩性⽹络应⽤程序的框架。</li><li>它通过Java nio技术基于TCP&#x2F;IP和UDP&#x2F;IP协议提供了抽象的、事件驱动的、异步的API</li><li>采⽤⾮阻塞⽅式的异步传输，⽀持批量传输数据</li><li>mina框架简单⾼效，完成了底层的线程管理，内置编码器能够满⾜⼤多数⽤户的需求，省去了消息编码和解码的⼯作。</li></ul><h4 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h4><ul><li>本质是JBoss开发的⼀个jar包，⽬的是开发⾼性能、⾼可靠性的⽹络服务和客户端服务</li><li>提供异步⾮阻塞的、事件驱动的⽹络应⽤程序的NIO框架和⼯具</li><li>处理socket</li><li>通过Future-Listener机制，⽤户可以⽅便的主动获取或者通过通知机制获得IO操作结果。</li></ul><h1 id="http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）"><a href="#http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）" class="headerlink" title="http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）"></a>http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）</h1><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul><li>HTTP协议是Hyper Text Transfer Protocol（超⽂本传输协议）的缩写,是⽤于从万维⽹（WWW:World Wide Web ）服务器传输超⽂本到本地浏览器的传送协议。</li><li>HTTP是⼀个基于TCP&#x2F;IP通信协议来传递数据（HTML ⽂件, 图⽚⽂件, 查询结果等）。</li><li>HTTP是⼀个属于应⽤层的⾯向对象的协议，由于其简捷、快速的⽅式，适⽤于分布式超媒体信息系统。它于1990年提出，经过⼏年的使⽤与发展，得到不断地完善和扩展。⽬前在WWW中使⽤的是HTTP&#x2F;1.0的第六版，HTTP&#x2F;1.1的规范化⼯作正在进⾏之中，⽽且HTTP-NG(Next Generation of HTTP)的建议已经提出。</li><li>HTTP协议⼯作于客户端-服务端架构为上。</li><li>浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求</li><li>Web服务器根据接收到的请求后，向客户端发送响应信息。</li></ul><h4 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h4><ul><li>简单快速：客户向服务器请求服务时，只需传送请求⽅法和路径。请求⽅法常⽤的有GET、HEAD、POST。每种⽅法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模⼩，因⽽通信速度很快。</li><li>灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。</li><li>⽆连接：⽆连接的含义是限制每次连接只处理⼀个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采⽤这种⽅式可以节省传输时间。</li><li>⽆状态：HTTP协议是⽆状态协议。⽆状态是指协议对于事务处理没有记忆能⼒。缺少状态意味着如果后续处理需要前⾯的信息，则它必须重传，这样可能导致每次连接传送的数据量增⼤。另⼀⽅⾯，在服务器不需要先前信息时它的应答就较快。</li><li>⽀持B&#x2F;S及C&#x2F;S模式。</li></ul><h1 id="get与post区别"><a href="#get与post区别" class="headerlink" title="get与post区别"></a>get与post区别</h1><ul><li>表单的method如果为get,那么所有的参数信息都会显示在浏览器的地址栏，当我们使⽤浏览器地址栏输⼊⽹址的⽅式来发送请求时,那么该请求⼀定是get⽅式</li><li>对于get⽅式,底层是将所有参数附加在请求资源的后⾯⼀起传递的，对于post⽅式,底层是将所有参数附加在请求参数的最后⼀⾏的下⼀⾏的下⼀⾏，Get请求的数据是被附在url之后（HTTP协议头中），POST请求数据则放置在HTTP包的包体head中；</li><li>对于get,post⽅式,servlet不同处理：doGet()，doPost();</li><li>浏览器处理：重复访问使⽤GET⽅法请求的⻚⾯，浏览器会使⽤缓存处理后续请求。使⽤POST⽅法的form提交时，浏览器基于POST将产⽣永久改变的假设，将让⽤户进⾏提交确认。</li></ul><h1 id="rpc和http的区别，使⽤场景"><a href="#rpc和http的区别，使⽤场景" class="headerlink" title="rpc和http的区别，使⽤场景"></a>rpc和http的区别，使⽤场景</h1><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><h5 id="传输协议"><a href="#传输协议" class="headerlink" title="传输协议"></a>传输协议</h5><ul><li>RPC，可以基于TCP协议，也可以基于HTTP协议</li><li>HTTP，基于HTTP协议</li></ul><h5 id="传输效率"><a href="#传输效率" class="headerlink" title="传输效率"></a>传输效率</h5><ul><li>RPC，使⽤⾃定义的TCP协议，可以让请求报⽂体积更⼩，或者使⽤HTTP2协议，也可以很好的减少报⽂的体积，提⾼传输效率</li><li>HTTP，如果是基于HTTP1.1的协议，请求中会包含很多⽆⽤的内容，如果是基于HTTP2.0，那么简单的封装以下是可以作为⼀个RPC来使⽤的，这时标准RPC框架更多的是服务治理性能消耗，主要在于序列化和反序列化的耗时<br>RPC，可以基于thrift实现⾼效的⼆进制传输</li><li>HTTP，⼤部分是通过json来实现的，字节⼤⼩和序列化耗时都⽐thrift要更消耗性能</li></ul><h5 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h5><ul><li>RPC，基本都⾃带了负载均衡策略</li><li>HTTP，需要配置Nginx，HAProxy来实现</li></ul><h5 id="服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）"><a href="#服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）" class="headerlink" title="服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）"></a>服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）</h5><ul><li>RPC，能做到⾃动通知，不影响上游</li><li>HTTP，需要事先通知，修改Nginx&#x2F;HAProxy配置</li></ul><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>RPC主要⽤于公司内部的服务调⽤，性能消耗低，传输效率⾼，服务治理⽅便。</li><li>HTTP主要⽤于对外的异构环境，浏览器接⼝调⽤，APP接⼝调⽤，第三⽅接⼝调⽤等。</li></ul><h1 id="说说TCP-UDP和socket-Http之间联系和区别"><a href="#说说TCP-UDP和socket-Http之间联系和区别" class="headerlink" title="说说TCP,UDP和socket,Http之间联系和区别"></a>说说TCP,UDP和socket,Http之间联系和区别</h1><h4 id="TCP协议"><a href="#TCP协议" class="headerlink" title="TCP协议"></a>TCP协议</h4><ul><li>TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议，由IETF的RFC 793定义。</li><li>在简化的计算机网络OSI模型中，它完成第四层传输层所指定的功能，用户数据报协议（UDP）是同一层内另一个重要的传输协议。</li><li>在因特网协议族（Internet protocol suite）中，TCP层是位于IP层之上，应用层之下的中间层。</li><li>不同主机的应用层之间经常需要可靠的、像管道一样的连接，但是IP层不提供这样的流机制，而是提供不可靠的包交换。</li></ul><h5 id="TCP的优点"><a href="#TCP的优点" class="headerlink" title="TCP的优点"></a>TCP的优点</h5><ul><li>可靠，稳定</li><li>TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。</li></ul><h5 id="TCP的缺点"><a href="#TCP的缺点" class="headerlink" title="TCP的缺点"></a>TCP的缺点</h5><ul><li>慢，效率低，占用系统资源高，易被攻击</li><li>TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。<br>由于TCP存在确认机制和三次握手机制，这些是导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。</li></ul><h5 id="TCP应用场景"><a href="#TCP应用场景" class="headerlink" title="TCP应用场景"></a>TCP应用场景</h5><ul><li>当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。</li><li>在日常生活中，常见使用TCP协议的应用比如：浏览器使用HTTP，Outlook使用POP、SMTP，QQ文件传输等。</li></ul><h4 id="UDP协议"><a href="#UDP协议" class="headerlink" title="UDP协议"></a>UDP协议</h4><ul><li>U- DP 是User Datagram Protocol的简称， 中文名是用户数据报协议，是OSI（Open System Interconnection，开放式系统互联） 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，IETF RFC 768是UDP的正式规范。UDP在IP报文的协议号是17。</li></ul><h5 id="UDP的优点"><a href="#UDP的优点" class="headerlink" title="UDP的优点"></a>UDP的优点</h5><ul><li>快，比TCP稍安全</li><li>UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击……</li></ul><h5 id="UDP的缺点"><a href="#UDP的缺点" class="headerlink" title="UDP的缺点"></a>UDP的缺点</h5><ul><li>不可靠，不稳定</li><li>因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。</li></ul><h5 id="UDP应用场景"><a href="#UDP应用场景" class="headerlink" title="UDP应用场景"></a>UDP应用场景</h5><ul><li>当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。在日常生活中，常见使用UDP协议的应用比如：QQ语音、QQ视频、TFTP等。</li><li>TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。</li><li>TCP&#x2F;IP是个协议组，可分为三个层次：网络层、传输层和应用层。<ul><li>在网络层有：IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议。</li><li>在传输层中有：TCP协议与UDP协议。</li><li>在应用层有：FTP、HTTP、TELNET、SMTP、DNS等协议。</li></ul></li><li>因此，HTTP本身就是一个协议，是从Web服务器传输超文本到本地浏览器的传送协议。</li><li>TCP和UDP是FTP，HTTP和SMTP之类使用的传输层协议。</li><li>虽然TCP和UDP都是用来传输其他协议的，它们却有一个显著的不同：TCP提供有保证的数据传输，而UDP不提供。这意味着TCP有一个特殊的机制来确保数据安全的不出错的从一个端点传到另一个端点，而UDP不提供任何这样的保证。</li></ul><h4 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h4><ul><li>HTTP（超文本传输协议）是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。</li><li>HTTP是短连接：客户端发送请求都需要服务器端回送响应.请求结束后，主动释放链接，因此为短连接。通常的做法是，不需要任何数据，也要保持每隔一段时间向服务器发送”保持连接”的请求。这样可以保证客户端在服务器端是”上线”状态。</li><li>HTTP连接使用的是”请求-响应”方式，不仅在请求时建立连接，而且客户端向服务器端请求后，服务器才返回数据。</li></ul><h4 id="Socket协议"><a href="#Socket协议" class="headerlink" title="Socket协议"></a>Socket协议</h4><ul><li>网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。</li><li>建立网络通信连接至少要一对端口号（socket）。socket本质是编程接口（API），对TCP&#x2F;IP的封装，TCP&#x2F;IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口；HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。</li></ul><h1 id="TCP为何采用三次握手来建立连接，若采用二次握手可以么，请说明理由"><a href="#TCP为何采用三次握手来建立连接，若采用二次握手可以么，请说明理由" class="headerlink" title="TCP为何采用三次握手来建立连接，若采用二次握手可以么，请说明理由"></a>TCP为何采用三次握手来建立连接，若采用二次握手可以么，请说明理由</h1><ul><li>三次握手是为了防止已失效的连接请求再次传送到服务器端</li><li>二次握手不可行，因为：如果由于网络不稳定，虽然客户端以前发送的连接请求已到达服务方，但服务方的同意连接的应答未能到达客户端。则客户方要重新发送连接请求，若采用二次握手，服务方收到重传的请求连接后，会以为是新的请求，就会发送同意连接报文，并新开进程提供服务，这样会造成服务方资源的无谓浪费。</li></ul><h1 id="HTTP协议工作原理及其特点"><a href="#HTTP协议工作原理及其特点" class="headerlink" title="HTTP协议工作原理及其特点"></a>HTTP协议工作原理及其特点</h1><ul><li>超文本传输协议（HTTP：Hypertext Transport Protocol）是万维网应用层的协议，它通过两个程序实现：一个是客户端程序（各种浏览器），另一个是服务器 （常称Web服务器）。这两个通常运行在不同的主机上，通过交换报文来完成网页请求和响应，报文可简单分为请求报文和响应报文。</li><li>工作原理（流程）：<ul><li>客户机与服务器建立连接后，浏览器可以向web服务器发送请求并显示收到的网页，当用户在浏览器地址栏中输入一个URL或点击一个超连接时，浏览器就向服务器发出了HTTP请求，请求方式的格式为：统一资源标识符、协议版本号，后边是MIME（Multipurpose Internet Mail Extensions）信息包括请求修饰符、客户机信息和可能的内容</li><li>该请求被送往由URL指定的WEB服务器，WEB服务器接收到请求后，进行相应反映，其格式为：一个状态行包括信息的协议版本号、一个成功或错误的代码，后边服务器信息、实体信息和可能的内容</li><li>即以HTTP规定的格式送回所要求的文件或其他相关信息，再由用户计算机上的浏览器负责解释和显示</li></ul></li><li>特点：<ul><li>支持客户&#x2F;服务器模式。</li><li>简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。</li><li>灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。</li><li>无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。</li><li>无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。</li></ul></li></ul><h1 id="介绍OSI七层模型和TCP-IP模型"><a href="#介绍OSI七层模型和TCP-IP模型" class="headerlink" title="介绍OSI七层模型和TCP&#x2F;IP模型"></a>介绍OSI七层模型和TCP&#x2F;IP模型</h1><ul><li>OSI(Open System Interconnection)，开放式系统互联参考模型</li><li>是一个逻辑上的定义，一个规范，它把网络协议从逻辑上分为了7层</li><li>每一层都有相关、相对应的物理设备，比如常规的路由器是三层交换设备，常规的交换机是二层交换设备</li><li>OSI七层模型是一种框架性的设计方法，建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题，其最主要的功能就是帮助不同类型的主机实现数据传输</li><li>它的最大优点是将服务、接口和协议这三个概念明确地区分开来，通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯。</li><li>TCP&#x2F;IP协议是Internet最基本的协议、Internet国际互联网络的基础，主要由网络层的IP协议和传输层的TCP协议组成</li><li>TCP&#x2F;IP 定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准</li><li>协议采用了4层的层级结构，每一层都呼叫它的下一层所提供的协议来完成自己的需求。</li><li>ISO制定的OSI参考模型的过于庞大、复杂招致了许多批评。伴随着互联网的流行，其本身所采用的TCP&#x2F;IP协议栈获得了更为广泛的应用和认可。在TCP&#x2F;IP参考模型中，去掉了OSI参考模型中的会话层和表示层（这两层的功能被合并到应用层实现）。同时将OSI参考模型中的数据链路层和物理层合并为主机到网络层</li></ul><h1 id="TCP协议和UDP协议的比较"><a href="#TCP协议和UDP协议的比较" class="headerlink" title="TCP协议和UDP协议的比较"></a>TCP协议和UDP协议的比较</h1><ul><li>TCP和UDP是TCP&#x2F;IP协议栈中传输层的两个协议，它们使用IP路由功能把数据包发送到目的地，从而为应用程序及应用层协议（包括：HTTP、SMTP、SNMP、FTP和Telnet）提供网络服务。</li><li>TCP的server和client之间通信就好比两个人打电话，需要互相知道对方的电话号码，然后开始对话。所以在两者的连接过程中间需要指定端口和地址。</li><li>UDP的server和client之间的通信就像两个人互相发信。我只需要知道对方的地址，然后就发信过去。对方是否收到我不知道，也不需要专门对口令似的来建立连接</li><li>具体区别如下：<ul><li>TCP是面向连接的传输。UDP是无连接的传输</li><li>TCP有流量控制、拥塞控制，检验数据数据按序到达，而UDP则相反。</li><li>TCP的路由选择只发生在建立连接的时候，而UDP的每个报文都要进行路由选择</li><li>TCP是可靠性传输，他的可靠性是由超时重发机制实现的，而UDP则是不可靠传输</li><li>UDP因为少了很多控制信息，所以传输速度比TCP速度快</li><li>TCP适合用于传输大量数据，UDP适合用于传输小量数据</li></ul></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/fe062138c36d.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/fe062138c36d.html" class="post-title-link" itemprop="url">Memcached</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:10:21" itemprop="dateCreated datePublished" datetime="2023-12-20T16:10:21+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-25 22:51:49" itemprop="dateModified" datetime="2023-12-25T22:51:49+08:00">2023-12-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a> </span></span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5.2k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="memcached是怎么工作的？"><a href="#memcached是怎么工作的？" class="headerlink" title="memcached是怎么工作的？"></a>memcached是怎么工作的？</h1><ul><li>Memcached的神奇来自两阶段哈希（two-stage hash）</li><li>Memcached就像一个巨大的、存储了很多&lt;key,value&gt;对的哈希表。通过key，可以存储或查询任意的数据。 </li><li>客户端可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后memcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）。 </li><li>举个列子，假设有3个客户端1, 2, 3，3台memcached A, B, C：Client 1想把数据”barbaz”以key “foo”存储。Client 1首先参考节点列表（A, B, C），计算key “foo”的哈希值，假设memcached B被选中。接着，Client 1直接connect到memcached B，通过key “foo”把数据”barbaz”存储进去。Client 2使用与Client 1相同的客户端库（意味着阶段一的哈希算法相同），也拥有同样的memcached列表（A, B, C）。 于是，经过相同的哈希计算（阶段一），Client 2计算出key “foo”在memcached B上，然后它直接请求memcached B，得到数据”barbaz”。 </li><li>各种客户端在memcached中数据的存储形式是不同的（perl Storable, php serialize, java hibernate, JSON等）。一些客户端实现的哈希算法也不一样。但是，memcached服务器端的行为总是一致的。 </li><li>最后，从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。这种架构可以很好地解决C10K problem ，并具有极佳的可扩展性。</li></ul><p> </p><h1 id="memcached最大的优势是什么？"><a href="#memcached最大的优势是什么？" class="headerlink" title="memcached最大的优势是什么？"></a>memcached最大的优势是什么？</h1><ul><li>Memcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中</li><li>由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中</li><li>memcached之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。memcached的集群很好用。内存不够了？增加几台 memcached吧；CPU不够用了？再增加几台吧；有多余的内存？在增加几台吧，不要浪费了。 </li><li>基于memcached的基本原则，可以相当轻松地构建出不同类型的缓存架构。</li></ul><h1 id="memcached和MySQL的query-cache相比，有什么优缺点？"><a href="#memcached和MySQL的query-cache相比，有什么优缺点？" class="headerlink" title="memcached和MySQL的query cache相比，有什么优缺点？"></a>memcached和MySQL的query cache相比，有什么优缺点？</h1><ul><li>把memcached引入应用中，还是需要不少工作量的</li><li>MySQL有个使用方便的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复地快速执行。</li></ul><h4 id="Memcached与之相比，怎么样呢"><a href="#Memcached与之相比，怎么样呢" class="headerlink" title="Memcached与之相比，怎么样呢"></a>Memcached与之相比，怎么样呢</h4><ul><li>MySQL的query cache是集中式的，连接到该query cache的MySQL服务器都会受益。 </li><li>当您修改表时，MySQL的query cache会立刻被刷新（flush）</li><li>存储一个memcached item只需要很少的时间，但是当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。 </li><li>在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度会变得更慢。 </li><li>在 MySQL的query cache中，我们是不能存储任意的数据的（只能是SQL查询结果）。而利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的增加，query cache的弊将大于利。 </li><li>query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。</li></ul><p> </p><h1 id="memcached和服务器的local-cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？"><a href="#memcached和服务器的local-cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？" class="headerlink" title="memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？"></a>memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？</h1><ul><li>首先，local cache有许多与上面(query cache)相同的问题</li><li>local cache能够利用的内存容量受到（单台）服务器空闲内存空间的限制</li><li>不过，local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。 </li><li>local cache的数据查询更快</li><li>考虑把highly common的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，考虑把它们放在local cached吧。 </li><li>local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器刷新cache（很慢，不具扩展性），或者仅仅依赖缓存超时失效机制。 </li><li>local cache面临着严重的内存限制，这一点上面已经提到。</li></ul><p> </p><h1 id="memcached的cache机制是怎样的？"><a href="#memcached的cache机制是怎样的？" class="headerlink" title="memcached的cache机制是怎样的？"></a>memcached的cache机制是怎样的？</h1><ul><li>Memcached主要的cache机制是LRU（最近最少用）算法+超时失效</li><li>当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the future</li><li>如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。</li></ul><p> </p><h1 id="memcached如何实现冗余机制？"><a href="#memcached如何实现冗余机制？" class="headerlink" title="memcached如何实现冗余机制？"></a>memcached如何实现冗余机制？</h1><ul><li>不实现！我们对这个问题感到很惊讶</li><li>Memcached应该是应用的缓存层</li><li>它的设计本身就不带有任何冗余机制</li><li>如果一个memcached节点失去了所有数据，您应该可以从数据源（比如数据库）再次获取到数据</li><li>您应该特别注意，您的应用应该可以容忍节点的失效</li><li>不要写一些糟糕的查询代码，寄希望于 memcached来保证一切！如果您担心节点失效会大大加重数据库的负担，那么您可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节点down了的时候接管IP），等等。</li></ul><p> </p><h1 id="memcached如何处理容错的？"><a href="#memcached如何处理容错的？" class="headerlink" title="memcached如何处理容错的？"></a>memcached如何处理容错的？</h1><ul><li>不处理！</li><li>在memcached节点失效的情况下，集群没有必要做任何容错处理</li><li>如果发生了节点失效，应对的措施完全取决于用户</li><li>节点失效时，下面列出几种方案供您选择： <ul><li>忽略它！在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响</li><li>把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。 </li><li>启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。 </li><li>如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）</li><li>两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。</li></ul></li></ul><p> </p><h1 id="如何将memcached中item批量导入导出？"><a href="#如何将memcached中item批量导入导出？" class="headerlink" title="如何将memcached中item批量导入导出？"></a>如何将memcached中item批量导入导出？</h1><ul><li>您不应该这样做！</li><li>Memcached是一个非阻塞的服务器</li><li>任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑</li><li>向 memcached中批量导入数据往往不是您真正想要的</li><li>想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？ </li><li>因此，批量导出导入数据并不像您想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助的。虽然这个场景并不典型，但却经常发生，因此我们会考虑在将来实现批量导出导入的功能。</li></ul><p> </p><h1 id="memcached是如何做身份验证的？"><a href="#memcached是如何做身份验证的？" class="headerlink" title="memcached是如何做身份验证的？"></a>memcached是如何做身份验证的？</h1><ul><li>没有身份认证机制！</li><li>memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）</li><li>memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。 </li><li>如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。</li></ul><p> </p><h1 id="memcached的多线程是什么？如何使用它们？"><a href="#memcached的多线程是什么？如何使用它们？" class="headerlink" title="memcached的多线程是什么？如何使用它们？"></a>memcached的多线程是什么？如何使用它们？</h1><ul><li>线程就是定律（threads rule）！</li><li>多线程模式允许memcached能够充分利用多个CPU，并在CPU之间共享所有的缓存数据</li><li>memcached使用一种简单的锁机制来保证数据更新操作的互斥</li><li>相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi gets。 </li><li>如果您的系统负载并不重，也许您不需要启用多线程工作模式</li><li>如果您在运行一个拥有大规模硬件的、庞大的网站，您将会看到多线程的好处。 </li><li>简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。</li></ul><p> </p><h1 id="memcached能接受的key的最大长度是多少？"><a href="#memcached能接受的key的最大长度是多少？" class="headerlink" title="memcached能接受的key的最大长度是多少？"></a>memcached能接受的key的最大长度是多少？</h1><ul><li>key的最大长度是250个字符</li><li>需要注意的是，250是memcached服务器端内部的限制，如果您使用的客户端支持”key的前缀”或类似特性，那么key（前缀+原始key）的最大长度是可以超过250个字符的</li><li>我们推荐使用使用较短的key，因为可以节省内存和带宽。</li></ul><p> </p><h1 id="memcached对item的过期时间有什么限制？"><a href="#memcached对item的过期时间有什么限制？" class="headerlink" title="memcached对item的过期时间有什么限制？"></a>memcached对item的过期时间有什么限制？</h1><ul><li>过期时间最大可以达到30天</li><li>memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态。</li></ul><p> </p><h1 id="memcached最大能存储多大的单个item？"><a href="#memcached最大能存储多大的单个item？" class="headerlink" title="memcached最大能存储多大的单个item？"></a>memcached最大能存储多大的单个item？</h1><ul><li>1MB</li><li>如果你的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。</li></ul><p> </p><h1 id="为什么单个item的大小被限制在1M-byte之内？"><a href="#为什么单个item的大小被限制在1M-byte之内？" class="headerlink" title="为什么单个item的大小被限制在1M byte之内？"></a>为什么单个item的大小被限制在1M byte之内？</h1><ul><li>简单的回答：因为内存分配器的算法就是这样的。 </li><li>详细的回答：Memcached的内存存储引擎（引擎将来可插拔…），使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。 </li><li>如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：slab1 – 400B slab2 – 480B slab3 – 576B … </li><li>slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内存，因此如果设置了较小的因子和较大的最大值，会需要更多的内存。 </li><li>还有其他原因使得您不要这样向memcached中存取很大的数据…不要尝试把巨大的网页放到mencached中。把这样大的数据结构load和unpack到内存中需要花费很长的时间，从而导致您的网站性能反而不好。 </li><li>如果您确实需要存储大于1MB的数据，你可以修改slabs.c:POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc&#x2F;free。其他的建议包括数据库、MogileFS等。</li></ul><p> </p><h1 id="我可以在不同的memcached节点上使用大小不等的缓存空间吗？这么做之后，memcached能够更有效地使用内存吗？"><a href="#我可以在不同的memcached节点上使用大小不等的缓存空间吗？这么做之后，memcached能够更有效地使用内存吗？" class="headerlink" title="我可以在不同的memcached节点上使用大小不等的缓存空间吗？这么做之后，memcached能够更有效地使用内存吗？"></a>我可以在不同的memcached节点上使用大小不等的缓存空间吗？这么做之后，memcached能够更有效地使用内存吗？</h1><ul><li>Memcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小</li><li>因此，您可以在不同的节点上使用大小不等的缓存。但是一般都是这样做的：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。</li></ul><p> </p><h1 id="LRU算法，slab分配，如何减少内存碎⽚"><a href="#LRU算法，slab分配，如何减少内存碎⽚" class="headerlink" title="LRU算法，slab分配，如何减少内存碎⽚"></a>LRU算法，slab分配，如何减少内存碎⽚</h1><ul><li>memcached预先将分配的内存分割成各种尺⼨的块(chunk)，并把尺⼨相同的块分成组(chunk的集合)，以此克服内<br>存碎⽚化问题</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><nav class="pagination"><a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/default-index/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/default-index/">1</a><span class="page-number current">2</span><a class="page-number" href="/default-index/page/3/">3</a><a class="page-number" href="/default-index/page/4/">4</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/default-index/page/3/"><i class="fa fa-angle-right"></i></a></nav></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">褚岩</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">1.4m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">21:06</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="300" alpha="0.6" zindex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.2/anime.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.28/fancybox/fancybox.umd.js" integrity="sha256-ytMJGN3toR+a84u7g7NuHm91VIR06Q41kMWDr2pq7Zo=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script src="/js/third-party/fancybox.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>