<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"javainterviewguide.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.19.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8070896123414715" crossorigin="anonymous"></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-TQWRP5B4WS"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TQWRP5B4WS")</script><meta name="description" content="路漫漫其修远兮，吾将上下而求索"><meta property="og:type" content="website"><meta property="og:title" content="Java后端面试指南"><meta property="og:url" content="https://javainterviewguide.github.io/default-index/index.html"><meta property="og:site_name" content="Java后端面试指南"><meta property="og:description" content="路漫漫其修远兮，吾将上下而求索"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="褚岩"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://javainterviewguide.github.io/default-index/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"default-index/index.html","title":""}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Java后端面试指南</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Java后端面试指南</h1><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-overview-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">褚岩</p><div class="site-description" itemprop="description">路漫漫其修远兮，吾将上下而求索</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><span class="site-state-item-count">27</span> <span class="site-state-item-name">分类</span></div><div class="site-state-item site-state-tags"><span class="site-state-item-count">43</span> <span class="site-state-item-name">标签</span></div></nav></div></div></div></div></aside></div><div class="main-inner index posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/b3085e36f5dd.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/b3085e36f5dd.html" class="post-title-link" itemprop="url">Kafka</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:27:32 / 修改时间：16:28:13" itemprop="dateCreated datePublished" datetime="2023-12-20T16:27:32+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="什么是Apache-Kafka"><a href="#什么是Apache-Kafka" class="headerlink" title="什么是Apache Kafka"></a>什么是Apache Kafka</h1><p>Apache Kafka是一个分布式发布/订阅消息系统。它是一个可扩展的，容错的发布 - 订阅消息系统，它使我们能够构建分布式应用程序。这是一个Apache顶级项目。Kafka适合离线和在线消息消费。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/4d12791836df.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/4d12791836df.html" class="post-title-link" itemprop="url">Spring boot</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:26:00 / 修改时间：16:26:37" itemprop="dateCreated datePublished" datetime="2023-12-20T16:26:00+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spring/" itemprop="url" rel="index"><span itemprop="name">Spring</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="什么是Spring-Boot"><a href="#什么是Spring-Boot" class="headerlink" title="什么是Spring Boot"></a>什么是Spring Boot</h1><p>多年来，随着新功能的增加，spring变得越来越复杂。<br>如果必须启动一个新的Spring项目，我们必须添加构建路径或添加Maven依赖关系，配置应用程序服务器，添加spring配置。<br>因此，开始一个新的spring项目需要很多努力，因为我们现在必须从头开始做所有事情。<br>Spring Boot是解决这个问题的方法。Spring Boot已经建立在现有spring框架之上。使用spring启动，我们避免了之前我们必须做的所有样板代码和配置。<br>因此，Spring Boot可以帮助我们以最少的工作量，更加健壮地使用现有的Spring功能。</p><h1 id="Spring-Boot有哪些优点"><a href="#Spring-Boot有哪些优点" class="headerlink" title="Spring Boot有哪些优点"></a>Spring Boot有哪些优点</h1><ul><li>减少开发，测试时间和努力。</li><li>使用JavaConfig有助于避免使用XML。</li><li>避免大量的Maven导入和各种版本冲突。</li><li>提供意见发展方法。</li><li>通过提供默认值快速开始开发。</li><li>没有单独的Web服务器需要。这意味着你不再需要启动Tomcat，Glassfish或其他任何东西。</li><li>需要更少的配置 因为没有web.xml文件。只需添加用@ Configuration注释的类，然后添加用@Bean注释的方法，Spring将自动加载对象并像以前一样对其进行管理。您甚至可以将@Autowired添加到bean方法中，以使Spring自动装入需要的依赖关系中。</li><li>基于环境的配置 使用这些属性，您可以将您正在使用的环境传递到应用程序：-Dspring.profiles.active = {enviornment}。在加载主应用程序属性文件后，Spring将在（application{environment} .properties）中加载后续的应用程序属性文件。</li></ul><h1 id="什么是JavaConfig"><a href="#什么是JavaConfig" class="headerlink" title="什么是JavaConfig"></a>什么是JavaConfig</h1><p>Spring JavaConfig是Spring社区的产品，它提供了配置Spring IoC容器的纯Java方法。因此它有助于避免使用XML配置。使用JavaConfig的优点在于：<br>面向对象的配置。由于配置被定义为JavaConfig中的类，因此用户可以充分利用Java中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean方法等。<br>减少或消除XML配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在XML和Java之间来回切换。<br>JavaConfig为开发人员提供了一种纯Java方法来配置与XML配置概念相似的Spring容器。<br>从技术角度来讲，只使用JavaConfig配置类来配置容器是可行的，但实际上很多人认为将JavaConfig与XML混合匹配是理想的。<br>类型安全和重构友好。JavaConfig提供了一种类型安全的方法来配置Spring容器。由于Java 5.0对泛型的支持，现在可以按类型而不是按名称检索bean，不需要任何强制转换或基于字符串的查找。</p><h1 id="如何重新加载Spring-Boot上的更改，而无需重新启动服务器？"><a href="#如何重新加载Spring-Boot上的更改，而无需重新启动服务器？" class="headerlink" title="如何重新加载Spring Boot上的更改，而无需重新启动服务器？"></a>如何重新加载Spring Boot上的更改，而无需重新启动服务器？</h1><p>这可以使用DEV工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat将重新启动。<br>Spring Boot有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力。Java开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。<br>开发人员可以重新加载Spring Boot上的更改，而无需重新启动服务器。这将消除每次手动部署更改的需要。Spring Boot在发布它的第一个版本时没有这个功能。<br>这是开发人员最需要的功能。DevTools模块完全满足开发人员的需求。该模块将在生产环境中被禁用。它还提供H2数据库控制台以更好地测试应用程序。</p><h1 id="Spring-Boot中的监视器是什么？"><a href="#Spring-Boot中的监视器是什么？" class="headerlink" title="Spring Boot中的监视器是什么？"></a>Spring Boot中的监视器是什么？</h1><p>Spring boot actuator是spring启动框架中的重要功能之一。Spring boot监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。<br>有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为HTTP URL访问的REST端点来检查状态。</p><h1 id="如何在Spring-Boot中禁用Actuator端点安全性？"><a href="#如何在Spring-Boot中禁用Actuator端点安全性？" class="headerlink" title="如何在Spring Boot中禁用Actuator端点安全性？"></a>如何在Spring Boot中禁用Actuator端点安全性？</h1><p>默认情况下，所有敏感的HTTP端点都是安全的，只有具有ACTUATOR角色的用户才能访问它们。<br>安全性是使用标准的HttpServletRequest.isUserInRole方法实施的。 我们可以使用management.security.enabled = false 来禁用安全性。只有在执行机构端点在防火墙后访问时，才建议禁用安全性。<br>如何在自定义端口上运行Spring Boot应用程序？<br>为了在自定义端口上运行Spring Boot应用程序，您可以在application.properties中指定端口。<br>server.port = 8090</p><h1 id="什么是YAML？"><a href="#什么是YAML？" class="headerlink" title="什么是YAML？"></a>什么是YAML？</h1><p>YAML是一种人类可读的数据序列化语言。它通常用于配置文件。<br>与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML文件就更加结构化，而且更少混淆。可以看出YAML具有分层配置数据。</p><h1 id="如何实现Spring-Boot应用程序的安全性？"><a href="#如何实现Spring-Boot应用程序的安全性？" class="headerlink" title="如何实现Spring Boot应用程序的安全性？"></a>如何实现Spring Boot应用程序的安全性？</h1><p>为了实现Spring Boot的安全性，我们使用 spring-boot-starter-security依赖项，并且必须添加安全配置。它只需要很少的代码。配置类将必须扩展WebSecurityConfigurerAdapter并覆盖其方法。</p><h1 id="如何集成Spring-Boot和ActiveMQ？"><a href="#如何集成Spring-Boot和ActiveMQ？" class="headerlink" title="如何集成Spring Boot和ActiveMQ？"></a>如何集成Spring Boot和ActiveMQ？</h1><p>对于集成Spring Boot和ActiveMQ，我们使用spring-boot-starter-activemq<br>依赖关系。 它只需要很少的配置，并且不需要样板代码。</p><h1 id="如何使用Spring-Boot实现分页和排序？"><a href="#如何使用Spring-Boot实现分页和排序？" class="headerlink" title="如何使用Spring Boot实现分页和排序？"></a>如何使用Spring Boot实现分页和排序？</h1><p>使用Spring Boot实现分页非常简单。使用Spring Data-JPA可以实现将可分页的org.springframework.data.domain.Pageable传递给存储库方法。</p><h1 id="什么是Spring-Boot？"><a href="#什么是Spring-Boot？" class="headerlink" title="什么是Spring Boot？"></a>什么是Spring Boot？</h1><p>多年来，随着新功能的增加，spring变得越来越复杂。只需访问<a target="_blank" rel="noopener" href="https://spring.io/projects%E9%A1%B5%E9%9D%A2%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%B1%E4%BC%9A%E7%9C%8B%E5%88%B0%E5%8F%AF%E4%BB%A5%E5%9C%A8%E6%88%91%E4%BB%AC%E7%9A%84%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%89%80%E6%9C%89Spring%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%B8%8D%E5%90%8C%E5%8A%9F%E8%83%BD%E3%80%82%E5%A6%82%E6%9E%9C%E5%BF%85%E9%A1%BB%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84Spring%E9%A1%B9%E7%9B%AE%EF%BC%8C%E6%88%91%E4%BB%AC%E5%BF%85%E9%A1%BB%E6%B7%BB%E5%8A%A0%E6%9E%84%E5%BB%BA%E8%B7%AF%E5%BE%84%E6%88%96%E6%B7%BB%E5%8A%A0Maven%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%EF%BC%8C%E9%85%8D%E7%BD%AE%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%8C%E6%B7%BB%E5%8A%A0spring%E9%85%8D%E7%BD%AE%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%E5%BC%80%E5%A7%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84spring%E9%A1%B9%E7%9B%AE%E9%9C%80%E8%A6%81%E5%BE%88%E5%A4%9A%E5%8A%AA%E5%8A%9B%EF%BC%8C%E5%9B%A0%E4%B8%BA%E6%88%91%E4%BB%AC%E7%8E%B0%E5%9C%A8%E5%BF%85%E9%A1%BB%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%81%9A%E6%89%80%E6%9C%89%E4%BA%8B%E6%83%85%E3%80%82">https://spring.io/projects页面，我们就会看到可以在我们的应用程序中使用的所有Spring项目的不同功能。如果必须启动一个新的Spring项目，我们必须添加构建路径或添加Maven依赖关系，配置应用程序服务器，添加spring配置。因此，开始一个新的spring项目需要很多努力，因为我们现在必须从头开始做所有事情。</a></p><p>Spring Boot是解决这个问题的方法。Spring Boot已经建立在现有spring框架之上。使用spring启动，我们避免了之前我们必须做的所有样板代码和配置。因此，Spring Boot可以帮助我们以最少的工作量，更加健壮地使用现有的Spring功能。</p><h1 id="Spring-Boot有哪些优点？"><a href="#Spring-Boot有哪些优点？" class="headerlink" title="Spring Boot有哪些优点？"></a>Spring Boot有哪些优点？</h1><p>Spring Boot的优点有：</p><p>减少开发，测试时间和努力。<br>使用JavaConfig有助于避免使用XML。<br>避免大量的Maven导入和各种版本冲突。<br>提供意见发展方法。<br>通过提供默认值快速开始开发。<br>没有单独的Web服务器需要。这意味着你不再需要启动Tomcat，Glassfish或其他任何东西。<br>需要更少的配置 因为没有web.xml文件。只需添加用@ Configuration注释的类，然后添加用@Bean注释的方法，Spring将自动加载对象并像以前一样对其进行管理。您甚至可以将@Autowired添加到bean方法中，以使Spring自动装入需要的依赖关系中。<br>基于环境的配置 使用这些属性，您可以将您正在使用的环境传递到应用程序：-Dspring.profiles.active = {enviornment}。在加载主应用程序属性文件后，Spring将在（application{environment} .properties）中加载后续的应用程序属性文件。</p><h1 id="什么是JavaConfig？"><a href="#什么是JavaConfig？" class="headerlink" title="什么是JavaConfig？"></a>什么是JavaConfig？</h1><p>Spring JavaConfig是Spring社区的产品，它提供了配置Spring IoC容器的纯Java方法。因此它有助于避免使用XML配置。使用JavaConfig的优点在于：</p><p>面向对象的配置。由于配置被定义为JavaConfig中的类，因此用户可以充分利用Java中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean方法等。<br>减少或消除XML配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在XML和Java之间来回切换。JavaConfig为开发人员提供了一种纯Java方法来配置与XML配置概念相似的Spring容器。从技术角度来讲，只使用JavaConfig配置类来配置容器是可行的，但实际上很多人认为将JavaConfig与XML混合匹配是理想的。<br>类型安全和重构友好。JavaConfig提供了一种类型安全的方法来配置Spring容器。由于Java 5.0对泛型的支持，现在可以按类型而不是按名称检索bean，不需要任何强制转换或基于字符串的查找。</p><h1 id="如何重新加载Spring-Boot上的更改，而无需重新启动服务器？-1"><a href="#如何重新加载Spring-Boot上的更改，而无需重新启动服务器？-1" class="headerlink" title="如何重新加载Spring Boot上的更改，而无需重新启动服务器？"></a>如何重新加载Spring Boot上的更改，而无需重新启动服务器？</h1><p>这可以使用DEV工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat将重新启动。Spring Boot有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力。Java开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。开发人员可以重新加载Spring Boot上的更改，而无需重新启动服务器。这将消除每次手动部署更改的需要。Spring Boot在发布它的第一个版本时没有这个功能。这是开发人员最需要的功能。DevTools模块完全满足开发人员的需求。该模块将在生产环境中被禁用。它还提供H2数据库控制台以更好地测试应用程序。</p><p>org.springframework.boot spring-boot-devtools true</p><h1 id="Spring-Boot中的监视器是什么？-1"><a href="#Spring-Boot中的监视器是什么？-1" class="headerlink" title="Spring Boot中的监视器是什么？"></a>Spring Boot中的监视器是什么？</h1><p>Spring boot actuator是spring启动框架中的重要功能之一。Spring boot监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为HTTP URL访问的REST端点来检查状态。</p><h1 id="如何在Spring-Boot中禁用Actuator端点安全性？-1"><a href="#如何在Spring-Boot中禁用Actuator端点安全性？-1" class="headerlink" title="如何在Spring Boot中禁用Actuator端点安全性？"></a>如何在Spring Boot中禁用Actuator端点安全性？</h1><p>默认情况下，所有敏感的HTTP端点都是安全的，只有具有ACTUATOR角色的用户才能访问它们。安全性是使用标准的HttpServletRequest.isUserInRole方法实施的。 我们可以使用</p><p>management.security.enabled = false<br>来禁用安全性。只有在执行机构端点在防火墙后访问时，才建议禁用安全性。</p><h1 id="如何在自定义端口上运行Spring-Boot应用程序？"><a href="#如何在自定义端口上运行Spring-Boot应用程序？" class="headerlink" title="如何在自定义端口上运行Spring Boot应用程序？"></a>如何在自定义端口上运行Spring Boot应用程序？</h1><p>为了在自定义端口上运行Spring Boot应用程序，您可以在application.properties中指定端口。</p><p>server.port = 8090</p><h1 id="什么是YAML？-1"><a href="#什么是YAML？-1" class="headerlink" title="什么是YAML？"></a>什么是YAML？</h1><p>YAML是一种人类可读的数据序列化语言。它通常用于配置文件。</p><p>与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML文件就更加结构化，而且更少混淆。可以看出YAML具有分层配置数据。</p><h1 id="如何实现Spring-Boot应用程序的安全性？-1"><a href="#如何实现Spring-Boot应用程序的安全性？-1" class="headerlink" title="如何实现Spring Boot应用程序的安全性？"></a>如何实现Spring Boot应用程序的安全性？</h1><p>为了实现Spring Boot的安全性，我们使用 spring-boot-starter-security依赖项，并且必须添加安全配置。它只需要很少的代码。配置类将必须扩展WebSecurityConfigurerAdapter并覆盖其方法。</p><h1 id="如何集成Spring-Boot和ActiveMQ？-1"><a href="#如何集成Spring-Boot和ActiveMQ？-1" class="headerlink" title="如何集成Spring Boot和ActiveMQ？"></a>如何集成Spring Boot和ActiveMQ？</h1><p>对于集成Spring Boot和ActiveMQ，我们使用</p><p>spring-boot-starter-activemq<br>依赖关系。 它只需要很少的配置，并且不需要样板代码。</p><h1 id="如何使用Spring-Boot实现分页和排序？-1"><a href="#如何使用Spring-Boot实现分页和排序？-1" class="headerlink" title="如何使用Spring Boot实现分页和排序？"></a>如何使用Spring Boot实现分页和排序？</h1><p>使用Spring Boot实现分页非常简单。使用Spring Data-JPA可以实现将可分页的</p><p>org.springframework.data.domain.Pageable<br>传递给存储库方法。</p><h1 id="什么是Swagger？你用Spring-Boot实现了它吗？"><a href="#什么是Swagger？你用Spring-Boot实现了它吗？" class="headerlink" title="什么是Swagger？你用Spring Boot实现了它吗？"></a>什么是Swagger？你用Spring Boot实现了它吗？</h1><p>Swagger广泛用于可视化API，使用Swagger UI为前端开发人员提供在线沙箱。Swagger是用于生成RESTful Web服务的可视化表示的工具，规范和完整框架实现。它使文档能够以与服务器相同的速度更新。当通过Swagger正确定义时，消费者可以使用最少量的实现逻辑来理解远程服务并与其进行交互。因此，Swagger消除了调用服务时的猜测。</p><h1 id="什么是Spring-Profiles？"><a href="#什么是Spring-Profiles？" class="headerlink" title="什么是Spring Profiles？"></a>什么是Spring Profiles？</h1><p>Spring Profiles允许用户根据配置文件（dev，test，prod等）来注册bean。因此，当应用程序在开发中运行时，只有某些bean可以加载，而在PRODUCTION中，某些其他bean可以加载。假设我们的要求是Swagger文档仅适用于QA环境，并且禁用所有其他文档。这可以使用配置文件来完成。Spring Boot使得使用配置文件非常简单。</p><h1 id="什么是Spring-Batch？"><a href="#什么是Spring-Batch？" class="headerlink" title="什么是Spring Batch？"></a>什么是Spring Batch？</h1><p>Spring Boot Batch提供可重用的函数，这些函数在处理大量记录时非常重要，包括日志/跟踪，事务管理，作业处理统计信息，作业重新启动，跳过和资源管理。它还提供了更先进的技术服务和功能，通过优化和分区技术，可以实现极高批量和高性能批处理作业。简单以及复杂的大批量批处理作业可以高度可扩展的方式利用框架处理重要大量的信息。</p><h1 id="什么是FreeMarker模板？"><a href="#什么是FreeMarker模板？" class="headerlink" title="什么是FreeMarker模板？"></a>什么是FreeMarker模板？</h1><p>FreeMarker是一个基于Java的模板引擎，最初专注于使用MVC软件架构进行动态网页生成。使用Freemarker的主要优点是表示层和业务层的完全分离。程序员可以处理应用程序代码，而设计人员可以处理html页面设计。最后使用freemarker可以将这些结合起来，给出最终的输出页面。</p><h1 id="如何使用Spring-Boot实现异常处理？"><a href="#如何使用Spring-Boot实现异常处理？" class="headerlink" title="如何使用Spring Boot实现异常处理？"></a>如何使用Spring Boot实现异常处理？</h1><p>Spring提供了一种使用ControllerAdvice处理异常的非常有用的方法。 我们通过实现一个ControlerAdvice类，来处理控制器类抛出的所有异常。</p><h1 id="您使用了哪些starter-maven依赖项？"><a href="#您使用了哪些starter-maven依赖项？" class="headerlink" title="您使用了哪些starter maven依赖项？"></a>您使用了哪些starter maven依赖项？</h1><p>使用了下面的一些依赖项</p><p>spring-boot-starter-activemq<br>spring-boot-starter-security<br>spring-boot-starter-web<br>这有助于增加更少的依赖关系，并减少版本的冲突。</p><h1 id="如何监视所有Spring-Boot微服务"><a href="#如何监视所有Spring-Boot微服务" class="headerlink" title="如何监视所有Spring Boot微服务"></a>如何监视所有Spring Boot微服务</h1><p>Spring Boot提供监视器端点以监控各个微服务的度量。这些端点对于获取有关应用程序的信息（如它们是否已启动）以及它们的组件（如数据库等）是否正常运行很有帮助。但是，使用监视器的一个主要缺点或困难是，我们必须单独打开应用程序的知识点以了解其状态或健康状况。想象一下涉及50个应用程序的微服务，管理员将不得不击中所有50个应用程序的执行终端。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/5788a7088796.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/5788a7088796.html" class="post-title-link" itemprop="url">Redis</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:24:36 / 修改时间：18:30:03" itemprop="dateCreated datePublished" datetime="2023-12-20T16:24:36+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="什么是缓存雪崩"><a href="#什么是缓存雪崩" class="headerlink" title="什么是缓存雪崩"></a>什么是缓存雪崩</h1><p>如果我们的缓存挂掉了，这意味着我们的全部请求都跑去数据库了。</p><p>我们都知道Redis不可能把所有的数据都缓存起来(内存昂贵且有限)，所以Redis需要对数据设置过期时间，并采用的是惰性删除 + 定期删除两种策略对过期键删除。<br>如果缓存数据设置的过期时间是相同的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存同时失效，全部请求到数据库中。<br>这就是缓存雪崩：Redis挂掉了，请求全部走数据库。<br>缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！</p><h1 id="如何解决缓存雪崩"><a href="#如何解决缓存雪崩" class="headerlink" title="如何解决缓存雪崩"></a>如何解决缓存雪崩</h1><p>在缓存的时候给过期时间加上一个随机值，这样就会大幅度的减少缓存在同一时间过期。<br>对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：<br>事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。<br>事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)<br>事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。</p><h1 id="什么是缓存穿透"><a href="#什么是缓存穿透" class="headerlink" title="什么是缓存穿透"></a>什么是缓存穿透</h1><p>缓存穿透是指查询一个一定不存在的数据。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存<br>这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。</p><p>这就是缓存穿透：请求的数据在缓存大量不命中，导致请求走数据库。<br>缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！</p><h1 id="如何解决缓存穿透"><a href="#如何解决缓存穿透" class="headerlink" title="如何解决缓存穿透"></a>如何解决缓存穿透</h1><p>解决缓存穿透也有两种方案：<br>由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！<br>当我们从数据库找不到的时候，我们也将这个空对象设置到缓存里边去。下次再请求的时候，就可以从缓存里边获取了。<br>这种情况我们一般会将空对象设置一个较短的过期时间</p><h1 id="缓存与数据库双写一致"><a href="#缓存与数据库双写一致" class="headerlink" title="缓存与数据库双写一致"></a>缓存与数据库双写一致</h1><p>对于读操作，流程是这样的<br>如果我们的数据在缓存里边有，那么就直接取缓存的。<br>如果缓存里没有我们想要的数据，我们会先去查询数据库，然后将数据库查出来的数据写到缓存中。最后将数据返回给请求</p><h1 id="什么是缓存与数据库双写一致问题"><a href="#什么是缓存与数据库双写一致问题" class="headerlink" title="什么是缓存与数据库双写一致问题"></a>什么是缓存与数据库双写一致问题</h1><p>如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要更新时候呢？各种情况很可能就造成数据库和缓存的数据不一致了。<br>这里不一致指的是：数据库的数据跟缓存的数据不一致<br>从理论上说，只要我们设置了键的过期时间，我们就能保证缓存和数据库的数据最终是一致的。<br>因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。<br>除了设置过期时间，我们还需要做更多的措施来尽量避免数据库与缓存处于不一致的情况发生</p><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><p>缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。<br>缓存失效时的雪崩效应对底层系统的冲击非常可怕！大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。<br>以下简单介绍两种实现方式的伪代码：<br>（1）碰到这种情况，一般并发量不是特别多的时候，使用最多的解决方案是加锁排队</p><p>加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法！<br>注意：加锁排队的解决方式分布式环境的并发问题，有可能还要解决分布式锁的问题；线程还会被阻塞，用户体验很差！因此，在真正的高并发场景下很少使用！<br>（2）还有一个解决办法解决方案是：给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存</p><p>解释说明：<br>1、缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存；<br>2、缓存数据：它的过期时间比缓存标记的时间延长1倍，例：标记缓存时间30分钟，数据缓存设置为60分钟。 这样，当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。<br>关于缓存崩溃的解决方法，这里提出了三种方案：使用锁或队列、设置过期标志更新缓存、为key设置不同的缓存失效时间，还有一各被称为“二级缓存”的解决方法，有兴趣的读者可以自行研究。</p><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><p>缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。<br>有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。<br>另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴！</p><p>把空结果，也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。同时也可以单独设置个缓存区域存储空值，对要查询的key进行预先校验，然后再放行给后面的正常缓存处理逻辑。</p><h1 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h1><p>缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！<br>解决思路：<br>1、直接写个缓存刷新页面，上线时手工操作下；<br>2、数据量不大，可以在项目启动的时候自动进行加载；<br>3、定时刷新缓存；</p><h1 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h1><p>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：<br>（1）定时去清理过期的缓存；<br>（2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。<br>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p><h1 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h1><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。<br>降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。<br>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：<br>（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；<br>（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；<br>（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；<br>（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p><h1 id="为什么使用-Redis"><a href="#为什么使用-Redis" class="headerlink" title="为什么使用 Redis"></a>为什么使用 Redis</h1><p>我觉得在项目中使用 Redis，主要是从两个角度去考虑：性能和并发。<br>当然，Redis 还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件，如 ZooKpeer 等代替，并不是非要使用 Redis。因此，这个问题主要从性能和并发两个角度去答。</p><h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><p>如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。</p><p>题外话：忽然想聊一下这个迅速响应的标准。根据交互效果的不同，这个响应时间没有固定标准。<br>不过曾经有人这么告诉我：”在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。<br>另外，超过一弹指的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。”<br>那么瞬间、刹那、一弹指具体是多少时间呢？<br>根据《摩诃僧祗律》记载：<br>一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。<br>那么，经过周密的计算，一瞬间为 0.36 秒、一刹那有 0.018 秒、一弹指长达 7.2 秒。</p><h4 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h4><p>如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。<br>这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。</p><h4 id="使用-Redis-有什么缺点"><a href="#使用-Redis-有什么缺点" class="headerlink" title="使用 Redis 有什么缺点"></a>使用 Redis 有什么缺点</h4><p>大家用 Redis 这么久，这个问题是必须要了解的，基本上使用 Redis 都会碰到一些问题，常见的也就几个。<br>回答主要是四个问题：<br>缓存和数据库双写一致性问题<br>缓存雪崩问题<br>缓存击穿问题<br>缓存的并发竞争问题</p><h4 id="单线程的-Redis-为什么这么快"><a href="#单线程的-Redis-为什么这么快" class="headerlink" title="单线程的 Redis 为什么这么快"></a>单线程的 Redis 为什么这么快</h4><p>这个问题是对 Redis 内部机制的一个考察。根据我的面试经验，很多人都不知道Redis 是单线程工作模型。所以，这个问题还是应该要复习一下的。<br>回答主要是以下三点：</p><ul><li>纯内存操作</li><li>单线程操作，避免了频繁的上下文切换</li><li>采用了非阻塞 I/O 多路复用机制</li></ul><h4 id="I-O-多路复用机制"><a href="#I-O-多路复用机制" class="headerlink" title="I/O 多路复用机制"></a>I/O 多路复用机制</h4><p>题外话：我们现在要仔细的说一说 I/O 多路复用机制，因为这个说法实在是太通俗了，通俗到一般人都不懂是什么意思。<br>打一个比方：小曲在 S 城开了一家快递店，负责同城快送服务。小曲因为资金限制，雇佣了一批快递员，然后小曲发现资金不够了，只够买一辆车送快递。<br>经营方式一<br>客户每送来一份快递，小曲就让一个快递员盯着，然后快递员开车去送快递。<br>慢慢的小曲就发现了这种经营方式存在下述问题：<br>几十个快递员基本上时间都花在了抢车上了，大部分快递员都处在闲置状态，谁抢到了车，谁就能去送快递。<br>随着快递的增多，快递员也越来越多，小曲发现快递店里越来越挤，没办法雇佣新的快递员了。<br>快递员之间的协调很花时间。<br>综合上述缺点，小曲痛定思痛，提出了下面的经营方式。<br>经营方式二<br>小曲只雇佣一个快递员。然后呢，客户送来的快递，小曲按送达地点标注好，然后依次放在一个地方。<br>最后，那个快递员依次的去取快递，一次拿一个，然后开着车去送快递，送好了就回来拿下一个快递。<br>上述两种经营方式对比，是不是明显觉得第二种，效率更高，更好呢？<br>在上述比喻中：<br>每个快递员→每个线程<br>每个快递→每个 Socket(I/O 流)<br>快递的送达地点→Socket 的不同状态<br>客户送快递请求→来自客户端的请求<br>小曲的经营方式→服务端运行的代码<br>一辆车→CPU 的核数<br>于是我们有如下结论：<br>经营方式一就是传统的并发模型，每个 I/O 流(快递)都有一个新的线程(快递员)管理。<br>经营方式二就是 I/O 多路复用。只有单个线程(一个快递员)，通过跟踪每个 I/O 流的状态(每个快递的送达地点)，来管理多个 I/O 流。</p><p>简单来说，就是我们的 redis-client 在操作的时候，会产生具有不同事件类型的 Socket。<br>在服务端，有一段 I/O 多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。<br>需要说明的是，这个 I/O 多路复用机制，Redis 还提供了 select、epoll、evport、kqueue 等多路复用函数库，大家可以自行去了解。</p><h1 id="Redis-的数据类型，以及每种数据类型的使用场景"><a href="#Redis-的数据类型，以及每种数据类型的使用场景" class="headerlink" title="Redis 的数据类型，以及每种数据类型的使用场景"></a>Redis 的数据类型，以及每种数据类型的使用场景</h1><h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><p>这个没啥好说的，最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存</p><h4 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h4><p>这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。<br>我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果</p><h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><p>使用 List 的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。</p><h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4><p>因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用 JVM 自带的 Set 进行去重？<br>因为我们的系统一般都是集群部署，使用 JVM 自带的 Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。<br>另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><h4 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h4><p>Sorted Set多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。<br>可以做排行榜应用，取 TOP N 操作。Sorted Set 可以用来做延时任务。最后一个应用就是可以做范围查找。</p><h1 id="Redis-的过期策略以及内存淘汰机制"><a href="#Redis-的过期策略以及内存淘汰机制" class="headerlink" title="Redis 的过期策略以及内存淘汰机制"></a>Redis 的过期策略以及内存淘汰机制</h1><p>这个问题相当重要，到底 Redis 有没用到家，这个问题就可以看出来。<br>比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？<br>还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?<br>回答：Redis 采用的是定期删除+惰性删除策略。</p><h4 id="为什么不用定时删除策略"><a href="#为什么不用定时删除策略" class="headerlink" title="为什么不用定时删除策略"></a>为什么不用定时删除策略</h4><p>定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。<br>在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。</p><h4 id="定期删除-惰性删除是如何工作"><a href="#定期删除-惰性删除是如何工作" class="headerlink" title="定期删除+惰性删除是如何工作"></a>定期删除+惰性删除是如何工作</h4><p>定期删除，Redis 默认每个 100ms 检查，是否有过期的 Key，有过期 Key 则删除。<br>需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查(如果每隔 100ms，全部 Key 进行检查，Redis 岂不是卡死)。<br>因此，如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。<br>也就是说在你获取某个 Key 的时候，Redis 会检查一下，这个 Key 如果设置了过期时间，那么是否过期了？如果过期了此时就会删除。<br>采用定期删除+惰性删除就没其他问题了么?<br>不是的，如果定期删除没删除 Key。然后你也没即时去请求 Key，也就是说惰性删除也没生效。这样，Redis的内存会越来越高。那么就应该采用内存淘汰机制。<br>在 redis.conf 中有一行配置：</p><h1 id="maxmemory-policy-volatile-lru"><a href="#maxmemory-policy-volatile-lru" class="headerlink" title="maxmemory-policy volatile-lru"></a>maxmemory-policy volatile-lru</h1><p>该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)：<br>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。<br>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。<br>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。<br>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。<br>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。<br>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。<br>PS：如果没有设置 expire 的 Key，不满足先决条件(prerequisites)；那么 volatile-lru，volatile-random 和 volatile-ttl 策略的行为，和 noeviction(不删除) 基本上一致。</p><h1 id="Redis-和数据库双写一致性问题"><a href="#Redis-和数据库双写一致性问题" class="headerlink" title="Redis 和数据库双写一致性问题"></a>Redis 和数据库双写一致性问题</h1><p>一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。<br>答这个问题，先明白一个前提。就是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。<br>另外，我们所做的方案从根本上来说，只能说降低不一致发生的概率，无法完全避免。因此，有强一致性要求的数据，不能放缓存。<br>回答：首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p><h1 id="如何应对缓存穿透和缓存雪崩问题"><a href="#如何应对缓存穿透和缓存雪崩问题" class="headerlink" title="如何应对缓存穿透和缓存雪崩问题"></a>如何应对缓存穿透和缓存雪崩问题</h1><h4 id="缓存穿透-1"><a href="#缓存穿透-1" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。<br>缓存穿透解决方案：<br>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。<br>采用异步更新策略，无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。<br>提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的 Key。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p><h4 id="缓存雪崩-1"><a href="#缓存雪崩-1" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。<br>缓存雪崩解决方案：<br>给缓存的失效时间，加上一个随机值，避免集体失效。<br>使用互斥锁，但是该方案吞吐量明显下降了。<br>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。<br>然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。</p><h1 id="如何解决-Redis-的并发竞争-Key-问题"><a href="#如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="如何解决 Redis 的并发竞争 Key 问题"></a>如何解决 Redis 的并发竞争 Key 问题</h1><p>这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候大家思考过要注意什么呢？<br>需要说明一下，我提前百度了一下，发现答案基本都是推荐用 Redis 事务机制。<br>我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。<br>你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。</p><h4 id="如果对这个-Key-操作，不要求顺序"><a href="#如果对这个-Key-操作，不要求顺序" class="headerlink" title="如果对这个 Key 操作，不要求顺序"></a>如果对这个 Key 操作，不要求顺序</h4><p>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</p><h4 id="如果对这个-Key-操作，要求顺序"><a href="#如果对这个-Key-操作，要求顺序" class="headerlink" title="如果对这个 Key 操作，要求顺序"></a>如果对这个 Key 操作，要求顺序</h4><p>假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。<br>期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。<br>假设时间戳如下：<br>系统A key 1 {valueA 3:00}<br>系统B key 1 {valueB 3:05}<br>系统C key 1 {valueC 3:10}<br>那么，假设这会系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。<br>其他方法，比如利用队列，将 set 方法变成串行访问也可以。总之，灵活变通。</p><h1 id="列举⼀个常⽤的Redis客户端的并发模型"><a href="#列举⼀个常⽤的Redis客户端的并发模型" class="headerlink" title="列举⼀个常⽤的Redis客户端的并发模型"></a>列举⼀个常⽤的Redis客户端的并发模型</h1><pre><code>lock = 0;
while (timeout &gt; 0) &#123;
if (setnxexpire(key, value)) &#123;
lock = 1;
return lock;
&#125;

timeout -= sleeptime
sleep(sleeptime);
 &#125;
</code></pre><h1 id="分布式缓存，⼀致性hash"><a href="#分布式缓存，⼀致性hash" class="headerlink" title="分布式缓存，⼀致性hash"></a>分布式缓存，⼀致性hash</h1><p>1、⼀致性hash算法：我们的memcached客户端（这⾥我看的spymemcache的源码），使⽤了⼀致性hash算法<br>ketama进⾏数据存储节点的选择。与常规的hash算法思路不同，只是对我们要存储数据的key进⾏hash计算，分配到不同节点<br>存储。⼀致性hash算法是对我们要存储数据的服务器进⾏hash计算，进⽽确认每个key的存储位置。这⾥提到的⼀致性hash算<br>法ketama的做法是：选择具体的机器节点不在只依赖需要缓存数据的key的hash本身了，⽽是机器节点本身也进⾏了hash运<br>算。<br>1、⼀致性hash算法是分布式系统中常⽤算法，设计⽬的是为了解决因特⽹中的热点(hot spot)问题。解决了P2P<br>环境最为关键问题—如何在动态⽹络拓扑中分布存储和路由；<br>2、⼀致性hash算法引⼊虚拟节点机制，解决服务节点少时数据倾斜问题(即对每⼀个服务节点计算多个哈希，每<br>个计算结果位置都放置⼀个此服务节点，称为虚拟节点。)；<br>2、具体做法：如果有⼀个写⼊缓存的请求，其中Key值为K，计算器hash值Hash(K)， Hash(K) 对应于图 – 1环中的<br>某⼀个点，如果该点对应没有映射到具体的某⼀个机器节点，那么顺时针查找，直到第⼀次找到有映射机器的节点，该节点就<br>是确定的⽬标节点，如果超过了2^32仍然找不到节点，则命中第⼀个机器节点。⽐如 Hash(K) 的值介于A~B之间，那么命中<br>的机器节点应该是B节点（如上图 ）。<br>3、数据保存流程：<br>1、⾸先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。<br>2、然后采⽤同样的⽅法求出存储数据的键的哈希值，并映射到相同的圆上。<br>3、然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第⼀个服务器上。如果超过232仍然找不到<br>服务器，就会保存到第⼀台memcached服务器上。</p><h1 id="LRU算法，-slab分配，如何减少内存碎⽚"><a href="#LRU算法，-slab分配，如何减少内存碎⽚" class="headerlink" title="LRU算法， slab分配，如何减少内存碎⽚"></a>LRU算法， slab分配，如何减少内存碎⽚</h1><p>memcached预先将分配的内存分割成各种尺⼨的块(chunk)，并把尺⼨相同的块分成组(chunk的集合)，以此克服内<br>存碎⽚化问题</p><h1 id="如何解决缓存单机热点问题"><a href="#如何解决缓存单机热点问题" class="headerlink" title="如何解决缓存单机热点问题"></a>如何解决缓存单机热点问题</h1><p>a. 原因：<br>1、缓存服务器⾃身有限流保持<br>缓存服务器数量 * 单机能够承受的qps &gt; ⽤户最⼤的QPS 就会触发限流保护<br>针对这个原因：可以做横向扩容。加机器即可<br>2、⽤户访问过来cache服务器集中打到⼀台上⾯了。⼤流量并没有按预期的那样分摊到不同的cache机器上<br>导致出现单机热点。(热点数据)<br>针对这个原因：只要计算cache-hash算法不出问题，那基本上可以做到缓存的随机分布均匀的<br>3、缓存⾥⾯的value过⼤，导致虽然QPS不⾼，但⽹络流量（qps * 单个value的⼤⼩）还是过⼤，触发了cache<br>机器单台机器的⽹络流量限流；<br>针对这个原因：需要把⼤value进⾏精简，部分可以放在本机内存⽽不需要⾛远程获取这种⽅式的。<br>b. 解决⽅法：针对cache中元素key的访问监控。⼀旦发现cache有qps限流或⽹络⼤⼩限流时，能够通过监控看到到<br>底是哪个key并发访问量过⼤导致，或者哪些key返回的value⼤⼩较⼤，再结合cache散列算法，通过⼀定的规则动态<br>修改key值去平摊到各个cache机器上去。</p><h1 id="memcache与redis的区别"><a href="#memcache与redis的区别" class="headerlink" title="memcache与redis的区别"></a>memcache与redis的区别</h1><ol><li>Redis中，并不是所有的数据都⼀直存储在内存中的，这是和Memcached相⽐⼀个最⼤的区别。</li><li>Memcache仅仅⽀持简单的k/v类型的数据，Redis同时还提供String, list，set，hash等数据结构的存储。</li><li>Redis⽀持数据的备份，即master-slave模式的数据备份。</li><li>Redis⽀持数据的持久化，可以将内存中的数据保持在磁盘中（rdb定时快照和aof实时记录操作命令的⽇志备<br>份），重启的时候可以再次加载进⾏使⽤。Redis在很多⽅⾯具备数据库的特征，或者说就是⼀个数据库系统，⽽<br>Memcached只是简单的K/V缓存</li><li>Redis可以做⼀些聚合、排序操作。</li><li>memcache使⽤cas乐观锁做⼀致性：拿版本号，操作，对⽐版本号，如果⼀致就操作，不⼀致就放弃任何操作；</li><li>⼤数据memcached性能更⾼。由于Redis只使⽤单核，⽽Memcached可以使⽤多核，所以平均每⼀个核上<br>Redis在存储⼩数据时⽐Memcached性能更 ⾼。⽽在100k以上的数据中，Memcached性能要⾼于Redis 。</li></ol><h1 id="redis-本身有持久化，为什么还要写进-mysql-呢？"><a href="#redis-本身有持久化，为什么还要写进-mysql-呢？" class="headerlink" title="redis 本身有持久化，为什么还要写进 mysql 呢？"></a>redis 本身有持久化，为什么还要写进 mysql 呢？</h1><p>RDB：快照形式是直接把内存中的数据保存到⼀个 dump ⽂件中，定时保存，保存策略。<br>AOF：把所有的对Redis的服务器进⾏修改的命令都存到⼀个⽂件⾥，命令的集合。<br>RDB会丢数据，AOP性能不⾏<br>有改动先插⼊数据库，再插缓存，⽐较靠谱但性能⼀般；<br>有改动先插缓存，批量更新到数据库，靠谱度略差，但性能好。</p><h1 id="redis的数据结构和各种应⽤场景？"><a href="#redis的数据结构和各种应⽤场景？" class="headerlink" title="redis的数据结构和各种应⽤场景？"></a>redis的数据结构和各种应⽤场景？</h1><p>a. 更多的数据结构；<br>b. 可持久化；<br>c. 计数器；<br>d. 发布-订阅功能；<br>e. 事务功能；<br>f. 过期回调功能；<br>g. 队列功能；<br>h. 排序、聚合查询功能。</p><h1 id="redis数据结构？"><a href="#redis数据结构？" class="headerlink" title="redis数据结构？"></a>redis数据结构？</h1><p>a. Redis有5个基本数据结构，string、list、hash、set和zset。<br>b. String：string表示的是⼀个可变的字节数组，我们初始化字符串的内容、可以拿到字符串的⻓度，可以获<br>取string的⼦串，可以覆盖string的⼦串内容，可以追加⼦串。<br>c. List：Redis将列表数据结构命名为list⽽不是array，是因为列表的存储结构⽤的是链表⽽不是数组，⽽且链<br>表还是双向链表。因为它是链表，所以随机定位性能较弱，⾸尾插⼊删除性能较优。如果list的列表⻓度很<br>⻓，使⽤时我们⼀定要关注链表相关操作的时间复杂度。<br>d. hash：哈希等价于Java语⾔的HashMap或者是Python语⾔的dict，在实现结构上它使⽤⼆维结构，第⼀维是数<br>组，第⼆维是链表，hash的内容key和value存放在链表中，数组⾥存放的是链表的头指针。通过key查找元素时，先<br>计算key的hashcode，然后⽤hashcode对数组的⻓度进⾏取模定位到链表的表头，再对链表进⾏遍历获取到相应的<br>value值，链表的作⽤就是⽤来将产⽣了「hash碰撞」的元素串起来。Java语⾔开发者会感到⾮常熟悉，因为这样的<br>结构和HashMap是没有区别的。哈希的第⼀维数组的⻓度也是2^n。<br>e. set：Java程序员都知道HashSet的内部实现使⽤的是HashMap，只不过所有的value都指向同⼀个对象。<br>Redis的set结构也是⼀样，它的内部也使⽤hash结构，所有的value都指向同⼀个内部值。<br>f. SortedSet(zset)：是Redis提供的⼀个⾮常特别的数据结构，⼀⽅⾯它等价于Java的数据结构Map&lt;String,<br>Double&gt;，可以给每⼀个元素value赋予⼀个权重score，另⼀⽅⾯它⼜类似于TreeSet，内部的元素会按照权重<br>score进⾏排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。</p><h1 id="codis和redis集群的区别？"><a href="#codis和redis集群的区别？" class="headerlink" title="codis和redis集群的区别？"></a>codis和redis集群的区别？</h1><h1 id="redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高"><a href="#redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高" class="headerlink" title="redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高"></a>redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高</h1><p>区别：<br>1.mc可缓存图片和视频。rd支持除k/v更多的数据结构;<br>2.rd可以使用虚拟内存，rd可持久化和aof灾难恢复，rd通过主从支持数据备份;<br>3.rd可以做消息队列。<br>原因：mc多线程模型引入了缓存一致性和锁，加锁带来了性能损耗。</p><h1 id="redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？"><a href="#redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？" class="headerlink" title="redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？"></a>redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？</h1><p>主从复制实现：主节点将自己内存中的数据做一份快照，将快照发给从节点，从节点将数据恢复到内存中。之后再每次增加新数据的时候，主节点以类似于mysql的二进制日志方式将语句发送给从节点，从节点拿到主节点发送过来的语句进行重放。<br>分片方式：<br>-客户端分片<br>-基于代理的分片<br>● Twemproxy<br>● codis<br>-路由查询分片<br>● Redis-cluster（本身提供了自动将数据分散到Redis Cluster不同节点的能力，整个数据集合的某个数据子集存储在哪个节点对于用户来说是透明的）<br>redis-cluster分片原理：Cluster中有一个16384长度的槽(虚拟槽)，编号分别为0-16383。每个Master节点都会负责一部分的槽，当有某个key被映射到某个Master负责的槽，那么这个Master负责为这个key提供服务，至于哪个Master节点负责哪个槽，可以由用户指定，也可以在初始化的时候自动生成，只有Master才拥有槽的所有权。Master节点维护着一个16384/8字节的位序列，Master节点用bit来标识对于某个槽自己是否拥有。比如对于编号为1的槽，Master只要判断序列的第二位（索引从0开始）是不是为1即可。这种结构很容易添加或者删除节点。比如如果我想新添加个节点D, 我需要从节点A、B、 C中得部分槽到D上。</p><h1 id="使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？"><a href="#使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？" class="headerlink" title="使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？"></a>使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？</h1><p>redis:<br>1.线程A setnx(上锁的对象,超时时的时间戳t1)，如果返回true，获得锁。<br>2.线程B 用get获取t1,与当前时间戳比较,判断是是否超时,没超时false,若超时执行第3步;<br>3.计算新的超时时间t2,使用getset命令返回t3(该值可能其他线程已经修改过),如果t1==t3，获得锁，如果t1!=t3说明锁被其他线程获取了。<br>4.获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）。<br>zk:<br>1.客户端对某个方法加锁时，在zk上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点node1;<br>2.客户端获取该路径下所有已经创建的子节点，如果发现自己创建的node1的序号是最小的，就认为这个客户端获得了锁。<br>3.如果发现node1不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待。<br>4.获取锁后，处理完逻辑，删除自己创建的node1即可。<br>区别:zk性能差一些，开销大，实现简单。</p><h1 id="知道redis的持久化吗？底层如何实现的？有什么优点缺点？"><a href="#知道redis的持久化吗？底层如何实现的？有什么优点缺点？" class="headerlink" title="知道redis的持久化吗？底层如何实现的？有什么优点缺点？"></a>知道redis的持久化吗？底层如何实现的？有什么优点缺点？</h1><p>RDB(Redis DataBase:在不同的时间点将redis的数据生成的快照同步到磁盘等介质上):内存到硬盘的快照，定期更新。缺点：耗时，耗性能(fork+io操作)，易丢失数据。<br>AOF(Append Only File：将redis所执行过的所有指令都记录下来，在下次redis重启时，只需要执行指令就可以了):写日志。缺点：体积大，恢复速度慢。</p><p>bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会消耗比较长的时间，不够实时，在停机的时候会导致大量的数据丢失，需要aof来配合，在redis实例重启时，优先使用aof来恢复内存的状态，如果没有aof日志，就会使用rdb文件来恢复。Redis会定期做aof重写，压缩aof文件日志大小。Redis4.0之后有了混合持久化的功能，将bgsave的全量和aof的增量做了融合处理，这样既保证了恢复的效率又兼顾了数据的安全性。bgsave的原理，fork和cow, fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。</p><h1 id="redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？"><a href="#redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？" class="headerlink" title="redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？"></a>redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？</h1><p>过期策略:<br>定时过期(一key一定时器)，惰性过期：只有使用key时才判断key是否已过期，过期则清除。定期过期：前两者折中。<br>LRU:new LinkedHashMap&lt;K, V&gt;(capacity, DEFAULT_LOAD_FACTORY, true);<br>//第三个参数置为true，代表linkedlist按访问顺序排序，可作为LRU缓存；设为false代表按插入顺序排序，可作为FIFO缓存<br>LRU算法实现：1.通过双向链表来实现，新数据插入到链表头部；2.每当缓存命中（即缓存数据被访问），则将数据移到链表头部；3.当链表满的时候，将链表尾部的数据丢弃。</p><p>LinkedHashMap：HashMap和双向链表合二为一即是LinkedHashMap。HashMap是无序的，LinkedHashMap通过维护一个额外的双向链表保证了迭代顺序。该迭代顺序可以是插入顺序（默认），也可以是访问顺序。</p><h1 id="缓存穿透、缓存击穿、缓存雪崩解决方案？"><a href="#缓存穿透、缓存击穿、缓存雪崩解决方案？" class="headerlink" title="缓存穿透、缓存击穿、缓存雪崩解决方案？"></a>缓存穿透、缓存击穿、缓存雪崩解决方案？</h1><p>缓存穿透：指查询一个一定不存在的数据，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，可能导致DB挂掉。<br>解决方案：1.查询返回的数据为空，仍把这个空结果进行缓存，但过期时间会比较短；2.布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对DB的查询。<br>缓存击穿：对于设置了过期时间的key，缓存在某个时间点过期的时候，恰好这时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把DB压垮。<br>解决方案：1.使用互斥锁：当缓存失效时，不立即去load db，先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时再进行load db的操作并回设缓存，否则重试get缓存的方法。2.永远不过期：物理不过期，但逻辑过期（后台异步线程去刷新）。<br>缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。与缓存击穿的区别：雪崩是很多key，击穿是某一个key缓存。<br>解决方案：将缓存失效时间分散开，比如可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p><h1 id="在选择缓存时，什么时候选择redis，什么时候选择memcached"><a href="#在选择缓存时，什么时候选择redis，什么时候选择memcached" class="headerlink" title="在选择缓存时，什么时候选择redis，什么时候选择memcached"></a>在选择缓存时，什么时候选择redis，什么时候选择memcached</h1><p>选择redis的情况：</p><p>      1、复杂数据结构，value的数据是哈希，列表，集合，有序集合等这种情况下，会选择redis, 因为memcache无法满足这些数据结构，最典型的的使用场景是，用户订单列表，用户消息，帖子评论等。</p><p>      2、需要进行数据的持久化功能，但是注意，不要把redis当成数据库使用，如果redis挂了，内存能够快速恢复热数据，不会将压力瞬间压在数据库上，没有cache预热的过程。对于只读和数据一致性要求不高的场景可以采用持久化存储</p><p>      3、高可用，redis支持集群，可以实现主动复制，读写分离，而对于memcache如果想要实现高可用，需要进行二次开发。</p><p>      4、存储的内容比较大，memcache存储的value最大为1M。</p><p>选择memcache的场景：</p><p>     1、纯KV,数据量非常大的业务，使用memcache更合适，原因是，</p><p>           a)memcache的内存分配采用的是预分配内存池的管理方式，能够省去内存分配的时间，redis是临时申请空间，可能导致碎片化。</p><p>           b)虚拟内存使用，memcache将所有的数据存储在物理内存里，redis有自己的vm机制，理论上能够存储比物理内存更多的数据，当数据超量时，引发swap,把冷数据刷新到磁盘上，从这点上，数据量大时，memcache更快</p><p>           c)网络模型，memcache使用非阻塞的IO复用模型，redis也是使用非阻塞的IO复用模型，但是redis还提供了一些非KV存储之外的排序，聚合功能，复杂的CPU计算，会阻塞整个IO调度，从这点上由于redis提供的功能较多，memcache更快些</p><p>           d) 线程模型，memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程可能存在锁冲突。redis使用的单线程，虽然无锁冲突，但是难以利用多核的特性提升吞吐量。</p><h1 id="缓存与数据库不一致怎么办"><a href="#缓存与数据库不一致怎么办" class="headerlink" title="缓存与数据库不一致怎么办"></a>缓存与数据库不一致怎么办</h1><p>假设采用的主存分离，读写分离的数据库，</p><p>如果一个线程A先删除缓存数据，然后将数据写入到主库当中，这个时候，主库和从库同步没有完成，线程B从缓存当中读取数据失败，从从库当中读取到旧数据，然后更新至缓存，这个时候，缓存当中的就是旧的数据。</p><p>发生上述不一致的原因在于，主从库数据不一致问题，加入了缓存之后，主从不一致的时间被拉长了</p><p>处理思路：在从库有数据更新之后，将缓存当中的数据也同时进行更新，即当从库发生了数据更新之后，向缓存发出删除，淘汰这段时间写入的旧数据。</p><h1 id="主从数据库不一致如何解决"><a href="#主从数据库不一致如何解决" class="headerlink" title="主从数据库不一致如何解决"></a>主从数据库不一致如何解决</h1><p>场景描述，对于主从库，读写分离，如果主从库更新同步有时差，就会导致主从库数据的不一致</p><p>1、忽略这个数据不一致，在数据一致性要求不高的业务下，未必需要时时一致性</p><p>2、强制读主库，使用一个高可用的主库，数据库读写都在主库，添加一个缓存，提升数据读取的性能。</p><p>3、选择性读主库，添加一个缓存，用来记录必须读主库的数据，将哪个库，哪个表，哪个主键，作为缓存的key,设置缓存失效的时间为主从库同步的时间，如果缓存当中有这个数据，直接读取主库，如果缓存当中没有这个主键，就到对应的从库中读取。</p><h1 id="Redis常见的性能问题和解决方案"><a href="#Redis常见的性能问题和解决方案" class="headerlink" title="Redis常见的性能问题和解决方案"></a>Redis常见的性能问题和解决方案</h1><p>1、master最好不要做持久化工作，如RDB内存快照和AOF日志文件<br>2、如果数据比较重要，某个slave开启AOF备份，策略设置成每秒同步一次<br>3、为了主从复制的速度和连接的稳定性，master和Slave最好在一个局域网内<br>4、尽量避免在压力大得主库上增加从库<br>5、主从复制不要采用网状结构，尽量是线性结构，<code>Master&lt;-- Slave1 &lt;--Slave2</code></p><h1 id="Redis的数据淘汰策略有哪些"><a href="#Redis的数据淘汰策略有哪些" class="headerlink" title="Redis的数据淘汰策略有哪些"></a>Redis的数据淘汰策略有哪些</h1><p>voltile-lru 从已经设置过期时间的数据集中挑选最近最少使用的数据淘汰<br>voltile-ttl 从已经设置过期时间的数据库集当中挑选将要过期的数据<br>voltile-random 从已经设置过期时间的数据集任意选择淘汰数据<br>allkeys-lru 从数据集中挑选最近最少使用的数据淘汰<br>allkeys-random 从数据集中任意选择淘汰的数据<br>no-eviction 禁止驱逐数据</p><h1 id="Redis当中有哪些数据结构"><a href="#Redis当中有哪些数据结构" class="headerlink" title="Redis当中有哪些数据结构"></a>Redis当中有哪些数据结构</h1><p>字符串String、字典Hash、列表List、集合Set、有序集合SortedSet。如果是高级用户，那么还会有，如果你是Redis中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。</p><h1 id="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来"><a href="#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来" class="headerlink" title="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来</h1><p>使用keys指令可以扫出指定模式的key列表。</p><p>对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</p><p>这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p><h1 id="使用Redis做过异步队列吗，是如何实现的"><a href="#使用Redis做过异步队列吗，是如何实现的" class="headerlink" title="使用Redis做过异步队列吗，是如何实现的"></a>使用Redis做过异步队列吗，是如何实现的</h1><p>使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。</p><h1 id="Redis如何实现延时队列"><a href="#Redis如何实现延时队列" class="headerlink" title="Redis如何实现延时队列"></a>Redis如何实现延时队列</h1><p>使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理</p><h1 id="Redis为什么使用单进程单线程方式也这么快"><a href="#Redis为什么使用单进程单线程方式也这么快" class="headerlink" title="Redis为什么使用单进程单线程方式也这么快"></a>Redis为什么使用单进程单线程方式也这么快</h1><p>Redis采用的是基于内存的采用的是单进程单线程模型的KV数据库，由C语言编写。官方提供的数据是可以达到100000+的qps。这个数据不比采用单进程多线程的同样基于内存的KV数据库Memcached差。<br>Redis快的主要原因是：<br>完全基于内存<br>数据结构简单，对数据操作也简单<br>使用多路 I/O 复用模型<br>第一、二点不细讲，主要围绕第三点采用多路 I/O 复用技术来展开。<br>多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。</p><p>单进程单线程好处<br>代码更清晰，处理逻辑更简单<br>不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗<br>不存在多进程或者多线程导致的切换而消耗CPU<br>单进程单线程弊端<br>无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；<br>其他一些优秀的开源软件采用的模型<br>多进程单线程模型：Nginx<br>单进程多线程模型：Memcached</p><h1 id="Redis对象类型简介"><a href="#Redis对象类型简介" class="headerlink" title="Redis对象类型简介"></a>Redis对象类型简介</h1><p>字符串：int，raw或者embstr。Long 简单动态字符串<br>列表：ziplist(压缩列表) 和 linkedlist(双端链表)<br>哈希：ziplist 或者 hashtable。<br>集合对象：intset 或者 hashtable。整数集合，字典。<br>有序集合： ziplist 或者 skiplist。压缩列表，跳跃表</p><p>跳跃表(skiplist)是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。<br>  跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。<br>  在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。<br>  Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员(member)是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。<br>  和链表、字典等数据结构被广泛地应用在Redis内部不同，Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。</p><p>简单动态字符串</p><p>链表<br>　Redis链表特性：<br>　　①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。<br>　　②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　<br>　　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。<br>　　④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。</p><p>字典<br>　Redis 的字典使用哈希表作为底层实现<br>有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来解决哈希冲突。<br>redis支持多种数据结构，其中dict是使用频率相当高，也是非常实用的一种结构。在redis的具体实现中，使用了一种叫做渐进式哈希(rehashing)的机制来提高dict的缩放效率，<br>渐进式哈希的精髓在于：数据的迁移不是一次性完成的，而是可以通过dictRehash()这个函数分步规划的，并且调用方可以及时知道是否需要继续进行渐进式哈希操作。如果dict数据结构中存储了海量的数据，那么一次性迁移势必带来redis性能的下降，别忘了redis是单线程模型，在实时性要求高的场景下这可能是致命的。而渐进式哈希则将这种代价可控地分摊了，调用方可以在dict做插入，删除，更新的时候执行dictRehash()，最小化数据迁移的代价。 </p><p>跳跃表<br>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：<br>　　1、由很多层结构组成；<br>　　2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；<br>　　3、最底层的链表包含了所有的元素；<br>　　4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；<br>　　5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；<br>整数集合<br>支持升级，不支持降级<br>　整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。<br>压缩列表<br>压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。<br>　　压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。</p><h1 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h1><p>Redis 相对于 Memcache 等其他的缓存产品，有一个比较明显的优势就是 Redis 不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。这几种丰富的数据类型我们花了两篇文章进行了详细的介绍，接下来我们要介绍 Redis 的另外一大优势——持久化。<br>Redis 支持两种形式的持久化，一种是RDB快照（snapshotting），另外一种是AOF（append-only-file）。</p><p>　RDB 有两种触发方式，分别是自动触发和手动触发。<br>在 redis.conf 配置文件中的 SNAPSHOTTING 下<br>save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。<br>bgsave<br>　　执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体操作是Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</p><h1 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h1><p>开启 AOF<br>　　将 redis.conf 的 appendonly 配置改为 yes 即可。<br>Redis的持久化方式之一RDB是通过保存数据库中的键值对来记录数据库的状态。而另一种持久化方式 AOF 则是通过保存Redis服务器所执行的写命令来记录数据库状态。<br>优点：<br>　　①、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。<br>　　②、AOF 文件使用 Redis 命令追加的形式来构造，因此，即使 Redis 只能向 AOF 文件写入命令的片断，使用 redis-check-aof 工具也很容易修正 AOF 文件。<br>　　③、AOF 文件的格式可读性较强，这也为使用者提供了更灵活的处理方式。例如，如果我们不小心错用了 FLUSHALL 命令，在重写还没进行时，我们可以手工将最后的 FLUSHALL 命令去掉，然后再使用 AOF 来恢复数据。<br>　　缺点：<br>　　①、对于具有相同数据的的 Redis，AOF 文件通常会比 RDF 文件体积更大。<br>　　②、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。但在 Redis 的负载较高时，RDB 比 AOF 具好更好的性能保证。<br>　　③、RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从理论上说，RDB 比 AOF 方式更健壮。官方文档也指出，AOF 的确也存在一些 BUG，这些 BUG 在 RDB 没有存在。<br> 　　那么对于 AOF 和 RDB 两种持久化方式，我们应该如何选择呢？<br>　　如果可以忍受一小段时间内数据的丢失，毫无疑问使用 RDB 是最好的，定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，而且使用 RDB 还可以避免 AOF 一些隐藏的 bug；否则就使用 AOF 重写。但是一般情况下建议不要单独使用某一种持久化机制，而是应该两种一起用，在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。Redis后期官方可能都有将两种持久化方式整合为一种持久化模型。</p><h1 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h1><p>通常会采取的一种方式是主从架构Master/Slave，Master 以写为主，Slave 以读为主，Master 主节点更新后根据配置，自动同步到从机Slave 节点。<br>1 redis-server –port 6380 –slaveof<master-ip><master-port>，配置当前服务为某Redis服务的Slave<br>2 SLAVEOF host port命令，将当前服务器状态从Master修改为别的服务器的Slave<br>redis&gt;SLAVEOF 192.169.0.110 6379，将服务器转换为Slave<br>redis&gt;SLAVEOF NO ONE 将服务器状态重新恢复到Master，不会丢弃已同步的数据<br>3 配置方式：启动时，服务器读取配置文件，并自动成为指定服务器的从服务器<br>slaveof <master-ip><master-port><br>slaveof 127.0.0.1 6379</master-port></master-ip></master-port></master-ip></p><h1 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h1><p>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： <br>-  从服务器连接主服务器，发送SYNC命令； <br>-  主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； <br>-  主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； <br>-  从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； <br>-  主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； <br>-  从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</p><h1 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h1><p>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 <br>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。  </p><h1 id="Redis主从同步策略"><a href="#Redis主从同步策略" class="headerlink" title="Redis主从同步策略"></a>Redis主从同步策略</h1><p>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><p>如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机。</p><p>在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。<br> 不持久化的主服务器自动重启非常危险呢？</p><p>复制原理<br>       1、Slave启动成功连接到master后会发送一个sync命令；<br>       2、Master接到命令启动后的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master<br>            将传送整个数据文件到slave，以完成一次完全同步；<br>       3、全量复制：而slave服务在数据库文件数据后，将其存盘并加载到内存中；<br>       4、增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步；<br>       5、但是只要是重新连接master，一次完全同步（全量复制）将被自动执行。<br>五、哨兵模式（sentinel）<br>       反客为主的自动版，能够后台监控Master库是否故障，如果故障了根据投票数自动将slave库转换为主库。一组sentinel能<br>       同时监控多个Master。<br>       使用步骤：<br>       1、在Master对应redis.conf同目录下新建sentinel.conf文件，名字绝对不能错；<br>       2、配置哨兵，在sentinel.conf文件中填入内容：<br>             sentinel monitor 被监控数据库名字（自己起名字） ip port 1<br>             说明：上面最后一个数字1，表示主机挂掉后slave投票看让谁接替成为主机，得票数多少后成为主机。<br>      3、启动哨兵模式：<br>            命令键入：redis-sentinel  /myredis/sentinel.conf<br>           注：上述sentinel.conf路径按各自实际情况配置<br>六、复制的缺点<br>            延时，由于所有的写操作都是在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定<br>       的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使得这个问题更加严重。</p><h1 id="redis的过期策略以及内存淘汰机制"><a href="#redis的过期策略以及内存淘汰机制" class="headerlink" title="redis的过期策略以及内存淘汰机制"></a>redis的过期策略以及内存淘汰机制</h1><p>分析:这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?<br>回答:<br>redis采用的是定期删除+惰性删除策略。<br>为什么不用定时删除策略?<br>定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.<br>定期删除+惰性删除是如何工作的呢?<br>定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。<br>于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</p><h1 id="如何应对缓存穿透和缓存雪崩问题-1"><a href="#如何应对缓存穿透和缓存雪崩问题-1" class="headerlink" title="如何应对缓存穿透和缓存雪崩问题"></a>如何应对缓存穿透和缓存雪崩问题</h1><p>分析:这两个问题，说句实在话，一般中小型传统软件企业，很难碰到这个问题。如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。<br>回答:如下所示<br>缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。<br>解决方案:<br>(一)利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试<br>(二)采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。<br>(三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。<br>缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。<br>解决方案:<br>(一)给缓存的失效时间，加上一个随机值，避免集体失效。<br>(二)使用互斥锁，但是该方案吞吐量明显下降了。<br>(三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点<br>I 从缓存A读数据库，有则直接返回<br>II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。<br>III 更新线程同时更新缓存A和缓存B。</p><h1 id="如何解决redis的并发竞争key问题"><a href="#如何解决redis的并发竞争key问题" class="headerlink" title="如何解决redis的并发竞争key问题"></a>如何解决redis的并发竞争key问题</h1><p>分析:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。<br>回答:如下所示<br>(1)如果对这个key操作，不要求顺序<br>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。<br>(2)如果对这个key操作，要求顺序<br>假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.<br>期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下<br>那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。<br>其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。</p><h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><p>redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。<br>Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点。<br>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据。只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。<br>需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。</p><h1 id="redis和memcached的区别（总结）"><a href="#redis和memcached的区别（总结）" class="headerlink" title="redis和memcached的区别（总结）"></a>redis和memcached的区别（总结）</h1><p>Redis和Memcache都是将数据存放在内存中<br>1.数据类型<br>Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储；<br>2.过期<br>过期策略–memcache在set时就指定，例如set key1 0 0 8,即永不过期。Redis可以通过例如expire 设定，例如expire name 10；<br>3.持久化，数据恢复，快照，aof<br>4.集群，主从复制</p><h1 id="什么是-Redis？"><a href="#什么是-Redis？" class="headerlink" title="什么是 Redis？"></a>什么是 Redis？</h1><p>Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统<br>加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。因为<br>是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能<br>最快的 Key-Value DB。<br>Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个<br>value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用<br>来实现很多有用的功能，比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性 能<br>消息队列服务，用他的 Set 可以做高性能的 tag 系统等等。另外 Redis 也可以对存入的<br>Key-Value 设置 expire 时间，因此也可以被当作一 个功能加强版的 memcached 来用。<br>Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因<br>此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。<br>2、Redis 相比 memcached 有哪些优势？<br>(1) memcached 所有的值均是简单的字符串，Redis 作为其替代者，支持更为丰富的数据类<br>型<br>(2) Redis 的速度比 memcached 快很多<br>(3) Redis 可以持久化其数据<br>3、Redis 支持哪几种数据类型？<br>String、List、Set、Sorted Set、hashes<br>4、Redis 主要消耗什么物理资源？<br>内存。<br>5、Redis 的全称是什么？<br>Remote Dictionary Server。<br>6、Redis 有哪几种数据淘汰策略？<br>noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大<br>部分的写入指令，但 DEL 和几个例外）<br>allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。<br>volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据<br>有空间存放。<br>allkeys-random: 回收随机的键使得新添加的数据有空间存放。<br>volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。<br>volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的<br>数据有空间存放。<br>7、Redis 官方为什么不提供 Windows 版本？<br>因为目前 Linux 版本已经相当稳定，而且用户量很大，无需开发 windows 版本，反而会带来<br>兼容性等问题。<br>8、一个字符串类型的值能存储最大容量是多少？<br>512M<br>9、为什么 Redis 需要把所有数据放到内存中？<br>Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。<br>所以 Redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重<br>影响 Redis 的性能。在内存越来越便宜的今天，Redis 将会越来越受欢迎。<br>如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。<br>10、Redis 集群方案应该怎么做？都有哪些方案？<br>1.twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通 Redis 无任何区别，<br>设置好它下属的多个 Redis 实例后，使用时在本需要连接 Redis 的地方改为连接<br>twemproxy，它会以一个代理的身份接收请求并使用一致性 hash 算法，将请求转接到具<br>体 Redis，将结果再返回 twemproxy。使用方式简便(相对 Redis 只需修改连接端口)，对<br>旧项目扩展的首选。 问题：twemproxy 自身单端口实例的压力，使用一致性 hash 后，对<br>Redis 节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。<br>2. codis，目前用的最多的集群方案，基本和 twemproxy 一致的效果，但它支持在 节点<br>数量改变情况下，旧节点数据可恢复到新 hash 节点。<br>3. Redis cluster3.0 自带的集群，特点在于他的分布式算法不是一致性 hash，而是 hash<br>槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。<br>4.在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 key 进行 hash 计算，<br>然后去对应的 Redis 实例操作数据。 这种方式对 hash 层代码要求比较高，考虑部分包括，<br>节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。<br>11、Redis 集群方案什么情况下会导致整个集群不可用？<br>有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就<br>会以为缺少 5501-11000 这个范围的槽而不可用。<br>12、MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，<br>如何保证 Redis 中的数据都是热点数据？<br>Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。<br>13、Redis 有哪些适合的场景？<br>（1）、会话缓存（Session Cache）<br>最常用的一种使用 Redis 的情景是会话缓存（session cache）。用 Redis 缓存会话比其他<br>存储（如 Memcached）的优势在于：Redis 提供持久化。当维护一个不是严格要求一致性<br>的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样<br>吗？<br>幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文<br>档。甚至广为人知的商业平台 Magento 也提供 Redis 的插件。<br>（2）、全页缓存（FPC）<br>除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启<br>了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极<br>大改进，类似 PHP 本地 FPC。<br>再次以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。<br>此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-Redis，这个插件<br>能帮助你以最快速度加载你曾浏览过的页面。<br>（3）、队列<br>Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个<br>很好的消息队列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如<br>Python）对 list 的 push/pop 操作。<br>如果你快速的在 Google 中搜索“Redis queues”，你马上就能找到大量的开源项目，这些<br>项目的目的就是利用 Redis 创建非常好的后端工具，以满足各种队列需求。例如，Celery<br>有一个后台就是使用 Redis 作为 broker，你可以从这里去查看。<br>（4）、排行榜/计数器<br>Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted<br>Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据<br>结构。所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们称之为<br>“user_scores”，我们只需要像下面一样执行即可：<br>当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你<br>需要这样执行：<br>ZRANGE user_scores 0 10 WITHSCORES<br>Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储<br>数据的，你可以在这里看到。<br>（5）、发布/订阅<br>最后（但肯定不是最不重要的）是 Redis 的发布/订阅功能。发布/订阅的使用场景确实非<br>常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至<br>用 Redis 的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。<br>14、Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？<br>Redisson、Jedis、lettuce 等等，官方推荐使用 Redisson。<br>15、Redis 和 Redisson 有什么关系？<br>Redisson 是一个高级的分布式协调 Redis 客服端，能帮助用户在分布式环境中轻松实现一<br>些 Java 的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。<br>16、Jedis 与 Redisson 对比有什么优缺点？<br>Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持；<br>Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，功能较为简单，不支<br>持字符串操作，不支持排序、事务、管道、分区等 Redis 特性。Redisson 的宗旨是促进使<br>用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。<br>17、Redis 如何设置密码及验证密码？<br>设置密码：config set requirepass 123456<br>授权密码：auth 123456<br>18、说说 Redis 哈希槽的概念？<br>Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，<br>每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分<br>hash 槽。<br>19、Redis 集群的主从复制模型是怎样的？<br>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主<br>从复制模型,每个节点都会有 N-1 个复制品. 20、Redis 集群会有写操作丢失吗？为什么？<br>Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操<br>作。<br>21、Redis 集群之间是如何复制的？<br>异步复制<br>22、Redis 集群最大节点个数是多少？<br>16384 个。<br>23、Redis 集群如何选择数据库？<br>Redis 集群目前无法做数据库选择，默认在 0 数据库。<br>24、怎么测试 Redis 的连通性？<br>ping<br>25、Redis 中的管道有什么用？<br>一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命<br>令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。<br>这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现<br>支持这个功能，大大加快了从服务器下载新邮件的过程。<br>26、怎么理解 Redis 事务？<br>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的<br>过程中，不会被其他客户端发送来的命令请求所打断。<br>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。<br>27、Redis 事务相关的命令有哪几个？<br>MULTI、EXEC、DISCARD、WATCH<br>28、Redis key 的过期时间和永久有效分别怎么设置？<br>EXPIRE 和 PERSIST 命令。<br>29、Redis 如何做内存优化？<br>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，<br>所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的 web 系统中有一个<br>用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key,而是应该把这个用户<br>的所有信息存储到一张散列表里面. 30、Redis 回收进程如何工作的？<br>一个客户端运行了新的命令，添加了新的数据。<br>Redi 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。<br>一个新的命令被执行，等等。<br>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。<br>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不<br>用多久内存限制就会被这个内存使用量超越。<br>31、Redis 回收使用的是什么算法？<br>LRU 算法<br>32、Redis 如何做大量数据插入？<br>Redis2.6 开始 Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工<br>作。<br>33、为什么要做 Redis 分区？<br>分区可以让 Redis 管理更大的内存，Redis 将可以使用所有机器的内存。如果没有分区，你<br>最多只能使用一台机器的内存。分区使 Redis 的计算能力通过简单地增加计算机得到成倍提<br>升,Redis 的网络带宽也会随着计算机和网卡的增加而成倍增长。<br>34、你知道有哪些 Redis 分区实现方案？<br>客户端分区就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节<br>点读取。大多数客户端已经实现了客户端分区。<br>代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。<br>代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。<br>Redis 和 memcached 的一种代理实现就是 Twemproxy<br>查询路由(Query routing) 的意思是客户端随机地请求任意一个 Redis 实例，然后由 Redis<br>将请求转发给正确的 Redis 节点。Redis Cluster 实现了一种混合形式的查询路由，但并不<br>是直接将请求从一个 Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接<br>redirected 到正确的 Redis 节点。<br>35、Redis 分区有什么缺点？<br>涉及多个 key 的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存<br>储到不同的 Redis 实例（实际上这种情况也有办法，但是不能直接使用交集指令）。<br>同时操作多个 key,则不能使用 Redis 事务. 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning<br>granularity is the key, so it is not possible to shard a dataset with a single huge<br>key like a very big sorted set）. 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的 Redis 实例和主<br>机同时收集 RDB / AOF 文件。<br>分区时动态扩容或缩容可能非常复杂。Redis 集群在运行时增加或者删除 Redis 节点，能<br>做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持<br>这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。<br>36、Redis 持久化数据和缓存怎么做扩容？<br>如果 Redis 被当做缓存使用，使用一致性哈希实现动态扩容缩容。<br>如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关系，节点的<br>数量一旦确定不能变化。否则的话(即 Redis 节点需要动态变化的情况），必须使用可以在运<br>行时进行数据再平衡的一套系统，而当前只有 Redis 集群可以做到这样。<br>37、分布式 Redis 是前期做还是后期规模上来了再做好？为<br>什么？<br>既然 Redis 是如此的轻量（单实例只使用 1M 内存）,为防止以后的扩容，最好的办法就是<br>一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让 Redis 以分布式的<br>方式运行，使用分区，在同一台服务器上启动多个实例。<br>一开始就多设置几个 Redis 实例，例如 32 或者 64 个实例，对大多数用户来说这操作起来<br>可能比较麻烦，但是从长久来看做这点牺牲是值得的。<br>这样的话，当你的数据不断增长，需要更多的 Redis 服务器时，你需要做的就是仅仅将 Redis<br>实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了<br>另一台服务器，你需要将你一半的 Redis 实例从第一台机器迁移到第二台机器。<br>38、Twemproxy 是什么？<br>Twemproxy 是 Twitter 维护的（缓存）代理系统，代理 Memcached 的 ASCII 协议和 Redis<br>协议。它是单线程程序，使用 c 语言编写，运行起来非常快。它是采用 Apache 2.0 license<br>的开源软件。<br>Twemproxy 支持自动分区，如果其代理的其中一个 Redis 节点不可用时，会自动将该节点<br>排除（这将改变原来的 keys-instances 的映射关系，所以你应该仅在把 Redis 当缓存时使<br>用 Twemproxy)。<br>Twemproxy 本身不存在单点问题，因为你可以启动多个 Twemproxy 实例，然后让你的客<br>户端去连接任意一个 Twemproxy 实例。<br>Twemproxy 是 Redis 客户端和服务器端的一个中间层，由它来处理分区功能应该不算复杂，<br>并且应该算比较可靠的。<br>39、支持一致性哈希的客户端有哪些？<br>Redis-rb、PRedis 等。<br>40、Redis 与其他 key-value 存储有什么不同？<br>Redis 有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库<br>的进化路径。Redis 的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外<br>的抽象。<br>Redis 运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡<br>内存，应为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上<br>相同的复杂的数据结构，在内存中操作起来非常简单，这样 Redis 可以做很多内部复杂性<br>很强的事情。 同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需<br>要进行随机访问。<br>41、Redis 的内存占用情况怎么样？<br>给你举个例子： 100 万个键值对（键是 0 到 999999 值是字符串“hello world”）在我的<br>32 位的 Mac 笔记本上 用了 100MB。同样的数据放到一个 key 里只需要 16MB， 这是<br>因为键值有一个很大的开销。 在 Memcached 上执行也是类似的结果，但是相对 Redis<br>的开销要小一点点，因为 Redis 会记录类型信息引用计数等等。<br>当然，大键值对时两者的比例要好很多。<br>64 位的系统比 32 位的需要更多的内存开销，尤其是键值对都较小时，这是因为 64 位的系<br>统里指针占用了 8 个字节。 但是，当然，64 位系统支持更大的内存，所以为了运行大型<br>的 Redis 服务器或多或少的需要使用 64 位的系统。<br>42、都有哪些办法可以降低 Redis 的内存使用情况呢？<br>如果你使用的是 32 位的 Redis 实例，可以好好利用 Hash,list,sorted set,set 等集合类型数据，<br>因为通常情况下很多小的 Key-Value 可以用更紧凑的方式存放到一起。<br>43、查看 Redis 使用情况及状态信息用什么命令？<br>info<br>44、Redis 的内存用完了会发生什么？<br>如果达到设置的上限，Redis 的写命令会返回错误信息（但是读命令还可以正常返回。）或<br>者你可以将 Redis 当缓存来使用配置淘汰机制，当 Redis 达到内存上限时会冲刷掉旧的内容。<br>45、Redis 是单线程的，如何提高多核 CPU 的利用率？<br>可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时<br>候，无论如何一个服务器是不够的，<br>所以，如果你想使用多个 CPU，你可以考虑一下分片（shard）。<br>46、一个 Redis 实例最多能存放多少的 keys？List、Set、<br>Sorted Set 他们最多能存放多少元素？<br>理论上 Redis 可以处理多达 232 的 keys，并且在实际中进行了测试，每个实例至少存放了 2<br>亿 5 千万的 keys。我们正在测试一些较大的值。<br>任何 list、set、和 sorted set 都可以放 232 个元素。<br>换句话说，Redis 的存储极限是系统中的可用内存值。<br>47、Redis 常见性能问题和解决方案？<br>(1) Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件<br>(2) 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次<br>(3) 为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网内<br>(4) 尽量避免在压力很大的主库上增加从库<br>(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2<br>&lt;- Slave3… 这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可<br>以立刻启用 Slave1 做 Master，其他不变。<br>48、Redis 提供了哪几种持久化方式？<br>RDB 持久化方式能够在指定的时间间隔能对你的数据进行快照存储. AOF 持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来<br>恢复原始的数据,AOF 命令以 Redis 协议追加保存每次写的操作到文件末尾.Redis 还能对<br>AOF 文件进行后台重写,使得 AOF 文件的体积不至于过大. 如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式. 你也可以同时开启两种持久化方式, 在这种情况下, 当 Redis 重启的时候会优先载入 AOF<br>文件来恢复原始的数据,因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数<br>据集要完整. 最重要的事情是了解 RDB 和 AOF 持久化方式的不同,让我们以 RDB 持久化方式开始。<br>49、如何选择合适的持久化方式？<br>一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久<br>化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以<br>只使用 RDB 持久化。<br>有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照<br>（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复<br>的速度要快，除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug。<br>50、修改配置不重启 Redis 会实时生效吗？<br>针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何<br>形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式<br>而不需要重启 Redis。检索 ‘CONFIG GET *’ 命令获取更多信息。<br>但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前<br>CONFIG 命令还不支持的配置参数的时候。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/b9efb3c36627.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/b9efb3c36627.html" class="post-title-link" itemprop="url">Dubbo</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:22:55" itemprop="dateCreated datePublished" datetime="2023-12-20T16:22:55+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-23 22:16:32" itemprop="dateModified" datetime="2023-12-23T22:16:32+08:00">2023-12-23</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="Dubbo是什么？"><a href="#Dubbo是什么？" class="headerlink" title="Dubbo是什么？"></a>Dubbo是什么？</h1><ul><li>Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案</li><li>简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的东东，说白了就是个远程服务调用的分布式框架（告别Web Service模式中的WSdl，以服务者与消费者的方式在dubbo上注册）</li><li>其核心部分包含:<ul><li>远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。</li><li>集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li><li>自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li></ul></li></ul><h1 id="Dubbo能做什么？"><a href="#Dubbo能做什么？" class="headerlink" title="Dubbo能做什么？"></a>Dubbo能做什么？</h1><ul><li>透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。</li><li>软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。</li><li>服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。</li><li>Dubbo采用全spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。</li><li>之前使用Web Service，我想测试接口可以通过模拟消息的方式通过soapui或LR进行功能测试或性能测试。但现在使用Dubbo，接口之间不能直接交互，我尝试通过模拟消费者地址测试，结果不堪入目，再而使用jmeter通过junit进行测试，但还是需要往dubbo上去注册，如果再不给提供源代码的前提下，这个测试用例不好写啊….</li></ul><h1 id="dubbo的架构"><a href="#dubbo的架构" class="headerlink" title="dubbo的架构"></a>dubbo的架构</h1><ul><li>Provider: 暴露服务的服务提供方。</li><li>Consumer: 调用远程服务的服务消费方。</li><li>Registry: 服务注册与发现的注册中心。</li><li>Monitor: 统计服务的调用次调和调用时间的监控中心。</li><li>Container: 服务运行容器。</li><li>这点我觉得非常好，角色分明，可以根据每个节点角色的状态来确定该服务是否正常。</li><li>调用关系说明：<ul><li>服务容器负责启动，加载，运行服务提供者。</li><li>服务提供者在启动时，向注册中心注册自己提供的服务。</li><li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li><li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li><li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li></ul></li></ul><h1 id="Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么"><a href="#Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么" class="headerlink" title="Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么"></a>Dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么</h1><ul><li>可以通信的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用；</li><li>注册中心对等集群，任意一台宕机后，将会切换到另一台；注册中心全部宕机后，服务的提供者和消费者仍能通过本地缓存通讯。服务提供者无状态，任一台 宕机后，不影响使用；服务提供者全部宕机，服务消费者会无法使用，并无限次重连等待服务者恢复；</li><li>挂掉是不要紧的，但前提是你没有增加新的服务，如果你要调用新的服务，则是不能办到的。</li></ul><h1 id="dubbo服务负载均衡策略"><a href="#dubbo服务负载均衡策略" class="headerlink" title="dubbo服务负载均衡策略"></a>dubbo服务负载均衡策略</h1><ul><li>随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。(权重可以在dubbo管控台配置)</li><li>轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</li><li>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</li><li>一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。缺省只对第一个参数Hash，如果要修改，请配置<pre><code>&lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt;
</code></pre></li></ul><p>缺省用160份虚拟节点，如果要修改，请配置</p><pre><code>&lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt;
</code></pre><h1 id="Dubbo在安全机制方面是如何解决的"><a href="#Dubbo在安全机制方面是如何解决的" class="headerlink" title="Dubbo在安全机制方面是如何解决的"></a>Dubbo在安全机制方面是如何解决的</h1><ul><li>Dubbo通过Token令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。Dubbo还提供服务黑白名单，来控制服务所允许的调用方。</li></ul><h1 id="dubbo连接注册中心和直连的区别"><a href="#dubbo连接注册中心和直连的区别" class="headerlink" title="dubbo连接注册中心和直连的区别"></a>dubbo连接注册中心和直连的区别</h1><ul><li>在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，<br>点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表，</li><li>服务注册中心，动态的注册和发现服务，使服务的位置透明，并通过在消费方获取服务提供方地址列表，实现软负载均衡和Failover， 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li><li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外，注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者</li><li>注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表</li><li>注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。</li></ul><h1 id="dubbo服务集群配置（集群容错模式）"><a href="#dubbo服务集群配置（集群容错模式）" class="headerlink" title="dubbo服务集群配置（集群容错模式）"></a>dubbo服务集群配置（集群容错模式）</h1><ul><li>在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。可以自行扩展集群容错策略<h4 id="Failover-Cluster-默认"><a href="#Failover-Cluster-默认" class="headerlink" title="Failover Cluster(默认)"></a>Failover Cluster(默认)</h4></li><li>失败自动切换，当出现失败，重试其它服务器。(缺省)通常用于读操作，但重试会带来更长延迟。可通过retries=”2”来设置重试次数(不含第一次)。<pre><code>&lt;dubbo:service retries=&quot;2&quot; cluster=&quot;failover&quot;/&gt;
         或：
         &lt;dubbo:reference retries=&quot;2&quot; cluster=&quot;failover&quot;/&gt;
         cluster=&quot;failover&quot;可以不用写,因为默认就是failover
</code></pre></li></ul><h4 id="Failfast-Cluster"><a href="#Failfast-Cluster" class="headerlink" title="Failfast Cluster"></a>Failfast Cluster</h4><ul><li>快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。<pre><code>dubbo:service cluster=&quot;failfast&quot; /&gt;
         或：
         &lt;dubbo:reference cluster=&quot;failfast&quot; /&gt;
    cluster=&quot;failfast&quot;和 把cluster=&quot;failover&quot;、retries=&quot;0&quot;是一样的效果,retries=&quot;0&quot;就是不重试
</code></pre></li></ul><h4 id="Failsafe-Cluster"><a href="#Failsafe-Cluster" class="headerlink" title="Failsafe Cluster"></a>Failsafe Cluster</h4><ul><li>失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。<pre><code>&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;
         或：
         &lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;
</code></pre></li></ul><h4 id="Failback-Cluster"><a href="#Failback-Cluster" class="headerlink" title="Failback Cluster"></a>Failback Cluster</h4><ul><li>失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。<pre><code>&lt;dubbo:service cluster=&quot;failback&quot; /&gt;
         或：
         &lt;dubbo:reference cluster=&quot;failback&quot; /&gt;
</code></pre></li></ul><h4 id="Forking-Cluster"><a href="#Forking-Cluster" class="headerlink" title="Forking Cluster"></a>Forking Cluster</h4><ul><li>并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过forks=”2”来设置最大并行数。<pre><code>&lt;dubbo:service cluster=“forking&quot; forks=&quot;2&quot;/&gt;
         或：
         &lt;dubbo:reference cluster=“forking&quot; forks=&quot;2&quot;/&gt;
服务端服务级别
　　　　&lt;dubbo:service interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
　　客户端服务级别
　　　　&lt;dubbo:reference interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
　　服务端方法级别　　　&lt;dubbo:service interface=&quot;...&quot;&gt; &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt; &lt;/dubbo:service&gt;
客户端方法级别　        &lt;dubbo:reference interface=&quot;...&quot;&gt; &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt; &lt;/dubbo:reference&gt;
</code></pre></li></ul><h1 id="dubbo通信协议dubbo协议为什么要消费者比提供者个数多："><a href="#dubbo通信协议dubbo协议为什么要消费者比提供者个数多：" class="headerlink" title="dubbo通信协议dubbo协议为什么要消费者比提供者个数多："></a>dubbo通信协议dubbo协议为什么要消费者比提供者个数多：</h1><ul><li>因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit=128MByte)，根据测试经验数据每条连接最多只能压满7MByte(不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。</li></ul><h1 id="dubbo通信协议dubbo协议为什么不能传大包"><a href="#dubbo通信协议dubbo协议为什么不能传大包" class="headerlink" title="dubbo通信协议dubbo协议为什么不能传大包"></a>dubbo通信协议dubbo协议为什么不能传大包</h1><ul><li>因dubbo协议采用单一长连接，</li><li>如果每次请求的数据包大小为500KByte，假设网络为千兆网卡(1024Mbit=128MByte)，每条连接最大7MByte(不同的环境可能不一样，供参考)，</li><li>单个服务提供者的TPS(每秒处理事务数)最大为：128MByte / 500KByte = 262。</li><li>单个消费者调用单个服务提供者的TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。</li><li>如果能接受，可以考虑使用，否则网络将成为瓶颈。</li></ul><h1 id="dubbo通信协议dubbo协议为什么采用异步单一长连接"><a href="#dubbo通信协议dubbo协议为什么采用异步单一长连接" class="headerlink" title="dubbo通信协议dubbo协议为什么采用异步单一长连接"></a>dubbo通信协议dubbo协议为什么采用异步单一长连接</h1><ul><li>因为服务的现状大都是服务提供者少，通常只有几台机器，</li><li>而服务的消费者多，可能整个网站都在访问该服务，</li><li>比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，</li><li>如果采用常规的hessian服务，服务提供者很容易就被压跨，</li><li>通过单一连接，保证单一消费者不会压死提供者，</li><li>长连接，减少连接握手验证等，</li><li>并使用异步IO，复用线程池，防止C10K问题。</li></ul><h1 id="dubbo通信协议dubbo协议适用范围和适用场景"><a href="#dubbo通信协议dubbo协议适用范围和适用场景" class="headerlink" title="dubbo通信协议dubbo协议适用范围和适用场景"></a>dubbo通信协议dubbo协议适用范围和适用场景</h1><ul><li>适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。</li><li>适用场景：常规远程服务方法调用</li><li>dubbo协议补充：<ul><li>连接个数：单连接</li><li>连接方式：长连接</li><li>传输协议：TCP</li><li>传输方式：NIO异步传输</li><li>序列化：Hessian二进制序列化</li></ul></li></ul><h1 id="RMI协议"><a href="#RMI协议" class="headerlink" title="RMI协议"></a>RMI协议</h1><ul><li>RMI协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式，Java标准的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：TCP</li><li>传输方式：同步传输</li><li>序列化：Java标准二进制序列化</li><li>适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。</li><li>适用场景：常规远程服务方法调用，与原生RMI服务互操作</li></ul><h1 id="Hessian协议"><a href="#Hessian协议" class="headerlink" title="Hessian协议"></a>Hessian协议</h1><ul><li>Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现</li><li>基于Hessian的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：Hessian二进制序列化</li><li>适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。</li><li>适用场景：页面传输，文件传输，或与原生hessian服务互操作</li></ul><h1 id="http"><a href="#http" class="headerlink" title="http"></a>http</h1><ul><li>采用Spring的HttpInvoker实现</li><li>基于http表单的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：表单序列化（JSON）</li><li>适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。</li><li>适用场景：需同时给应用程序和浏览器JS使用的服务。</li></ul><h1 id="Webservice"><a href="#Webservice" class="headerlink" title="Webservice"></a>Webservice</h1><ul><li>基于CXF的frontend-simple和transports-http实现</li><li>基于WebService的远程调用协议。</li><li>连接个数：多连接</li><li>连接方式：短连接</li><li>传输协议：HTTP</li><li>传输方式：同步传输</li><li>序列化：SOAP文本序列化</li><li>适用场景：系统集成，跨语言调用。</li></ul><h1 id="Thrif"><a href="#Thrif" class="headerlink" title="Thrif"></a>Thrif</h1><ul><li>Thrift是Facebook捐给Apache的一个RPC框架，当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如service name，magic number等</li></ul><h1 id="为什么要⽤Dubbo？"><a href="#为什么要⽤Dubbo？" class="headerlink" title="为什么要⽤Dubbo？"></a>为什么要⽤Dubbo？</h1><ul><li>因为是阿⾥开源项⽬，国内很多互联⽹公司都在⽤，已经经过很多线上考验。</li><li>内部使⽤了 Netty、Zookeeper，保证了⾼性能⾼可⽤性。</li><li>使⽤ Dubbo 可以将核⼼业务抽取出来，作为独⽴的服务，逐渐形成稳定的服务中⼼，可⽤于提⾼业务复⽤灵活扩展，使前端应⽤能更快速的响应多变的市场需求。</li><li>最重要的⼀点是，分布式架构可以承受更⼤规模的并发流量。</li></ul><h1 id="Dubbo-和-Spring-Cloud-有什么区别？"><a href="#Dubbo-和-Spring-Cloud-有什么区别？" class="headerlink" title="Dubbo 和 Spring Cloud 有什么区别？"></a>Dubbo 和 Spring Cloud 有什么区别？</h1><ul><li><p>两个没关联，如果硬要说区别，有以下⼏点。</p><ul><li><p>通信⽅式不同</p><ul><li>Dubbo 使⽤的是 RPC 通信，⽽ Spring Cloud 使⽤的是 HTTP RESTFul ⽅式。</li><li>dubbo由于是⼆进制的传输，占⽤带宽会更少（基于netty等）；springCloud是http协议传输，带宽会⽐较多，同时使⽤http协议（http+restful api）⼀般会使⽤JSON报⽂，消耗会更⼤。</li></ul></li><li><p>dubbo的开发难度较⼤，原因是dubbo的jar包依赖（存在代码级别的强依赖）问题很多⼤型⼯程⽆法解决；</p></li><li><p>springcloud的接⼝协议约定⽐较⾃由且松散，需要有强有⼒的⾏政措施来限制接⼝⽆序升级。</p></li><li><p>dubbo的改进是通过dubbofilter，很多东⻄没有，需要⾃⼰继承，如监控，如⽇志，如限流，如追踪。</p></li><li><p>springcloud具有配置管理、服务发现、断路器、智能路由、微代理、控制总线、⼀次性token、全局锁、选主、分布式会话和集群状态等，满⾜了构建微服务所需的所有解决⽅案。</p></li><li><p>组成部分不同</p></li></ul></li></ul><h1 id="dubbo都⽀持什么协议，推荐⽤哪种？"><a href="#dubbo都⽀持什么协议，推荐⽤哪种？" class="headerlink" title="dubbo都⽀持什么协议，推荐⽤哪种？"></a>dubbo都⽀持什么协议，推荐⽤哪种？</h1><ul><li>dubbo://（推荐）</li><li>rmi://</li><li>hessian://</li><li>http://</li><li>webservice://</li><li>thrift://</li><li>memcached://</li><li>redis://</li><li>rest://</li></ul><h1 id="Dubbo需要-Web-容器吗？"><a href="#Dubbo需要-Web-容器吗？" class="headerlink" title="Dubbo需要 Web 容器吗？"></a>Dubbo需要 Web 容器吗？</h1><ul><li>不需要，如果硬要⽤ Web 容器，只会增加复杂性，也浪费资源。</li></ul><h1 id="Dubbo内置了哪⼏种服务容器？"><a href="#Dubbo内置了哪⼏种服务容器？" class="headerlink" title="Dubbo内置了哪⼏种服务容器？"></a>Dubbo内置了哪⼏种服务容器？</h1><ul><li>Spring Container</li><li>Jetty Container</li><li>Log4j Container</li><li>Dubbo 的服务容器只是⼀个简单的 Main ⽅法，并加载⼀个简单的 Spring 容器，⽤于暴露服务。</li></ul><h1 id="Dubbo默认使⽤什么注册中⼼，还有别的选择吗？"><a href="#Dubbo默认使⽤什么注册中⼼，还有别的选择吗？" class="headerlink" title="Dubbo默认使⽤什么注册中⼼，还有别的选择吗？"></a>Dubbo默认使⽤什么注册中⼼，还有别的选择吗？</h1><ul><li>推荐使⽤ Zookeeper 作为注册中⼼，还有 Redis、Multicast、Simple 注册中⼼，但不推荐。</li><li>redis⽅案需要服务器时间同步，且性能消耗过⼤。</li></ul><h1 id="Dubbo有哪⼏种配置⽅式？"><a href="#Dubbo有哪⼏种配置⽅式？" class="headerlink" title="Dubbo有哪⼏种配置⽅式？"></a>Dubbo有哪⼏种配置⽅式？</h1><ul><li>Spring 配置⽅式</li><li>Java API 配置⽅式</li></ul><h1 id="在-Provider-上可以配置的-Consumer-端的属性有哪些？"><a href="#在-Provider-上可以配置的-Consumer-端的属性有哪些？" class="headerlink" title="在 Provider 上可以配置的 Consumer 端的属性有哪些？"></a>在 Provider 上可以配置的 Consumer 端的属性有哪些？</h1><ul><li>timeout：⽅法调⽤超时</li><li>retries：失败重试次数，默认重试 2 次</li><li>loadbalance：负载均衡算法，默认随机</li><li>actives 消费者端，最⼤并发调⽤限制</li></ul><h1 id="Dubbo启动时如果依赖的服务不可⽤会怎样？"><a href="#Dubbo启动时如果依赖的服务不可⽤会怎样？" class="headerlink" title="Dubbo启动时如果依赖的服务不可⽤会怎样？"></a>Dubbo启动时如果依赖的服务不可⽤会怎样？</h1><ul><li>Dubbo 缺省会在启动时检查依赖的服务是否可⽤，不可⽤时会抛出异常，阻⽌ Spring 初始化完成，默认 check=”true”，可以通过 check=”false” 关闭检查。</li></ul><h1 id="Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？"><a href="#Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？" class="headerlink" title="Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？"></a>Dubbo推荐使⽤什么序列化框架，你知道的还有哪些？</h1><ul><li>推荐使⽤Hessian序列化，还有Duddo、FastJson、Java⾃带序列化。</li></ul><h1 id="Dubbo默认使⽤的是什么通信框架，还有别的选择吗？"><a href="#Dubbo默认使⽤的是什么通信框架，还有别的选择吗？" class="headerlink" title="Dubbo默认使⽤的是什么通信框架，还有别的选择吗？"></a>Dubbo默认使⽤的是什么通信框架，还有别的选择吗？</h1><ul><li>Dubbo 默认使⽤ Netty 框架，也是推荐的选择，另外内容还集成有Mina、Grizzly。</li></ul><h1 id="注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？"><a href="#注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？" class="headerlink" title="注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？"></a>注册了多个同⼀样的服务，如果测试指定的某⼀个服务呢？</h1><ul><li>可以配置环境点对点直连，绕过注册中⼼，将以服务接⼝为单位，忽略注册中⼼的提供者列表。</li></ul><h1 id="Dubbo⽀持服务多协议吗？"><a href="#Dubbo⽀持服务多协议吗？" class="headerlink" title="Dubbo⽀持服务多协议吗？"></a>Dubbo⽀持服务多协议吗？</h1><ul><li>Dubbo 允许配置多协议，在不同服务上⽀持不同协议或者同⼀服务上同时⽀持多种协议。</li></ul><h1 id="当⼀个服务接⼝有多种实现时怎么做？"><a href="#当⼀个服务接⼝有多种实现时怎么做？" class="headerlink" title="当⼀个服务接⼝有多种实现时怎么做？"></a>当⼀个服务接⼝有多种实现时怎么做？</h1><ul><li>当⼀个接⼝有多种实现时，可以⽤ group 属性来分组，服务提供⽅和消费⽅都指定同⼀个 group 即可。</li></ul><h1 id="服务上线怎么兼容旧版本？"><a href="#服务上线怎么兼容旧版本？" class="headerlink" title="服务上线怎么兼容旧版本？"></a>服务上线怎么兼容旧版本？</h1><ul><li>可以⽤版本号（version）过渡，多个不同版本的服务注册到注册中⼼，版本号不同的服务相互间不引⽤。这个和服务分组的概念有⼀点类似。</li></ul><h1 id="Dubbo可以对结果进⾏缓存吗？"><a href="#Dubbo可以对结果进⾏缓存吗？" class="headerlink" title="Dubbo可以对结果进⾏缓存吗？"></a>Dubbo可以对结果进⾏缓存吗？</h1><ul><li>可以，Dubbo 提供了声明式缓存，⽤于加速热⻔数据的访问速度，以减少⽤户加缓存的⼯作量。</li></ul><h1 id="Dubbo服务之间的调⽤是阻塞的吗？"><a href="#Dubbo服务之间的调⽤是阻塞的吗？" class="headerlink" title="Dubbo服务之间的调⽤是阻塞的吗？"></a>Dubbo服务之间的调⽤是阻塞的吗？</h1><ul><li>默认是同步等待结果阻塞的，⽀持异步调⽤。</li><li>Dubbo 是基于 NIO 的⾮阻塞实现并⾏调⽤，客户端不需要启动多线程即可完成并⾏调⽤多个远程服务，相对多线程开销较⼩，异步调⽤会返回⼀个 Future 对象。</li></ul><h1 id="Dubbo⽀持分布式事务吗？"><a href="#Dubbo⽀持分布式事务吗？" class="headerlink" title="Dubbo⽀持分布式事务吗？"></a>Dubbo⽀持分布式事务吗？</h1><ul><li>⽬前暂时不⽀持，后续可能采⽤基于 JTA/XA 规范实现，如以图所示。</li></ul><h1 id="Dubbo-telnet-命令能做什么？"><a href="#Dubbo-telnet-命令能做什么？" class="headerlink" title="Dubbo telnet 命令能做什么？"></a>Dubbo telnet 命令能做什么？</h1><ul><li>dubbo 通过 telnet 命令来进⾏服务治理</li><li>telnet localhost 8090</li></ul><h1 id="Dubbo⽀持服务降级吗？"><a href="#Dubbo⽀持服务降级吗？" class="headerlink" title="Dubbo⽀持服务降级吗？"></a>Dubbo⽀持服务降级吗？</h1><ul><li>Dubbo 2.2.0 以上版本⽀持。</li></ul><h1 id="Dubbo如何优雅停机？"><a href="#Dubbo如何优雅停机？" class="headerlink" title="Dubbo如何优雅停机？"></a>Dubbo如何优雅停机？</h1><ul><li>Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果使⽤ kill -9 PID 等强制关闭指令，是不会执⾏优雅停机的，只有通过 kill PID 时，才会执⾏。</li></ul><h1 id="服务提供者能实现失效踢出是什么原理？"><a href="#服务提供者能实现失效踢出是什么原理？" class="headerlink" title="服务提供者能实现失效踢出是什么原理？"></a>服务提供者能实现失效踢出是什么原理？</h1><ul><li>服务失效踢出基于 Zookeeper 的临时节点原理。 （服务机器会在zk上注册⼀个临时节点，服务失效则临时节点被删除）</li></ul><h1 id="如何解决服务调⽤链过⻓的问题？"><a href="#如何解决服务调⽤链过⻓的问题？" class="headerlink" title="如何解决服务调⽤链过⻓的问题？"></a>如何解决服务调⽤链过⻓的问题？</h1><ul><li>Dubbo 可以使⽤ Pinpoint 和 Apache Skywalking(Incubator) 实现分布式服务追踪，当然还有其他很多⽅案。</li></ul><h1 id="服务读写推荐的容错策略是怎样的？"><a href="#服务读写推荐的容错策略是怎样的？" class="headerlink" title="服务读写推荐的容错策略是怎样的？"></a>服务读写推荐的容错策略是怎样的？</h1><ul><li>读操作建议使⽤ Failover 失败⾃动切换，默认重试两次其他服务器。</li><li>写操作建议使⽤ Failfast 快速失败，发⼀次调⽤失败就⽴即报错。</li></ul><h1 id="Dubbo必须依赖的包有哪些？"><a href="#Dubbo必须依赖的包有哪些？" class="headerlink" title="Dubbo必须依赖的包有哪些？"></a>Dubbo必须依赖的包有哪些？</h1><ul><li>Dubbo 必须依赖 JDK，其他为可选。</li></ul><h1 id="Dubbo的管理控制台能做什么？"><a href="#Dubbo的管理控制台能做什么？" class="headerlink" title="Dubbo的管理控制台能做什么？"></a>Dubbo的管理控制台能做什么？</h1><ul><li>管理控制台主要包含：路由规则，动态配置，服务降级，访问控制，权重调整，负载均衡，等管理功能。</li></ul><h1 id="说说-Dubbo-服务暴露的过程。"><a href="#说说-Dubbo-服务暴露的过程。" class="headerlink" title="说说 Dubbo 服务暴露的过程。"></a>说说 Dubbo 服务暴露的过程。</h1><ul><li>Dubbo 会在 Spring 实例化完 bean 之后，</li><li>在刷新容器最后⼀步发布 ContextRefreshEvent 事件的时候，</li><li>通知实现了ApplicationListener 的 ServiceBean 类进⾏回调 onApplicationEvent 事件⽅法，</li><li>Dubbo 会在这个⽅法中调⽤ ServiceBean ⽗类ServiceConfig 的 export ⽅法，</li><li>⽽该⽅法真正实现了服务的（异步或者⾮异步）发布。</li></ul><h1 id="Dubbo-停⽌维护了吗？"><a href="#Dubbo-停⽌维护了吗？" class="headerlink" title="Dubbo 停⽌维护了吗？"></a>Dubbo 停⽌维护了吗？</h1><ul><li>2014 年开始停⽌维护过⼏年，17 年开始重新维护，并进⼊了 Apache 项⽬。</li></ul><h1 id="Dubbo-和-Dubbox-有什么区别？"><a href="#Dubbo-和-Dubbox-有什么区别？" class="headerlink" title="Dubbo 和 Dubbox 有什么区别？"></a>Dubbo 和 Dubbox 有什么区别？</h1><ul><li>Dubbox 是继 Dubbo 停⽌维护后，当当⽹基于 Dubbo 做的⼀个扩展项⽬，如加了服务可 Restful 调⽤，更新了开源组件等。</li></ul><h1 id="你还了解别的分布式框架吗？"><a href="#你还了解别的分布式框架吗？" class="headerlink" title="你还了解别的分布式框架吗？"></a>你还了解别的分布式框架吗？</h1><ul><li>别的还有 Spring cloud、Facebook 的 Thrift、Twitter 的 Finagle 等。</li></ul><h1 id="Dubbo-能集成-Spring-Boot-吗？"><a href="#Dubbo-能集成-Spring-Boot-吗？" class="headerlink" title="Dubbo 能集成 Spring Boot 吗？"></a>Dubbo 能集成 Spring Boot 吗？</h1><ul><li>可以的，项⽬地址如下。</li><li><a target="_blank" rel="noopener" href="https://github.com/apache/incubator-dubbo-spring-boot-project">https://github.com/apache/incubator-dubbo-spring-boot-project</a></li></ul><h1 id="在使⽤过程中都遇到了些什么问题？"><a href="#在使⽤过程中都遇到了些什么问题？" class="headerlink" title="在使⽤过程中都遇到了些什么问题？"></a>在使⽤过程中都遇到了些什么问题？</h1><ul><li>单⼀⻓连接和NIO异步通讯，适合⼤并发⼩数据量的服务调⽤，以及消费者远⼤于提供者。Dubbo 的设计⽬的是为了满⾜⾼并发⼩数据量的 rpc 调⽤，在⼤数据量下的性能表现并不好，建议使⽤ rmi 或 http 协议。</li></ul><h1 id="你觉得⽤-Dubbo-好还是-Spring-Cloud-好？"><a href="#你觉得⽤-Dubbo-好还是-Spring-Cloud-好？" class="headerlink" title="你觉得⽤ Dubbo 好还是 Spring Cloud 好？"></a>你觉得⽤ Dubbo 好还是 Spring Cloud 好？</h1><ul><li>扩展性的问题，没有好坏，只有适合不适合，不过我好像更倾向于使⽤ Dubbo, Spring Cloud 版本升级太快，组件更新替换太频繁，配置太繁琐，还有很多我觉得是没有 Dubbo 顺⼿的地⽅……</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/dffc02696193.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/dffc02696193.html" class="post-title-link" itemprop="url">MySQL</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:21:32 / 修改时间：16:22:19" itemprop="dateCreated datePublished" datetime="2023-12-20T16:21:32+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="谈谈MySQL支持的事务隔离级别？"><a href="#谈谈MySQL支持的事务隔离级别？" class="headerlink" title="谈谈MySQL支持的事务隔离级别？"></a>谈谈MySQL支持的事务隔离级别？</h1><p>MySQL数据库事务隔离级别分为四个不同层次:<br>读未提交: 一个事务能够读取其他事务未提交的修改的数据,这是最低的隔离水平,允许<br>脏读出现。<br>读已提交: 一个事务能够读取其他事务已经提交的修改的数据,脏读不会出现。但是隔离<br>级别比较低,允许出现不可重复读和幻象读。<br>可重复读： 一个事务读取到另一个事务已经提交的数据,隔离级别比较高,允许出现幻读。<br>这也是MySQL InnoDB引擎的默认隔离级别,但是和一些其他的数据库不同,可以简单的认为<br>MySQL在可重复读级别不会出现幻读。<br>串行化: 并发事务之间是串行化的,通常意味着读取需要共享读锁,更新需要获取排他写<br>锁。这是最高的隔离级别。</p><h4 id="不可重复读和幻读到底有什么区别呢？"><a href="#不可重复读和幻读到底有什么区别呢？" class="headerlink" title="不可重复读和幻读到底有什么区别呢？"></a>不可重复读和幻读到底有什么区别呢？</h4><p>（1）不可重复读是读取了其他事务更改的数据，针对update操作<br>解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许<br>其他事务更改刚才的数据。<br>（2）幻读是读取了其他事务新增的数据，针对insert操作<br>解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才<br>允许其他事务新增数据。</p><h1 id="为什么用自增列作为主键？"><a href="#为什么用自增列作为主键？" class="headerlink" title="为什么用自增列作为主键？"></a>为什么用自增列作为主键？</h1><p>1、如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引。<br>如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引。<br>如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。<br>2、数据记录本身被存于主索引（一颗B+Tree）的叶子节点上，这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放<br>因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）<br>3、如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页<br>4、如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置<br>此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销<br>同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。</p><h1 id="为什么使用数据索引能提高效率？"><a href="#为什么使用数据索引能提高效率？" class="headerlink" title="为什么使用数据索引能提高效率？"></a>为什么使用数据索引能提高效率？</h1><p>数据索引的存储是有序的</p><p>在有序的情况下，通过索引查询一个数据是无需遍历索引记录的</p><p>极端情况下，数据索引的查询效率为二分法查询效率，趋近于 log2(N)</p><h1 id="B-树索引和哈希索引的区别？"><a href="#B-树索引和哈希索引的区别？" class="headerlink" title="B+树索引和哈希索引的区别？"></a>B+树索引和哈希索引的区别？</h1><p>B+树是一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接，是有序的，如下图：</p><p>哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可,是无序的<br>如下图所示：</p><h1 id="哈希索引的优势："><a href="#哈希索引的优势：" class="headerlink" title="哈希索引的优势："></a>哈希索引的优势：</h1><p>等值查询，哈希索引具有绝对优势（前提是：没有大量重复键值，如果大量重复键值时，哈希索引的效率很低，因为存在所谓的哈希碰撞问题。）</p><h1 id="哈希索引不适用的场景："><a href="#哈希索引不适用的场景：" class="headerlink" title="哈希索引不适用的场景："></a>哈希索引不适用的场景：</h1><p>不支持范围查询</p><p>不支持索引完成排序</p><p>不支持联合索引的最左前缀匹配规则</p><p>通常，B+树索引结构适用于绝大多数场景，像下面这种场景用哈希索引才更有优势：<br>在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引，例如这种SQL：</p><h1 id="仅等值查询"><a href="#仅等值查询" class="headerlink" title="仅等值查询"></a>仅等值查询</h1><p>select id, name from table where name=’李明’; <br>而常用的 InnoDB 引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况。<br>如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引）。<br>通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。<br>注意：在某些工作负载下，通过哈希索引查找带来的性能提升远大于额外的监控索引搜索情况和保持这个哈希表结构所带来的开销。<br>但某些时候，在负载高的情况下，自适应哈希索引中添加的read/write锁也会带来竞争，比如高并发的join操作。like操作和%的通配符操作也不适用于自适应哈希索引，可能要关闭自适应哈希索引。</p><h1 id="B-树和-B-树的区别？"><a href="#B-树和-B-树的区别？" class="headerlink" title="B 树和 B+ 树的区别？"></a>B 树和 B+ 树的区别？</h1><p>1、B树，每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为nul，叶子结点不包含任何关键字信息。</p><p>2、B+树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接<br>所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。(而B 树的非终节点也包含需要查找的有效信息)</p><h1 id="为什么说B-比B树更适合实际应用中操作系统的文件索引和数据库索引？"><a href="#为什么说B-比B树更适合实际应用中操作系统的文件索引和数据库索引？" class="headerlink" title="为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？"></a>为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？</h1><p>1、B+的磁盘读写代价更低。<br>B+的内部结点并没有指向关键字具体信息的指针，因此其内部结点相对B树更小。<br>如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。<br>2、B+-tree的查询效率更加稳定。<br>由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p><h1 id="关于-MySQL-联合索引"><a href="#关于-MySQL-联合索引" class="headerlink" title="关于 MySQL 联合索引"></a>关于 MySQL 联合索引</h1><p>1、联合索引是两个或更多个列上的索引。<br>对于联合索引:Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。<br>例如索引是key index (a,b,c). 可以支持a 、 a,b 、 a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。<br>2、利用索引中的附加列，您可以缩小搜索的范围，但使用一个具有两列的索引不同于使用两个单独的索引。<br>复合索引的结构与电话簿类似，人名由姓和名构成，电话簿首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。<br>如果您知道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不知道姓，电话簿将没有用处。</p><h1 id="什么情况下应不建或少建索引？"><a href="#什么情况下应不建或少建索引？" class="headerlink" title="什么情况下应不建或少建索引？"></a>什么情况下应不建或少建索引？</h1><p>1、表记录太少<br>2、经常插入、删除、修改的表<br>3、数据重复且分布平均的表字段，假如一个表有10万行记录，有一个字段A只有T和F两种值，且每个值的分布概率大约为50%，那么对这种表A字段建索引一般不会提高数据库的查询速度。<br>4、经常和主字段一块查询但主字段索引值比较多的表字段</p><h1 id="什么是表分区？"><a href="#什么是表分区？" class="headerlink" title="什么是表分区？"></a>什么是表分区？</h1><p>表分区，是指根据一定规则，将数据库中的一张表分解成多个更小的，容易管理的部分。从逻辑上看，只有一张表，但是底层却是由多个物理分区组成。</p><h1 id="表分区与分表的区别？"><a href="#表分区与分表的区别？" class="headerlink" title="表分区与分表的区别？"></a>表分区与分表的区别？</h1><p>分表：指的是通过一定规则，将一张表分解成多张不同的表。比如将用户订单记录根据时间成多个表。<br>分表与分区的区别在于：分区从逻辑上来讲只有一张表，而分表则是将一张表分解成多张表。</p><h1 id="表分区有什么好处？"><a href="#表分区有什么好处？" class="headerlink" title="表分区有什么好处？"></a>表分区有什么好处？</h1><p>1、存储更多数据。分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。和单个磁盘或者文件系统相比，可以存储更多数据<br>2、优化查询。在where语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率；涉及sum和count语句时，也可以在多个分区上并行处理，最后汇总结果。<br>3、分区表更容易维护。例如：想批量删除大量数据可以清除整个分区。<br>4、避免某些特殊的瓶颈，例如InnoDB的单个索引的互斥访问，ext3问价你系统的inode锁竞争等。</p><h1 id="分区表的限制因素"><a href="#分区表的限制因素" class="headerlink" title="分区表的限制因素"></a>分区表的限制因素</h1><p>一个表最多只能有1024个分区<br>MySQL5.1中，分区表达式必须是整数，或者返回整数的表达式。在MySQL5.5中提供了非整数表达式分区的支持。<br>如果分区字段中有主键或者唯一索引的列，那么多有主键列和唯一索引列都必须包含进来。即：分区字段要么不包含主键或者索引列，要么包含全部主键和索引列。<br>分区表中无法使用外键约束<br>MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表分区，也不能只对表的一部分数据分区。</p><h1 id="如何判断当前MySQL是否支持分区？"><a href="#如何判断当前MySQL是否支持分区？" class="headerlink" title="如何判断当前MySQL是否支持分区？"></a>如何判断当前MySQL是否支持分区？</h1><p>命令：show variables like ‘%partition%’ 运行结果:<br>mysql&gt; show variables like ‘%partition%’;<br>+——————-+——-+| Variable_name | Value |+——————-+——-+| have_partitioning | YES |+——————-+——-+1 row in set (0.00 sec)<br>have_partintioning 的值为YES，表示支持分区。</p><h1 id="MySQL支持的分区类型有哪些？"><a href="#MySQL支持的分区类型有哪些？" class="headerlink" title="MySQL支持的分区类型有哪些？"></a>MySQL支持的分区类型有哪些？</h1><p>RANGE分区：这种模式允许将数据划分不同范围。例如可以将一个表通过年份划分成若干个分区<br>LIST分区：这种模式允许系统通过预定义的列表的值来对数据进行分割。按照List中的值分区，与RANGE的区别是，range分区的区间范围值是连续的。<br>HASH分区 ：这中模式允许通过对表的一个或多个列的Hash Key进行计算，最后通过这个Hash码不同数值对应的数据区域进行分区。例如可以建立一个对表主键进行分区的表。<br>KEY分区 ：上面Hash模式的一种延伸，这里的Hash Key是MySQL系统产生的。</p><h1 id="四种隔离级别"><a href="#四种隔离级别" class="headerlink" title="四种隔离级别"></a>四种隔离级别</h1><p>Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。<br>Repeatable read (可重复读)：可避免脏读、不可重复读的发生。<br>Read committed (读已提交)：可避免脏读的发生。<br>Read uncommitted (读未提交)：最低级别，任何情况都无法保证。</p><h1 id="关于MVVC"><a href="#关于MVVC" class="headerlink" title="关于MVVC"></a>关于MVVC</h1><p>MySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) <br>注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control<br>MVCC最大的好处：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，现阶段几乎所有的RDBMS，都支持了MVCC。<br>LBCC：Lock-Based Concurrency Control，基于锁的并发控制<br>MVCC：Multi-Version Concurrency Control<br>基于多版本的并发控制协议。纯粹基于锁的并发机制并发量低，MVCC是在基于锁的并发控制上的改进，主要是在读操作上提高了并发量。</p><h1 id="在MVCC并发控制中，读操作可以分成两类："><a href="#在MVCC并发控制中，读操作可以分成两类：" class="headerlink" title="在MVCC并发控制中，读操作可以分成两类："></a>在MVCC并发控制中，读操作可以分成两类：</h1><p>快照读 (snapshot read)：读取的是记录的可见版本 (有可能是历史版本)，不用加锁（共享读锁s锁也不加，所以不会阻塞其他事务的写）<br>当前读 (current read)：读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录</p><h1 id="行级锁定的优点："><a href="#行级锁定的优点：" class="headerlink" title="行级锁定的优点："></a>行级锁定的优点：</h1><p>1、当在许多线程中访问不同的行时只存在少量锁定冲突。<br>2、回滚时只有少量的更改<br>3、可以长时间锁定单一的行。</p><h1 id="行级锁定的缺点："><a href="#行级锁定的缺点：" class="headerlink" title="行级锁定的缺点："></a>行级锁定的缺点：</h1><p>比页级或表级锁定占用更多的内存。<br>当在表的大部分中使用时，比页级或表级锁定速度慢，因为你必须获取更多的锁。<br>如果你在大部分数据上经常进行GROUP BY操作或者必须经常扫描整个表，比其它锁定明显慢很多。<br>用高级别锁定，通过支持不同的类型锁定，你也可以很容易地调节应用程序，因为其锁成本小于行级锁定。</p><h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a>MySQL优化</h1><p>开启查询缓存，优化查询<br>explain你的select查询，这可以帮你分析你的查询语句或是表结构的性能瓶颈。EXPLAIN 的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的<br>当只要一行数据时使用limit 1，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据<br>为搜索字段建索引<br>使用 ENUM 而不是 VARCHAR。如果你有一个字段，比如“性别”，“国家”，“民族”，“状态”或“部门”，你知道这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是VARCHAR<br>Prepared StatementsPrepared Statements很像存储过程，是一种运行在后台的SQL语句集合，我们可以从使用 prepared statements 获得很多好处，无论是性能问题还是安全问题。<br>Prepared Statements 可以检查一些你绑定好的变量，这样可以保护你的程序不会受到“SQL注入式”攻击<br>垂直分表<br>选择正确的存储引擎</p><h1 id="key和index的区别"><a href="#key和index的区别" class="headerlink" title="key和index的区别"></a>key和index的区别</h1><p>key 是数据库的物理结构，它包含两层意义和作用，一是约束（偏重于约束和规范数据库的结构完整性），二是索引（辅助查询用的）。包括primary key, unique key, foreign key 等<br>index是数据库的物理结构，它只是辅助查询的，它创建时会在另外的表空间（mysql中的innodb表空间）以一个类似目录的结构存储。索引要分类的话，分为前缀索引、全文本索引等；</p><h1 id="Mysql-中-MyISAM-和-InnoDB-的区别有哪些？"><a href="#Mysql-中-MyISAM-和-InnoDB-的区别有哪些？" class="headerlink" title="Mysql 中 MyISAM 和 InnoDB 的区别有哪些？"></a>Mysql 中 MyISAM 和 InnoDB 的区别有哪些？</h1><p>区别：<br>InnoDB支持事务，MyISAM不支持<br>对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；<br>InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败；<br>InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。<br>但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此主键不应该过大，因为主键太大，其他索引也都会很大。<br>而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。<br>InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；<br>Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高；<br>如何选择：<br>是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM；<br>如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读写也挺频繁，请使用InnoDB<br>系统奔溃后，MyISAM恢复起来更困难，能否接受；<br>MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。</p><h1 id="数据库表创建注意事项"><a href="#数据库表创建注意事项" class="headerlink" title="数据库表创建注意事项"></a>数据库表创建注意事项</h1><p>1、字段名及字段配制合理性<br>剔除关系不密切的字段；<br>字段命名要有规则及相对应的含义（不要一部分英文，一部分拼音，还有类似a.b.c这样不明含义的字段）；<br>字段命名尽量不要使用缩写（大多数缩写都不能明确字段含义）；<br>字段不要大小写混用（想要具有可读性，多个英文单词可使用下划线形式连接）；<br>字段名不要使用保留字或者关键字；<br>保持字段名和类型的一致性；<br>慎重选择数字类型；<br>给文本字段留足余量；<br>2、系统特殊字段处理及建成后建议<br>添加删除标记（例如操作人、删除时间）；<br>建立版本机制；<br>3、表结构合理性配置<br>多型字段的处理，就是表中是否存在字段能够分解成更小独立的几部分（例如：人可以分为男人和女人）；<br>多值字段的处理，可以将表分为三张表，这样使得检索和排序更加有调理，且保证数据的完整性！<br>4、其它建议<br>对于大数据字段，独立表进行存储，以便影响性能（例如：简介字段）；<br>使用varchar类型代替char，因为varchar会动态分配长度，char指定长度是固定的；<br>给表创建主键，对于没有主键的表，在查询和索引定义上有一定的影响；<br>避免表字段运行为null，建议设置默认值（例如：int类型设置默认值为0）在索引查询上，效率立显；<br>建立索引，最好建立在唯一和非空的字段上，建立太多的索引对后期插入、更新都存在一定的影响（考虑实际情况来创建）；</p><h1 id="MySQL千万级的大表要怎么优化（读写分离、水平拆分、垂直拆分）"><a href="#MySQL千万级的大表要怎么优化（读写分离、水平拆分、垂直拆分）" class="headerlink" title="MySQL千万级的大表要怎么优化（读写分离、水平拆分、垂直拆分）"></a>MySQL千万级的大表要怎么优化（读写分离、水平拆分、垂直拆分）</h1><p>思考<br>如何设计或优化千万级别的大表？此外无其他信息，个人觉得这个话题有点范，就只好简单说下该如何做，对于一个存储设计，必须考虑业务特点，收集的信息如下：<br>1.数据的容量：1-3年内会大概多少条数据，每条数据大概多少字节；<br>2.数据项：是否有大字段，那些字段的值是否经常被更新；<br>3.数据查询SQL条件：哪些数据项的列名称经常出现在WHERE、GROUP BY、ORDER BY子句中等；<br>4.数据更新类SQL条件：有多少列经常出现UPDATE或DELETE 的WHERE子句中；<br>5.SQL量的统计比，如：SELECT：UPDATE+DELETE：INSERT=多少？<br>6.预计大表及相关联的SQL，每天总的执行量在何数量级？<br>7.表中的数据：更新为主的业务 还是 查询为主的业务 ？<br>8.打算采用什么数据库物理服务器，以及数据库服务器架构？<br>9.并发如何？<br>10.存储引擎选择InnoDB还是MyISAM？<br>大致明白以上10个问题，至于如何设计此类的大表，应该什么都清楚了！<br>至于优化若是指创建好的表，不能变动表结构的话，那建议InnoDB引擎，多利用点内存，减轻磁盘IO负载，因为IO往往是数据库服务器的瓶颈<br>另外对优化索引结构去解决性能问题的话，建议优先考虑修改类SQL语句，使他们更快些，不得已只靠索引组织结构的方式，当然此话前提是， 索引已经创建的非常好，若是读为主，可以考虑打开query_cache，以及调整一些参数值：sort_buffer_size,read_buffer_size,read_rnd_buffer_size,join_buffer_size<br>以及调整一些参数值：sort_buffer_size,read_buffer_size,read_rnd_buffer_size,join_buffer_size<br>案列一<br>我现在的公司有三张表，是5亿的数据，每天张表每天的增量是100w<br>每张表大概在10个columns左右<br>下面是我做的测试和对比<br>1.首先看engine,在大数据量情况下，在没有做分区的情况下<br>mysiam比innodb在只读的情况下，效率要高13％左右<br>2.在做了partition之后，你可以去读一下mysql的官方文档，其实对于partition，专门是对myisam做的优化，对于innodb，所有的数据是存在ibdata里面的，所以即使你可以看到schema变了，其实没有本质的变化<br>在分区出于同一个physical disk下面的情况下，提升大概只有1％<br>在分区在不同的physical disk下，我分到了三个不同的disks下，提升大概在3％，其实所谓的吞吐量，由很多因素决定的，比如你的explain parition时候可以看到，record在那一个分区，如果每个分区都有，其实本质上没有解决读的问题，这样只会提升写的效率。<br>另外一个问题在于，分区，你怎么分，如果一张表，有三个column都是经常被用于做查询条件的，其实是一件很悲惨的事情，因为你没有办法对所有的sql做针对性的分区，如果你只是如mysql官方文档上说的，只对时间做一个分区，而且你也只用时间查询的话，恭喜你<br>3.表主要用来读还是写，其实这个问题是不充分的，应该这样问，你在写入的时候，同时并发的查询多么？我的问题还比较简单，因为mongodb的shredding支持不能，在crush之后，还是回到mysql，所以在通常情况下，9am－9pm，写入的情况很多，这个时候我会做一个view，view是基于最近被插入或者经常被查询的，通过做view来分离读取，就是说写是在table上的，读在进行逻辑判断前是在view上操作的<br>4.做一些archive table，比如先对这些大表做很多已有的统计分析，然后通过已有的分析＋增量来解决<br>5.如果你用mysiam，还有一个问题你要注意，如果你的.configure的时候，加了一个max index length参数的时候，当你的record数大于制定长度的时候，这个index会被disable<br>案列二<br>任何偏离业务场景的优化都是耍流氓，如果是订单表，主要 通过订单id来查询 订单信息，则可以对这样的表 进行垂直分库，每个库表容量500万条，按订单号维度 给拆分到多个库，而在查询的时候，使用订单号查询，通过某个业务规则，直接定位到要查询的目标库。或者通过用户ID 、日期维度 进行分库，但是千万要注意，查询时携带 分库的条件。 如果是CRM系统 ，不直接使用订单号直接查询，而是一个范围查询，返回一个列表集合，而你还继续执着于分库分表就能解决你的性能问题，这样你要对各个库的查询结果集进行union，数据库的性能非但不能提高反而会适得其反！<br>解决方案<br>首先，任何优化，都需要你了解你的业务，了解你的数据。<br>QPS要到多少？- 带宽及存储够的情况下，单机几千QPS妥妥的。<br>读写比例如何？- 读多写少和写多读少，优化方法是有很大差别的。设置于只读场景，果断压缩。<br>数据是否快速增长？- 基本就是QPS的要求。<br>数据及服务的SLA要到多少？- 数据需不需要强一致？HA做到什么程度？<br>诸如此类。<br>不同的场景有不同的侧重，解决方案是不同的。而对于一些典型的场景可能会有成熟的解决方案。<br>题主已注明“千万级”，因此以下假设题主为最常见的场景： 大量数据，QPS要求高，读多写少，数据快速增长，SLA要求高 。<br>其次，说优化的方法。<br>主要从三个维度说：Why, How, When。<br>0. sql vs nosql<br>有些跑题，但也是很重要的一方面。<br>Why: nosql天生分布，而且大多针对某种类型的数据、某种使用场景做过优化。<br>比如大批量的监控数据，用mysql存费时费力，可以选择mongo，甚至时间序列数据库，存取会有量级提升。<br>How: 找对应解决方案。<br>When: 有足够诱惑 - 针对使用场景，有成熟解决方案，效率获得大量提升。</p><ol><li>优化shema、sql语句+索引<br>Why: 再好的MySQL架构也扛不住一个频繁的垃圾查询。不合理的schema设计也会导致数据存取慢。索引的作用不必多说，但如innodb下，错的索引带来的可能不只是查询变慢而已。<br>How: 设计阶段就需要预计QPS及数据规模，参考业务场景对数据的要求，合理设计表结构（参考mysql在线DDL问题），甚至违反设计范式做到适当冗余。生产环境分析慢日志，优化语句。索引的设计需要知道索引是怎么用的，比如innodb的加锁机制。<br>When: 这个不仅仅是第一个要考虑的，而应该是需要持续去优化的。特别是要参考业务。但实际环境中如果是这个的问题，那一般比较幸运了，因为一般已经优化过很多了。实际中遇到的一般是更深的问题。</li><li>缓存<br>缓存没有那么简单。<br>缓存对于应用不是完全透明的，除非你用Django这种成熟框架，而且缓存粒度很大，但实际。。。像python，最少也得加几个装饰器。<br>如何保证缓存里面的数据是始终正确的？写数据前失效缓存还是写数据后？<br>缓存挂了或者过冷，流量压到后端mysql了怎么办？<br>缓存也不是万能的。写多读少，命中率会很低。<br>How: memcache用做缓存，redis用于需要持久化的场景。（redis能不能完全取代memcache？呵呵。。）<br>还可以使用mysql自带的query cache，对应用基本完全透明。但会受限于本机。而且只缓存查询结果，mc和redis可以缓存一些加工后的数据。<br>而且数据量大、QPS大的情况下，也需要考虑分片及HA的问题。如果有一个数据过热，把一个节点压垮了怎么办？<br>When: 基本上大多数读多写少的场景都能用，写多的情况下可能需要考虑考虑。</li><li>复制及读写分离（做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护）<br>Why: 这个其实是大多数场景下都必须的。因为复制可以实现备份、高可用、负载均衡。就算嫌麻烦不做负载均衡，那备份下总是要的吧？既然已经备份了，何不加个LVS+HAProxy做下HA？顺便稍微修改下应用，读写分离也就成了。<br>How: 节点少的情况下，主备。前面加Keepalived+HAProxy等组件，失效自动切换。读写分离可能需要修改下应用。<br>节点多的情况下，一是考虑多级备份，减轻主的压力。其次可以引入第三方组件，接管主节点的备份工作。<br>主主不是很推荐。一是需要考虑数据冲突的情况，比如错开id，同时操作数据后冲突解决。其次如果强一致会导致延迟增加，如果有节点挂了，需要等到超时才返回。<br>When: 主备几乎大多数场景。甚至不论数据大小。高可用对应用透明，为啥不用?主主麻烦，建议先用切分。</li><li>切分<br>包括垂直切分和水平切分，实现方式上又包括分库、分表。<br>虽然有些难度，但还是推荐常用的。<br>Why: 垂直切分保证业务的独立性，防止不同业务争抢资源，毕竟业务是有优先级的。<br>水平切分主要用于突破单机瓶颈。除了主主外，只有切分能真正做到将负载分配下去。<br>切分后也可对不同片数据进行不同优化。如按时间切分，超过一定时间数据不允许修改，就可以引入压缩了，数据传输及读取减少很多。<br>How: 根据业务垂直切分。业务内部分库、分表。一般都需要修改应用。除分表外，其余实现不是很复杂。有第三方组件可用，但通用高效又灵活的方式，还是自己写client。<br>When: 垂直切分一般都要做，只不过业务粒度大小而已。<br>分库有是经常用的，就算当前压力小，也尽量分出几个逻辑库出来。等规模上去了，很方便就迁移扩展。<br>水平拆分有一定难度，但如果将来一定会到这个规模，又可能用到，建议越早做越好。因为对应用的改动较大，而且迁移成本高。<br>综上，数据库设计要面向现代化，面向世界，面向未来。。。<br>在一般运维的角度来看，我们什么情况下需要考虑分库分表？<br>首先说明，这里所说的分库分表是指把数据库数据的物理拆分到多个实例或者多台机器上去，而不是类似分区表的原地切分。<br>原则零：能不分就不分。<br>是的，MySQL 是关系数据库，数据库表之间的关系从一定的角度上映射了业务逻辑。任何分库分表的行为都会在某种程度上提升业务逻辑的复杂度，数据库除了承载数据的存储和访问外，协助业务更好的实现需求和逻辑也是其重要工作之一。分库分表会带来数据的合并，查询或者更新条件的分离，事务的分离等等多种后果，业务实现的复杂程度往往会翻倍或者指数级上升。所以，在分库分表之前，不要为分而分，去做其他力所能及的事情吧，例如升级硬件，升级，升级网络，升级数据库版本，读写分离，负载均衡等等。所有分库分表的前提是，这些你已经尽力了。<br>原则一：数据量太大，正常的运维影响正常业务访问。<br>这里说的运维，例如：<br>（1）对数据库的备份。如果单表或者单个实例太大，在做备份的时候需要大量的磁盘IO或者网络IO资源。例如1T的数据，网络传输占用50MB的时候，需要20000秒才能传输完毕，在此整个过程中的维护风险都是高于平时的。我们在Qunar的做法是给所有的数据库机器添加第二块网卡，用来做备份，或者SST，Group Communication等等各种内部的数据传输。1T的数据的备份，也会占用大量的磁盘IO，如果是SSD还好，当然这里忽略某些厂商的产品在集中IO的时候会出一些BUG的问题。如果是普通的物理磁盘，则在不限流的情况下去执行xtrabackup，该实例基本不可用。<br>（2）对数据表的修改。如果某个表过大，对此表做DDL的时候，MySQL会锁住全表，这个时间可能很长，在这段时间业务不能访问此表，影响甚大。解决的办法有类似腾讯游戏DBA自己改造的可以在线秒改表，不过他们目前也只是能添加字段而已，对别的DDL还是无效；或者使用pt-online-schema-change，当然在使用过程中，它需要建立触发器和影子表，同时也需要很长很长的时间，在此操作过程中的所有时间，都可以看做是风险时间。把数据表切分，总量减小，有助于改善这种风险。<br>（3）整个表热点，数据访问和更新频繁，经常有锁等待，你又没有能力去修改源码，降低锁的粒度，那么只会把其中的数据物理拆开，用空间换时间，变相降低访问压力。<br>原则二：表设计不合理，需要对某些字段垂直拆分<br>这里举一个例子，如果你有一个用户表，在最初设计的时候可能是这样：<br>table :users<br>id bigint 用户的ID<br>name varchar 用户的名字<br>last_login_time datetime 最近登录时间<br>personal_info text 私人信息<br>xxxxx 其他信息字段。<br>一般的users表会有很多字段，我就不列举了。如上所示，在一个简单的应用中，这种设计是很常见的。但是：<br>设想情况一：你的业务中彩了，用户数从100w飙升到10个亿。你为了统计活跃用户，在每个人登录的时候都会记录一下他的最近登录时间。并且的用户活跃得很，不断的去更新这个login_time，搞的你的这个表不断的被update，压力非常大。那么，在这个时候，只要考虑对它进行拆分，站在业务的角度，最好的办法是先把last_login_time拆分出去，我们叫它 user_time。这样做，业务的代码只有在用到这个字段的时候修改一下就行了。如果你不这么做，直接把users表水平切分了，那么，所有访问users表的地方，都要修改。或许你会说，我有proxy，能够动态merge数据。到目前为止我还从没看到谁家的proxy不影响性能的。<br>设想情况二：personal_info这个字段本来没啥用，你就是让用户注册的时候填一些个人爱好而已，基本不查询。一开始的时候有它没它无所谓。但是到后来发现两个问题，一，这个字段占用了大量的空间，因为是text嘛，有很多人喜欢长篇大论地介绍自己。更糟糕的是二，不知道哪天哪个产品经理心血来潮，说允许个人信息公开吧，以方便让大家更好的相互了解。那么在所有人猎奇窥私心理的影响下，对此字段的访问大幅度增加。数据库压力瞬间抗不住了，这个时候，只好考虑对这个表的垂直拆分了。<br>原则三：某些数据表出现了无穷增长<br>例子很好举，各种的评论，消息，日志记录。这个增长不是跟人口成比例的，而是不可控的，例如微博的feed的广播，我发一条消息，会扩散给很多很多人。虽然主体可能只存一份，但不排除一些索引或者路由有这种存储需求。这个时候，增加存储，提升机器配置已经苍白无力了，水平切分是最佳实践。拆分的标准很多，按用户的，按时间的，按用途的，不在一一举例。<br>原则四：安全性和可用性的考虑<br>这个很容易理解，鸡蛋不要放在一个篮子里，我不希望我的数据库出问题，但我希望在出问题的时候不要影响到100%的用户，这个影响的比例越少越好，那么，水平切分可以解决这个问题，把用户，库存，订单等等本来同统一的资源切分掉，每个小的数据库实例承担一小部分业务，这样整体的可用性就会提升。这对Qunar这样的业务还是比较合适的，人与人之间，某些库存与库存之间，关联不太大，可以做一些这样的切分。<br>原则五：业务耦合性考虑<br>这个跟上面有点类似，主要是站在业务的层面上，我们的火车票业务和烤羊腿业务是完全无关的业务，虽然每个业务的数据量可能不太大，放在一个MySQL实例中完全没问题，但是很可能烤羊腿业务的DBA 或者开发人员水平很差，动不动给你出一些幺蛾子，直接把数据库搞挂。这个时候，火车票业务的人员虽然技术很优秀，工作也很努力，照样被老板打屁股。解决的办法很简单:惹不起，躲得起。<br>20条规则摘要如下：<br>规则1：一般情况可以选择MyISAM存储引擎，如果需要事务支持必须使用InnoDB存储引擎。<br>规则2：命名规则。<br>规则3：数据库字段类型定义</li><li>经常需要计算和排序等消耗CPU的字段,应该尽量选择更为迅速的字段，如用TIMESTAMP(4个字节，最小值1970-01-01 00:00:00)代替Datetime（8个字节，最小值1001-01-01 00:00:00）,通过整型替代浮点型和字符型</li><li>变长字段使用varchar，不要使用char</li><li>对于二进制多媒体数据，流水队列数据(如日志)，超大文本数据不要放在数据库字段中<br>规则4：业务逻辑执行过程必须读到的表中必须要有初始的值。避免业务读出为负或无穷大的值导致程序失败<br>规则5：并不需要一定遵守范式理论，适度的冗余，让Query尽量减少Join<br>规则6：访问频率较低的大字段拆分出数据表。有些大字段占用空间多，访问频率较其他字段明显要少很多，这种情况进行拆分，频繁的查询中就不需要读取大字段，造成IO资源的浪费。<br>规则7： 水平分表，这个我还是建议 三思，搞不好非但不能提升性能反而多了很多的join和磁盘IO，开发起来也麻烦，有很多的业务就是要求一次查询大部分的字段 看你业务场景了。大表可以考虑水平拆分。大表影响查询效率，根据业务特性有很多拆分方式，像根据时间递增的数据，可以根据时间来分。以id划分的数据，可根据id%数据库个数的方式来拆分。<br>规则8：业务需要的相关索引是根据实际的设计所构造sql语句的where条件来确定的，业务不需要的不要建索引，不允许在联合索引（或主键）中存在多于的字段。特别是该字段根本不会在条件语句中出现。<br>规则9：唯一确定一条记录的一个字段或多个字段要建立主键或者唯一索引，不能唯一确定一条记录，为了提高查询效率建普通索引。<br>规则10：业务使用的表，有些记录数很少，甚至只有一条记录，为了约束的需要，也要建立索引或者设置主键。<br>规则11：对于取值不能重复，经常作为查询条件的字段，应该建唯一索引(主键默认唯一索引)，并且将查询条件中该字段的条件置于第一个位置。没有必要再建立与该字段有关的联合索引。<br>规则12：对于经常查询的字段，其值不唯一，也应该考虑建立普通索引，查询语句中该字段条件置于第一个位置，对联合索引处理的方法同样。<br>规则13：业务通过不唯一索引访问数据时，需要考虑通过该索引值返回的记录稠密度，原则上可能的稠密度最大不能高于0.2，如果稠密度太大，则不合适建立索引了。<br>规则14：需要联合索引(或联合主键)的数据库要注意索引的顺序。SQL语句中的匹配条件也要跟索引的顺序保持一致。<br>注意：索引的顺势不正确也可能导致严重的后果。<br>规则15：表中的多个字段查询作为查询条件，不含有其他索引，并且字段联合值不重复，可以在这多个字段上建唯一的联合索引，假设索引字段为 (a1,a2,…an),则查询条件(a1 op val1,a2 op val2,…am op valm)m&lt;=n,可以用到索引，查询条件中字段的位置与索引中的字段位置是一致的。<br>规则16：联合索引的建立原则(以下均假设在数据库表的字段a,b,c上建立联合索引(a,b,c))。<br>规则17：重要业务访问数据表时。但不能通过索引访问数据时，应该确保顺序访问的记录数目是有限的，原则上不得多于10。<br>规则18：合理构造Query语句，慢SQL监控，检查是否有大量的的子查询和关联查询 嵌套查询等，尽量避免使用这些查询， 使用连接（JOIN）来代替子查询(Sub-Queries)，使用联合(UNION)来代替手动创建的临时表。<br>规则19：应用系统的优化。<br>规则20：可以结合redis，memcache等缓存服务，把这些复杂的sql进行拆分， 充分利用二级缓存 ，减少数据库IO操作。对数据库连接池，mybatis，hiberante二级缓存充分利用上。尽量使用顺序IO代替随机IO。合理使用索引，尽量避免全表扫描。</li></ol><h1 id="MySQL-InnoDB、Mysaim的特点？"><a href="#MySQL-InnoDB、Mysaim的特点？" class="headerlink" title="MySQL InnoDB、Mysaim的特点？"></a>MySQL InnoDB、Mysaim的特点？</h1><p>a. InnoDB：</p><ol><li>⽀持事务处理</li><li>⽀持外键</li><li>⽀持⾏锁</li><li>不⽀持FULLTEXT类型的索引（在Mysql5.6已引⼊）</li><li>不保存表的具体⾏数，扫描表来计算有多少⾏</li><li>对于AUTO_INCREMENT类型的字段，必须包含只有该字段的索引</li><li>DELETE 表时，是⼀⾏⼀⾏的删除</li><li>InnoDB 把数据和索引存放在表空间⾥⾯</li><li>跨平台可直接拷⻉使⽤</li><li>表格很难被压缩<br>b. MyISAM：</li><li>不⽀持事务，回滚将造成不完全回滚，不具有原⼦性</li><li>不⽀持外键</li><li>⽀持全⽂搜索</li><li>保存表的具体⾏数,不带where时，直接返回保存的⾏数</li><li>DELETE 表时，先drop表，然后重建表</li><li>MyISAM 表被存放在三个⽂件 。frm ⽂件存放表格定义。 数据⽂件是MYD (MYData) 。 索引⽂件是MYI<br>(MYIndex)引伸</li><li>跨平台很难直接拷⻉</li><li>AUTO_INCREMENT类型字段可以和其他字段⼀起建⽴联合索引</li><li>表格可以被压缩<br>c. 选择：因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原⼦性要求低。那么MyISAM最好<br>的选择。且MyISAM恢复速度快。可直接⽤备份覆盖恢复。如果系统读少，写多的时候，尤其是并发写⼊⾼的时候。<br>InnoDB就是⾸选了。两种类型都有⾃⼰优缺点，选择那个完全要看⾃⼰的实际类弄。</li></ol><h1 id="⾏锁，表锁；乐观锁，悲观锁？"><a href="#⾏锁，表锁；乐观锁，悲观锁？" class="headerlink" title="⾏锁，表锁；乐观锁，悲观锁？"></a>⾏锁，表锁；乐观锁，悲观锁？</h1><p>a. ⾏锁：数据库表中某⼀⾏被锁住。<br>b. 表锁：整个数据库表被锁住。<br>c. 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别⼈不会修改，具体实现是给表增加⼀个版本号的字<br>段，在执⾏update操作时⽐较该版本号是否与当前数据库中版本号⼀致，如⼀致，更新数据，反之拒绝。<br>d. 悲观锁：顾名思义，就是很悲观，每次去拿数据的时候都认为别⼈会修改。读数据的时候会上锁，直到update完成才<br>释放锁，使⽤悲观锁要注意不要锁住整个表。</p><h1 id="数据库隔离级别是什么？有什么作⽤？"><a href="#数据库隔离级别是什么？有什么作⽤？" class="headerlink" title="数据库隔离级别是什么？有什么作⽤？"></a>数据库隔离级别是什么？有什么作⽤？</h1><ol><li>ISOLATIONREADUNCOMMITTED 这是事务最低的隔离级别，它允许另外⼀个事务可以看到这个事务未提交的数据。<br>这种隔离级别会产⽣脏读，不可重复读和幻读。</li><li>ISOLATIONREADCOMMITTED 保证⼀个事务修改的数据提交后才能被另外⼀个事务读取。另外⼀个事务不能读取该<br>事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻读。</li><li>ISOLATIONREPEATABLEREAD 这种事务隔离级别可以防⽌脏读，不可重复读。但是可能出现幻读。它除了保证⼀个<br>事务不能读取另⼀个事务未提交的数据外，还保证了避免不可重复读。</li><li>ISOLATION_SERIALIZABLE 这是花费最⾼代价但是最可靠的事务隔离级别。事务被处理为顺序执⾏。除了防⽌脏读，<br>不可重复读外，还避免了幻读。</li></ol><h1 id="MySQL主备同步的基本原理。"><a href="#MySQL主备同步的基本原理。" class="headerlink" title="MySQL主备同步的基本原理。"></a>MySQL主备同步的基本原理。</h1><p>mysql主备复制实现分成三个步骤：<br>1、master将改变记录到⼆进制⽇志(binary log)中（这些记录叫做⼆进制⽇志事件，binary log events，可以通过show<br>binlog events进⾏查看）；<br>2、slave将master的binary log events拷⻉到它的中继⽇志(relay log)；<br>3、slave重做中继⽇志中的事件，将改变反映它⾃⼰的数据。</p><h1 id="select-from-table-t-where-size-gt-10-group-by-size-order-by-size的sql语句执⾏顺序？"><a href="#select-from-table-t-where-size-gt-10-group-by-size-order-by-size的sql语句执⾏顺序？" class="headerlink" title="select * from table t where size &gt; 10 group by size order by size的sql语句执⾏顺序？"></a>select * from table t where size &gt; 10 group by size order by size的sql语句执⾏顺序？</h1><p>sql语句执⾏顺序如下：<br>where -&gt; group by -&gt; having -&gt; select -&gt; orderby</p><h1 id="如何优化数据库性能（索引、分库分表、批置操作、分⻚算法、升级硬盘SSD、业务优化、主从部署）"><a href="#如何优化数据库性能（索引、分库分表、批置操作、分⻚算法、升级硬盘SSD、业务优化、主从部署）" class="headerlink" title="如何优化数据库性能（索引、分库分表、批置操作、分⻚算法、升级硬盘SSD、业务优化、主从部署）"></a>如何优化数据库性能（索引、分库分表、批置操作、分⻚算法、升级硬盘SSD、业务优化、主从部署）</h1><p>1、选择合适的数据库引擎，合理使⽤索引<br>2、分⻚获取数据，只获取需要的字段<br>3、优化业务逻辑，减少数据库IO<br>4、分库分表<br>5、部署主从数据库<br>6、升级硬件</p><h1 id="SQL什么情况下不会使⽤索引（不包含，不等于，函数）"><a href="#SQL什么情况下不会使⽤索引（不包含，不等于，函数）" class="headerlink" title="SQL什么情况下不会使⽤索引（不包含，不等于，函数）"></a>SQL什么情况下不会使⽤索引（不包含，不等于，函数）</h1><p>a. select * 可能导致不⾛索引；<br>b. 空值会导致不⾛索引，因为hashset不能存空值；<br>c. 索引列有函数运算，不⾛索引，可以在索引列建⽴⼀个函数的索引。<br>d. 隐式转换可能导致不⾛索引；<br>e. 表的数据库⼩或者需要选择⼤部分数据，不⾛索引；<br>f. !=或者&lt;&gt;可能导致不⾛索引；<br>g. 字符型的索引列会导致优化器认为需要扫描索引⼤部分数据且聚簇因⼦很⼤，最终导致弃⽤索引扫描⽽改⽤全表扫描<br>⽅式<br>h. like ‘%liu’ 百分号在前不⾛索引；<br>i. not in, not exist不⾛索引；</p><h1 id="—般在什么字段上建索引（过滤数据最多的字段）"><a href="#—般在什么字段上建索引（过滤数据最多的字段）" class="headerlink" title="—般在什么字段上建索引（过滤数据最多的字段）"></a>—般在什么字段上建索引（过滤数据最多的字段）</h1><p>1、表的主键、外键必须有索引；<br>2、数据量超过300的表应该有索引；<br>3、经常与其他表进⾏连接的表，在连接字段上应该建⽴索引；<br>4、经常出现在Where⼦句中的字段，特别是⼤表的字段，应该建⽴索引；<br>5、索引应该建在选择性⾼的字段上；<br>6、索引应该建在⼩字段上，对于⼤的⽂本字段甚⾄超⻓字段，不要建索引；</p><h1 id="如何从⼀张表中查出name字段不包含”XYZ”的所有⾏？"><a href="#如何从⼀张表中查出name字段不包含”XYZ”的所有⾏？" class="headerlink" title="如何从⼀张表中查出name字段不包含”XYZ”的所有⾏？"></a>如何从⼀张表中查出name字段不包含”XYZ”的所有⾏？</h1><p>1 select * from table where name not like ‘%XYZ%’;</p><h1 id="HRedis-RDB和A0Ff如何做⾼可⽤、集群"><a href="#HRedis-RDB和A0Ff如何做⾼可⽤、集群" class="headerlink" title="HRedis, RDB和A0Ff如何做⾼可⽤、集群"></a>HRedis, RDB和A0Ff如何做⾼可⽤、集群</h1><h1 id="如何解决⾼并发减库存问题"><a href="#如何解决⾼并发减库存问题" class="headerlink" title="如何解决⾼并发减库存问题"></a>如何解决⾼并发减库存问题</h1><p>消息队列，异步处理，减库存加锁</p><h1 id="mysql存储引擎中索引的实现机制；"><a href="#mysql存储引擎中索引的实现机制；" class="headerlink" title="mysql存储引擎中索引的实现机制；"></a>mysql存储引擎中索引的实现机制；</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/debug_zhang/article/details/52168552">https://blog.csdn.net/debug_zhang/article/details/52168552</a></p><h1 id="数据库事务的⼏种粒度；"><a href="#数据库事务的⼏种粒度；" class="headerlink" title="数据库事务的⼏种粒度；"></a>数据库事务的⼏种粒度；</h1><p>a. 表锁定：对整个表的锁定。<br>b. ⾏锁定：只锁定进⾏更改的⾏，例如：insert，update，delete，都隐式采⽤⾏锁定。<br>c. 数据库锁机制可分为多种粒度的： 数据库，表，⻚⾯，⾏<br>d. 粒度越⼤，DBMS管理越容易，但是实现并发处理的能⼒就越差，表，⻚⾯，⾏</p><h1 id="mysql调优："><a href="#mysql调优：" class="headerlink" title="mysql调优："></a>mysql调优：</h1><p>a. explain select语句；<br>b. 当只要⼀条数据时使⽤limit 1；<br>c. 为搜索字段建索引；<br>d. 避免select *；<br>e. 字段尽量使⽤not null；<br>f. 垂直分割；<br>g. 拆分⼤的delete和insert语句：delete和insert会锁表；<br>h. 分表分库分区。</p><h1 id="说说事务的四种特性（ACID）？"><a href="#说说事务的四种特性（ACID）？" class="headerlink" title="说说事务的四种特性（ACID）？"></a>说说事务的四种特性（ACID）？</h1><h4 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性 (Atomicity)"></a>原子性 (Atomicity)</h4><p>原子性是指事冬是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p><h4 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性 (Consistency)"></a>一致性 (Consistency)</h4><p>事务前后数据的完整性必须保持一致。(比如转账)</p><h4 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性 (Isolation)"></a>隔离性 (Isolation)</h4><p>事务的隔离性是指多个用户并发访问数据库时，一个用户的事务不能被其它用户的事务所干扰，多个并发事务之间数据要相互隔。</p><h4 id="持久性-Durability"><a href="#持久性-Durability" class="headerlink" title="持久性(Durability)"></a>持久性(Durability)</h4><p>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响。</p><h1 id="innodb如何实现mysql的事务？"><a href="#innodb如何实现mysql的事务？" class="headerlink" title="innodb如何实现mysql的事务？"></a>innodb如何实现mysql的事务？</h1><p>事务进⾏过程中，每次sql语句执⾏，都会记录undo log和redo log，然后更新数据形成脏⻚，然后redo log按照时间或<br>者空间等条件进⾏落盘，undo log和脏⻚按照checkpoint进⾏落盘，落盘后相应的redo log就可以删除了。此时，事务还未<br>COMMIT，如果发⽣崩溃，则⾸先检查checkpoint记录，使⽤相应的redo log进⾏数据和undo log的恢复，然后查看undo log的状<br>态发现事务尚未提交，然后就使⽤undo log进⾏事务回滚。事务执⾏COMMIT操作时，会将本事务相关的所有redo log都进⾏落<br>盘，只有所有redo log落盘成功，才算COMMIT成功。然后内存中的数据脏⻚继续按照checkpoint进⾏落盘。如果此时发⽣了崩<br>溃，则只使⽤redo log恢复数据。</p><h1 id="让你设计⼀个索引，你会怎么设计？"><a href="#让你设计⼀个索引，你会怎么设计？" class="headerlink" title="让你设计⼀个索引，你会怎么设计？"></a>让你设计⼀个索引，你会怎么设计？</h1><p>mysql默认存储引擎innodb只显式⽀持B树索引，对于频繁访问的表，innodb会透明建⽴⾃适应hash索引，即在B树索引<br>基础上建⽴hash索引，可以显著提⾼查找效率，对于客户端是透明的，不可控制的，隐式的。</p><h1 id="用两种方式根据部门号从高到低，工资从低到高列出每个员工的信息。"><a href="#用两种方式根据部门号从高到低，工资从低到高列出每个员工的信息。" class="headerlink" title="用两种方式根据部门号从高到低，工资从低到高列出每个员工的信息。"></a>用两种方式根据部门号从高到低，工资从低到高列出每个员工的信息。</h1><p>employee:<br>eid,ename,salary,deptid;<br>select * from employee order by deptid desc,salary</p><h1 id="列出各个部门中工资高于本部门的平均工资的员工数和部门号，并按部门号排序"><a href="#列出各个部门中工资高于本部门的平均工资的员工数和部门号，并按部门号排序" class="headerlink" title="列出各个部门中工资高于本部门的平均工资的员工数和部门号，并按部门号排序"></a>列出各个部门中工资高于本部门的平均工资的员工数和部门号，并按部门号排序</h1><p>创建表：<br>mysql&gt; create table employee921(id int primary key auto_increment,name varchar(5<br>0),salary bigint,deptid int);</p><p>插入实验数据：<br>mysql&gt; insert into employee921 values(null,’zs’,1000,1),(null,’ls’,1100,1),(null<br>,’ww’,1100,1),(null,’zl’,900,1) ,(null,’zl’,1000,2), (null,’zl’,900,2) ,(null,’z<br>l’,1000,2) , (null,’zl’,1100,2);</p><p>编写sql语句：</p><p>（）select avg(salary) from employee921 group by deptid;<br>（）mysql&gt; select employee921.id,employee921.name,employee921.salary,employee921.dep<br>tid tid from employee921 where salary &gt; (select avg(salary) from employee921 where deptid = tid);<br>效率低的一个语句，仅供学习参考使用（在group by之后不能使用where，只能使用having，在group by之前可以使用where，即表示对过滤后的结果分组）：<br>mysql&gt; select employee921.id,employee921.name,employee921.salary,employee921.dep<br>tid tid from employee921 where salary &gt; (select avg(salary) from employee921 group by deptid having deptid = tid);<br>（）select count(*) ,tid<br>from (<br>select employee921.id,employee921.name,employee921.salary,employee921.deptid tid<br>from employee921<br>where salary &gt;<br>(select avg(salary) from employee921 where deptid = tid)<br>) as t<br>group by tid ;</p><p>另外一种方式：关联查询<br>select a.ename,a.salary,a.deptid<br>from emp a,<br>(select deptd,avg(salary) avgsal from emp group by deptid ) b<br>where a.deptid=b.deptid and a.salary&gt;b.avgsal;</p><h1 id="存储过程与触发器必须讲，经常被面试到"><a href="#存储过程与触发器必须讲，经常被面试到" class="headerlink" title="存储过程与触发器必须讲，经常被面试到?"></a>存储过程与触发器必须讲，经常被面试到?</h1><p>create procedure insert_Student (_name varchar(50),_age int ,out _id int)<br>begin<br>insert into student value(null,_name,_age);<br>select max(stuId) into _id from student;<br>end;</p><p>call insert_Student(‘wfz’,23,@id);<br>select @id;</p><p>mysql&gt; create trigger update_Student BEFORE update on student FOR EACH ROW<br>-&gt; select * from student;<br>触发器不允许返回结果</p><p>create trigger update_Student BEFORE update on student FOR EACH ROW<br>insert into student value(null,’zxx’,28);<br>mysql的触发器目前不能对当前表进行操作</p><p>create trigger update_Student BEFORE update on student FOR EACH ROW<br>delete from articles where id=8;<br>这个例子不是很好，最好是用删除一个用户时，顺带删除该用户的所有帖子<br>这里要注意使用OLD.id</p><p>触发器用处还是很多的，比如校内网、开心网、Facebook，你发一个日志，自动通知好友，其实就是在增加日志时做一个后触发，再向通知表中写入条目。因为触发器效率高。而UCH没有用触发器，效率和数据处理能力都很低。<br>存储过程的实验步骤：<br>mysql&gt; delimiter |<br>mysql&gt; create procedure insertArticle_Procedure (pTitle varchar(50),pBid int,out<br>pId int)<br>-&gt; begin<br>-&gt; insert into article1 value(null,pTitle,pBid);<br>-&gt; select max(id) into pId from article1;<br>-&gt; end;<br>-&gt; |<br>Query OK, 0 rows affected (0.05 sec)</p><p>mysql&gt; call insertArticle_Procedure(‘传智播客’,1,@pid);<br>-&gt; |<br>Query OK, 0 rows affected (0.00 sec)</p><p>mysql&gt; delimiter ;<br>mysql&gt; select @pid;<br>+——+<br>| @pid |<br>+——+<br>| 3 |<br>+——+<br>1 row in set (0.00 sec)</p><p>mysql&gt; select * from article1;<br>+—-+————–+——+<br>| id | title | bid |<br>+—-+————–+——+<br>| 1 | test | 1 |<br>| 2 | chuanzhiboke | 1 |<br>| 3 | 传智播客 | 1 |<br>+—-+————–+——+<br>3 rows in set (0.00 sec)</p><p>触发器的实验步骤：<br>create table board1(id int primary key auto_increment,name varchar(50),ar<br>ticleCount int);</p><p>create table article1(id int primary key auto_increment,title varchar(50)<br>,bid int references board1(id));</p><p>delimiter |</p><p>create trigger insertArticle_Trigger after insert on article1 for each ro<br>w begin<br>-&gt; update board1 set articleCount=articleCount+1 where id= NEW.bid;<br>-&gt; end;<br>-&gt; |</p><p>delimiter ;</p><p>insert into board1 value (null,’test’,0);</p><p>insert into article1 value(null,’test’,1);<br>还有，每插入一个帖子，都希望将版面表中的最后发帖时间，帖子总数字段进行同步更新，用触发器做效率就很高。下次课设计这样一个案例，写触发器时，对于最后发帖时间可能需要用declare方式声明一个变量，或者是用NEW.posttime来生成。</p><h1 id="数据库三范式是什么"><a href="#数据库三范式是什么" class="headerlink" title="数据库三范式是什么?"></a>数据库三范式是什么?</h1><p>第一范式（1NF）：字段具有原子性,不可再分。所有关系型数据库系统都满足第一范式）<br>数据库表中的字段都是单一属性的，不可再分。例如，姓名字段，其中的姓和名必须作为一个整体，无法区分哪部分是姓，哪部分是名，如果要区分出姓和名，必须设计成两个独立的字段。</p><p>  第二范式（2NF）：<br>第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。<br>要求数据库表中的每个实例或行必须可以被惟一地区分。通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主关键字或主键。</p><p>第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。简而言之，第二范式就是非主属性非部分依赖于主关键字。<br>  <br>第三范式的要求如下：<br>满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。<br>所以第三范式具有如下特征：<br>         1，每一列只有一个值<br>         2，每一行都能区分。<br>         3，每一个表都不包含其他表已经包含的非主关键字信息。<br>例如，帖子表中只能出现发帖人的id，而不能出现发帖人的id，还同时出现发帖人姓名，否则，只要出现同一发帖人id的所有记录，它们中的姓名部分都必须严格保持一致，这就是数据冗余。</p><h1 id="说出一些数据库优化方面的经验"><a href="#说出一些数据库优化方面的经验" class="headerlink" title="说出一些数据库优化方面的经验?"></a>说出一些数据库优化方面的经验?</h1><p>用PreparedStatement 一般来说比Statement性能高：一个sql 发给服务器去执行，涉及步骤：语法检查、语义分析， 编译，缓存<br>“inert into user values(1,1,1)”-二进制<br>“inert into user values(2,2,2)”-二进制<br>“inert into user values(?,?,?)”-二进制</p><p>有外键约束会影响插入和删除性能，如果程序能够保证数据的完整性，那在设计数据库时就去掉外键。（比喻：就好比免检产品，就是为了提高效率，充分相信产品的制造商）<br>（对于hibernate来说，就应该有一个变化：empleyee-&gt;Deptment对象，现在设计时就成了employeedeptid）</p><p>看mysql帮助文档子查询章节的最后部分，例如，根据扫描的原理，下面的子查询语句要比第二条关联查询的效率高：</p><ol><li><p>select e.name,e.salary where e.managerid=(select id from employee where name=’zxx’);</p></li><li><p>select e.name,e.salary,m.name,m.salary from employees e,employees m where<br>e.managerid = m.id and m.name=’zxx’;</p></li></ol><p>表中允许适当冗余，譬如，主题帖的回复数量和最后回复时间等<br>将姓名和密码单独从用户表中独立出来。这可以是非常好的一对一的案例哟！</p><p>sql语句全部大写，特别是列名和表名都大写。特别是sql命令的缓存功能，更加需要统一大小写，sql语句发给oracle服务器语法检查和编译成为内部指令缓存和执行指令。根据缓存的特点，不要拼凑条件，而是用?和PreparedStatment</p><p>还有索引对查询性能的改进也是值得关注的。</p><p>备注：下面是关于性能的讨论举例</p><p>4航班 3个城市</p><p>m*n</p><p>select * from flight,city where flight.startcityid=city.cityid and city.name=’beijing’;</p><p>m + n</p><p>select * from flight where startcityid = (select cityid from city where cityname=’beijing’);</p><p>select flight.id,’beijing’,flight.flightTime from flight where startcityid = (select cityid from city where cityname=’beijing’)</p><h1 id="union和union-all有什么不同"><a href="#union和union-all有什么不同" class="headerlink" title="union和union all有什么不同?"></a>union和union all有什么不同?</h1><p>假设我们有一个表Student，包括以下字段与数据：<br>drop table student;<br>create table student<br>(<br>id int primary key,<br>name nvarchar2(50) not null,<br>score number not null<br>);<br>insert into student values(1,’Aaron’,78);<br>insert into student values(2,’Bill’,76);<br>insert into student values(3,’Cindy’,89);<br>insert into student values(4,’Damon’,90);<br>insert into student values(5,’Ella’,73);<br>insert into student values(6,’Frado’,61);<br>insert into student values(7,’Gill’,99);<br>insert into student values(8,’Hellen’,56);<br>insert into student values(9,’Ivan’,93);<br>insert into student values(10,’Jay’,90);<br>commit;<br>Union和Union All的区别。<br>select *<br>from student<br>where id &lt; 4<br>union<br>select *<br>from student<br>where id &gt; 2 and id &lt; 6<br>结果将是<br>1    Aaron    78<br>2    Bill    76<br>3    Cindy    89<br>4    Damon    90<br>5    Ella    73<br>如果换成Union All连接两个结果集，则返回结果是：<br>1    Aaron    78<br>2    Bill    76<br>3    Cindy    89<br>3    Cindy    89<br>4    Damon    90<br>5    Ella    73<br>可以看到，Union和Union All的区别之一在于对重复结果的处理。</p><p>　　UNION在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION。如：<br>select * from gc_dfys<br>union<br>select * from ls_jg_dfys<br>　　这个SQL在运行时先取出两个表的结果，再用排序空间进行排序删除重复的记录，最后返回结果集，如果表数据量大的话可能会导致用磁盘进行排序。<br>　而UNION ALL只是简单的将两个结果合并后就返回。这样，如果返回的两个结果集中有重复的数据，那么返回的结果集就会包含重复的数据了。<br>　从效率上说，UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复的数据的话，那么就使用UNION ALL，</p><h1 id="分页语句"><a href="#分页语句" class="headerlink" title="分页语句"></a>分页语句</h1><p>取出sql表中第31到40的记录（以自动增长ID为主键）<br>sql server方案1：<br>select top 10 * from t where id not in (select top 30 id from t order by id ) orde by id<br>sql server方案2：<br>select top 10 * from t where id in (select top 40 id from t order by id) order by id desc</p><p>mysql方案：select * from t order by id limit 30,10</p><p>oracle方案：select * from (select rownum r,* from t where r&lt;=40) where r&gt;30</p><p>——————–待整理进去的内容————————————-<br>pageSize=20;<br>pageNo = 5;</p><p>1.分页技术1（直接利用sql语句进行分页，效率最高和最推荐的）</p><p>mysql:sql = “select * from articles limit “ + (pageNo-1)<em>pageSize + “,” + pageSize;<br>oracle: sql = “select * from “ +<br>“(select rownum r,</em> from “ +<br>“(select * from articles order by postime desc)” +<br>“where rownum&lt;= “ + pageNo*pageSize +”) tmp “ +<br>“where r&gt;” + (pageNo-1)*pageSize;<br>注释：第7行保证rownum的顺序是确定的，因为oracle的索引会造成rownum返回不同的值<br>简洋提示：没有order by时，rownum按顺序输出，一旦有了order by，rownum不按顺序输出了，这说明rownum是排序前的编号。如果对order by从句中的字段建立了索引，那么，rownum也是按顺序输出的，因为这时候生成原始的查询结果集时会参照索引表的顺序来构建。</p><p>sqlserver:sql = “select top 10 * from id not id(select top “ + (pageNo-1)*pageSize + “id from articles)”</p><p>DataSource ds = new InitialContext().lookup(jndiurl);<br>Connection cn = ds.getConnection();<br>//“select * from user where id=?” —&gt;binary directive<br>PreparedStatement pstmt = cn.prepareSatement(sql);<br>ResultSet rs = pstmt.executeQuery()<br>while(rs.next())<br>{<br>out.println(rs.getString(1));<br>}</p><p>2.不可滚动的游标<br>pageSize=20;<br>pageNo = 5;<br>cn = null<br>stmt = null;<br>rs = null;<br>try<br>{<br>sqlserver:sql = “select * from articles”;</p><p>DataSource ds = new InitialContext().lookup(jndiurl);<br>Connection cn = ds.getConnection();<br>//“select * from user where id=?” —&gt;binary directive<br>PreparedStatement pstmt = cn.prepareSatement(sql);<br>ResultSet rs = pstmt.executeQuery()<br>for(int j=0;j&lt;(pageNo-1)*pageSize;j++)<br>{<br>rs.next();<br>}</p><p>int i=0;</p><p>while(rs.next() &amp;&amp; i&lt;10)<br>{<br>i++;<br>out.println(rs.getString(1));<br>}<br>}<br>cacth(){}<br>finnaly<br>{<br>if(rs!=null)try{rs.close();}catch(Exception e){}<br>if(stm………<br>if(cn…………<br>}</p><p>3.可滚动的游标<br>pageSize=20;<br>pageNo = 5;<br>cn = null<br>stmt = null;<br>rs = null;<br>try<br>{<br>sqlserver:sql = “select * from articles”;</p><p>DataSource ds = new InitialContext().lookup(jndiurl);<br>Connection cn = ds.getConnection();<br>//“select * from user where id=?” —&gt;binary directive<br>PreparedStatement pstmt = cn.prepareSatement(sql,ResultSet.TYPE_SCROLL_INSENSITIVE,…);<br>//根据上面这行代码的异常SQLFeatureNotSupportedException，就可判断驱动是否支持可滚动游标</p><p>ResultSet rs = pstmt.executeQuery()<br>rs.absolute((pageNo-1)*pageSize)<br>int i=0;<br>while(rs.next() &amp;&amp; i&lt;10)<br>{<br>i++;<br>out.println(rs.getString(1));<br>}<br>}<br>cacth(){}<br>finnaly<br>{<br>if(rs!=null)try{rs.close();}catch(Exception e){}<br>if(stm………<br>if(cn…………<br>}</p><h1 id="用一条SQL语句-查询出每门课都大于80分的学生姓名"><a href="#用一条SQL语句-查询出每门课都大于80分的学生姓名" class="headerlink" title="用一条SQL语句 查询出每门课都大于80分的学生姓名"></a>用一条SQL语句 查询出每门课都大于80分的学生姓名</h1><p>name   kecheng   fenshu<br>张三     语文       81<br>张三     数学       75<br>李四     语文       76<br>李四     数学       90<br>王五     语文       81<br>王五     数学       100<br>王五     英语       90</p><p>准备数据的sql代码：<br>create table score(id int primary key auto_increment,name varchar(20),subject varchar(20),score int);<br>insert into score values<br>(null,’张三’,’语文’,81),<br>(null,’张三’,’数学’,75),<br>(null,’李四’,’语文’,76),<br>(null,’李四’,’数学’,90),<br>(null,’王五’,’语文’,81),<br>(null,’王五’,’数学’,100),<br>(null,’王五 ‘,’英语’,90);</p><p>提示：当百思不得其解时，请理想思维，把小变成大做，把大变成小做，</p><p>答案：<br>A: select distinct name from score  where  name not in (select distinct name from score where score&lt;=80)</p><p>B:select distince name t1 from score where 80&lt; all (select score from score where name=t1);</p><h1 id="所有部门之间的比赛组合"><a href="#所有部门之间的比赛组合" class="headerlink" title="所有部门之间的比赛组合"></a>所有部门之间的比赛组合</h1><p>一个叫department的表，里面只有一个字段name,一共有4条纪录，分别是a,b,c,d,对应四个球对，现在四个球对进行比赛，用一条sql语句显示所有可能的比赛组合.</p><p>答：select a.name, b.name<br>from team a, team b<br>where a.name &lt; b.name</p><h1 id="每个月份的发生额都比101科目多的科目"><a href="#每个月份的发生额都比101科目多的科目" class="headerlink" title="每个月份的发生额都比101科目多的科目"></a>每个月份的发生额都比101科目多的科目</h1><p>请用SQL语句实现：从TestDB数据表中查询出所有月份的发生额都比101科目相应月份的发生额高的科目。请注意：TestDB中有很多科目，都有1－12月份的发生额。<br>AccID：科目代码，Occmonth：发生额月份，DebitOccur：发生额。<br>数据库名：JcyAudit，数据集：Select * from TestDB<br>准备数据的sql代码：<br>drop table if exists TestDB;<br>create table TestDB(id int primary key auto_increment,AccID varchar(20), Occmonth date, DebitOccur bigint);<br>insert into TestDB values<br>(null,’101’,’1988-1-1’,100),<br>(null,’101’,’1988-2-1’,110),<br>(null,’101’,’1988-3-1’,120),<br>(null,’101’,’1988-4-1’,100),<br>(null,’101’,’1988-5-1’,100),<br>(null,’101’,’1988-6-1’,100),<br>(null,’101’,’1988-7-1’,100),<br>(null,’101’,’1988-8-1’,100);<br>–复制上面的数据，故意把第一个月份的发生额数字改小一点<br>insert into TestDB values<br>(null,’102’,’1988-1-1’,90),<br>(null,’102’,’1988-2-1’,110),<br>(null,’102’,’1988-3-1’,120),<br>(null,’102’,’1988-4-1’,100),<br>(null,’102’,’1988-5-1’,100),<br>(null,’102’,’1988-6-1’,100),<br>(null,’102’,’1988-7-1’,100),<br>(null,’102’,’1988-8-1’,100);<br>–复制最上面的数据，故意把所有发生额数字改大一点<br>insert into TestDB values<br>(null,’103’,’1988-1-1’,150),<br>(null,’103’,’1988-2-1’,160),<br>(null,’103’,’1988-3-1’,180),<br>(null,’103’,’1988-4-1’,120),<br>(null,’103’,’1988-5-1’,120),<br>(null,’103’,’1988-6-1’,120),<br>(null,’103’,’1988-7-1’,120),<br>(null,’103’,’1988-8-1’,120);<br>–复制最上面的数据，故意把所有发生额数字改大一点<br>insert into TestDB values<br>(null,’104’,’1988-1-1’,130),<br>(null,’104’,’1988-2-1’,130),<br>(null,’104’,’1988-3-1’,140),<br>(null,’104’,’1988-4-1’,150),<br>(null,’104’,’1988-5-1’,160),<br>(null,’104’,’1988-6-1’,170),<br>(null,’104’,’1988-7-1’,180),<br>(null,’104’,’1988-8-1’,140);<br>–复制最上面的数据，故意把第二个月份的发生额数字改小一点<br>insert into TestDB values<br>(null,’105’,’1988-1-1’,100),<br>(null,’105’,’1988-2-1’,80),<br>(null,’105’,’1988-3-1’,120),<br>(null,’105’,’1988-4-1’,100),<br>(null,’105’,’1988-5-1’,100),<br>(null,’105’,’1988-6-1’,100),<br>(null,’105’,’1988-7-1’,100),<br>(null,’105’,’1988-8-1’,100);<br>答案：<br>select distinct AccID from TestDB<br>where AccID not in<br>(select TestDB.AccIDfrom TestDB,<br>(select * from TestDB where AccID=’101’) as db101<br>where TestDB.Occmonth=db101.Occmonth and TestDB.DebitOccur&lt;=db101.DebitOccur<br>);</p><h1 id="统计每年每月的信息"><a href="#统计每年每月的信息" class="headerlink" title="统计每年每月的信息"></a>统计每年每月的信息</h1><p>year  month amount<br>1991   1     1.1<br>1991   2     1.2<br>1991   3     1.3<br>1991   4     1.4<br>1992   1     2.1<br>1992   2     2.2<br>1992   3     2.3<br>1992   4     2.4<br>查成这样一个结果<br>year m1  m2  m3  m4<br>1991 1.1 1.2 1.3 1.4<br>1992 2.1 2.2 2.3 2.4</p><p>提示：这个与工资条非常类似，与学生的科目成绩也很相似。</p><p>准备sql语句：<br>drop table if exists sales;<br>create table sales(id int auto_increment primary key,year varchar(10), month varchar(10), amount float(2,1));<br>insert into sales values<br>(null,’1991’,’1’,1.1),<br>(null,’1991’,’2’,1.2),<br>(null,’1991’,’3’,1.3),<br>(null,’1991’,’4’,1.4),<br>(null,’1992’,’1’,2.1),<br>(null,’1992’,’2’,2.2),<br>(null,’1992’,’3’,2.3),<br>(null,’1992’,’4’,2.4);</p><p>答案一、<br>select sales.year ,<br>(select t.amount from sales t where t.month=’1’ and t.year= sales.year) ‘1’,<br>(select t.amount from sales t where t.month=’1’ and t.year= sales.year) ‘2’,<br>(select t.amount from sales t where t.month=’1’ and t.year= sales.year) ‘3’,<br>(select t.amount from sales t where t.month=’1’ and t.year= sales.year) as ‘4’<br>from sales group by year;</p><h1 id="显示文章标题，发帖人、最后回复时间"><a href="#显示文章标题，发帖人、最后回复时间" class="headerlink" title="显示文章标题，发帖人、最后回复时间"></a>显示文章标题，发帖人、最后回复时间</h1><p>表：id,title,postuser,postdate,parentid<br>准备sql语句：<br>drop table if exists articles;<br>create table articles(id int auto_increment primary key,title varchar(50), postuser varchar(10), postdate datetime,parentid int references articles(id));<br>insert into articles values<br>(null,’第一条’,’张三’,’1998-10-10 12:32:32’,null),<br>(null,’第二条’,’张三’,’1998-10-10 12:34:32’,null),<br>(null,’第一条回复1’,’李四’,’1998-10-10 12:35:32’,1),<br>(null,’第二条回复1’,’李四’,’1998-10-10 12:36:32’,2),<br>(null,’第一条回复2’,’王五’,’1998-10-10 12:37:32’,1),<br>(null,’第一条回复3’,’李四’,’1998-10-10 12:38:32’,1),<br>(null,’第二条回复2’,’李四’,’1998-10-10 12:39:32’,2),<br>(null,’第一条回复4’,’王五’,’1998-10-10 12:39:40’,1);</p><p>答案：<br>select a.title,a.postuser,<br>(select max(postdate) from articles where parentid=a.id) reply<br>from articles a where a.parentid is null;</p><p>注释：子查询可以用在选择列中，也可用于where的比较条件中，还可以用于from从句中。</p><h1 id="删除除了id号不同-其他都相同的学生冗余信息"><a href="#删除除了id号不同-其他都相同的学生冗余信息" class="headerlink" title="删除除了id号不同,其他都相同的学生冗余信息"></a>删除除了id号不同,其他都相同的学生冗余信息</h1><p>2.学生表 如下:<br>id号   学号   姓名 课程编号 课程名称 分数<br>1        2005001  张三  0001      数学    69<br>2        2005002  李四  0001      数学    89<br>3        2005001  张三  0001      数学    69<br>A: delete from tablename where id号 not in(select min(id号) from tablename group by 学号,姓名,课程编号,课程名称,分数)<br>实验：<br>create table student2(id int auto_increment primary key,code varchar(20),name varchar(20));<br>insert into student2 values(null,’2005001’,’张三’),(null,’2005002’,’李四’),(null,’2005001’,’张三’);</p><p>//如下语句，mysql报告错误，可能删除依赖后面统计语句，而删除又导致统计语句结果不一致。</p><p>delete from student2 where id not in(select min(id) from student2 group by name);<br>//但是，如下语句没有问题：<br>select * from student2 where id not in(select min(id) from student2 group by name);<br>//于是，我想先把分组的结果做成虚表，然后从虚表中选出结果，最后再将结果作为删除的条件数据。<br>delete from student2 where id not in(select mid from (select min(id) mid<br>from student2 group by name) as t);<br>或者：<br>delete from student2 where id not in(select min(id) from (select * from s<br>tudent2) as t group by t.name);</p><h1 id="航空网的几个航班查询题："><a href="#航空网的几个航班查询题：" class="headerlink" title="航空网的几个航班查询题："></a>航空网的几个航班查询题：</h1><p>表结构如下：<br>flight{flightID,StartCityID ,endCityID,StartTime}<br>city{cityID, CityName)<br>实验环境：<br>create table city(cityID int auto_increment primary key,cityName varchar(20));<br>create table flight (flightID int auto_increment primary key,<br>StartCityID int references city(cityID),<br>endCityID int references city(cityID),<br>StartTime timestamp);<br>//航班本来应该没有日期部分才好，但是下面的题目当中涉及到了日期<br>insert into city values(null,’北京’),(null,’上海’),(null,’广州’);<br>insert into flight values<br>(null,1,2,’9:37:23’),(null,1,3,’9:37:23’),(null,1,2,’10:37:23’),(null,2,3,’10:37:23’);</p><p>1、查询起飞城市是北京的所有航班，按到达城市的名字排序</p><p>参与运算的列是我起码能够显示出来的那些列，但最终我不一定把它们显示出来。各个表组合出来的中间结果字段中必须包含所有运算的字段。</p><p>select * from flight f,city c<br>where f.endcityid = c.cityid and startcityid =<br>(select c1.cityid from city c1 where c1.cityname = “北京”)<br>order by c.cityname asc;</p><p>mysql&gt; select flight.flightid,’北京’ startcity, e.cityname from flight,city e wh<br>ere flight.endcityid=e.cityid and flight.startcityid=(select cityid from city wh<br>ere cityname=’北京’);</p><p>mysql&gt; select flight.flightid,s.cityname,e.cityname from flight,city s,city e wh<br>ere flight.startcityid=s.cityid and s.cityname=’北京’ and flight.endCityId=e.cit<br>yID order by e.cityName desc;</p><p>2、查询北京到上海的所有航班纪录（起飞城市，到达城市，起飞时间，航班号）<br>select c1.CityName,c2.CityName,f.StartTime,f.flightID<br>from city c1,city c2,flight f<br>where f.StartCityID=c1.cityID<br>and f.endCityID=c2.cityID<br>and c1.cityName=’北京’<br>and c2.cityName=’上海’<br>3、查询具体某一天（2005-5-8）的北京到上海的的航班次数<br>select count(*) from<br>(select c1.CityName,c2.CityName,f.StartTime,f.flightID<br>from city c1,city c2,flight f<br>where f.StartCityID=c1.cityID<br>and f.endCityID=c2.cityID<br>and c1.cityName=’北京’<br>and c2.cityName=’上海’<br>and 查帮助获得的某个日期处理函数(startTime) like ‘2005-5-8%’</p><p>mysql中提取日期部分进行比较的示例代码如下：<br>select * from flight where date_format(starttime,’%Y-%m-%d’)=’1998-01-02’</p><h1 id="查出比经理薪水还高的员工信息："><a href="#查出比经理薪水还高的员工信息：" class="headerlink" title="查出比经理薪水还高的员工信息："></a>查出比经理薪水还高的员工信息：</h1><p>Drop table if not exists employees;<br>create table employees(id int primary key auto_increment,name varchar(50)<br>,salary int,managerid int references employees(id));<br>insert into employees values (null,’ lhm’,10000,null), (null,’ zxx’,15000,1<br>),(null,’flx’,9000,1),(null,’tg’,10000,2),(null,’wzg’,10000,3);</p><p>Wzg大于flx,lhm大于zxx</p><p>解题思路：<br>根据sql语句的查询特点，是逐行进行运算，不可能两行同时参与运算。<br>涉及了员工薪水和经理薪水，所有，一行记录要同时包含两个薪水，所有想到要把这个表自关联组合一下。<br>首先要组合出一个包含有各个员工及该员工的经理信息的长记录，譬如，左半部分是员工，右半部分是经理。而迪卡尔积会组合出很多垃圾信息，先去除这些垃圾信息。</p><p>select e.* from employees e,employees m where e.managerid=m.id and e.sala<br>ry&gt;m.salary;</p><h1 id="求出小于45岁的各个老师所带的大于12岁的学生人数"><a href="#求出小于45岁的各个老师所带的大于12岁的学生人数" class="headerlink" title="求出小于45岁的各个老师所带的大于12岁的学生人数"></a>求出小于45岁的各个老师所带的大于12岁的学生人数</h1><p>数据库中有3个表 teacher 表，student表，tea_stu关系表。<br>teacher 表 teaID name age<br>student 表 stuID name age<br>teacher_student表 teaID stuID<br>要求用一条sql查询出这样的结果<br>1.显示的字段要有老师name, age 每个老师所带的学生人数<br>2 只列出老师age为40以下，学生age为12以上的记录<br>预备知识：<br>1.sql语句是对每一条记录依次处理，条件为真则执行动作（select,insert,delete,update）<br>2.只要是迪卡尔积，就会产生“垃圾”信息，所以，只要迪卡尔积了，我们首先就要想到清除“垃圾”信息<br>实验准备：<br>drop table if exists tea_stu;<br>drop table if exists teacher;<br>drop table if exists student;<br>create table teacher(teaID int primary key,name varchar(50),age int);<br>create table student(stuID int primary key,name varchar(50),age int);<br>create table tea_stu(teaID int references teacher(teaID),stuID int references student(stuID));<br>insert into teacher values(1,’zxx’,45), (2,’lhm’,25) , (3,’wzg’,26) , (4,’tg’,27);<br>insert into student values(1,’wy’,11), (2,’dh’,25) , (3,’ysq’,26) , (4,’mxc’,27);<br>insert into tea_stu values(1,1), (1,2), (1,3);<br>insert into tea_stu values(2,2), (2,3), (2,4);<br>insert into tea_stu values(3,3), (3,4), (3,1);<br>insert into tea_stu values(4,4), (4,1), (4,2) , (4,3);</p><p>结果：23,32,43</p><p>解题思路：（真实面试答题时，也要写出每个分析步骤，如果纸张不够，就找别人要）<br>1要会统计分组信息，统计信息放在中间表中：<br>select teaid,count(*) from tea_stu group by teaid;</p><p>2接着其实应该是筛除掉小于12岁的学生，然后再进行统计，中间表必须与student关联才能得到12岁以下学生和把该学生记录从中间表中剔除，代码是：<br>select tea_stu.teaid,count(*) total from student,tea_stu<br>where student.stuid=tea_stu.stuid and student.age&gt;12 group by tea_stu.teaid</p><p>3.接着把上面的结果做成虚表与teacher进行关联，并筛除大于45的老师<br>select teacher.teaid,teacher.name,total from teacher ,(select tea_stu.tea<br>id,count(*) total from student,tea_stu where student.stuid=tea_stu.stuid and stu<br>dent.age&gt;12 group by tea_stu.teaid) as tea_stu2 where teacher.teaid=tea_stu2.tea<br>id and teacher.age&lt;45;</p><h1 id="求出发帖最多的人："><a href="#求出发帖最多的人：" class="headerlink" title="求出发帖最多的人："></a>求出发帖最多的人：</h1><p>select authorid,count(<em>) total from articles<br>group by authorid<br>having total=<br>(select max(total2) from (select count(</em>) total2 from articles group by authorid) as t);</p><p>select t.authorid,max(t.total) from<br>（select authorid,count(*) total from articles ）as t<br>这条语句不行，因为max只有一列，不能与其他列混淆。</p><p>select authorid,count(*) total from articles<br>group by authorid having total=max(total)也不行。</p><h1 id="一个用户表中有一个积分字段，假如数据库中有100多万个用户，若要在每年第一天凌晨将积分清零，你将考虑什么，你将想什么办法解决"><a href="#一个用户表中有一个积分字段，假如数据库中有100多万个用户，若要在每年第一天凌晨将积分清零，你将考虑什么，你将想什么办法解决" class="headerlink" title="一个用户表中有一个积分字段，假如数据库中有100多万个用户，若要在每年第一天凌晨将积分清零，你将考虑什么，你将想什么办法解决?"></a>一个用户表中有一个积分字段，假如数据库中有100多万个用户，若要在每年第一天凌晨将积分清零，你将考虑什么，你将想什么办法解决?</h1><p>alter table drop column score;<br>alter table add colunm score int;<br>可能会很快，但是需要试验，试验不能拿真实的环境来操刀，并且要注意，<br>这样的操作时无法回滚的，在我的印象中，只有inert update delete等DML语句才能回滚，<br>对于create table,drop table ,alter table等DDL语句是不能回滚。</p><p>解决方案一，update user set score=0;<br>解决方案二，假设上面的代码要执行好长时间，超出我们的容忍范围，那我就alter table user drop column score;alter table user add column score int。</p><p>下面代码实现每年的那个凌晨时刻进行清零。<br>Runnable runnable =<br>new Runnable(){<br>public void run(){<br>clearDb();<br>schedule(this,new Date(new Date().getYear()+1,0,0));<br>}<br>};</p><p>schedule(runnable,<br>new Date(new Date().getYear()+1,0,1));</p><h1 id="一个用户具有多个角色，请查询出该表中具有该用户的所有角色的其他用户。"><a href="#一个用户具有多个角色，请查询出该表中具有该用户的所有角色的其他用户。" class="headerlink" title="一个用户具有多个角色，请查询出该表中具有该用户的所有角色的其他用户。"></a>一个用户具有多个角色，请查询出该表中具有该用户的所有角色的其他用户。</h1><p>select count(*) as num,tb.id<br>from<br>tb,<br>(select role from tb where id=xxx) as t1<br>where<br>tb.role = t1.role and tb.id != t1.id<br>group by tb.id<br>having<br>num = select count(role) from tb where id=xxx;</p><h1 id="xxx公司的sql面试"><a href="#xxx公司的sql面试" class="headerlink" title="xxx公司的sql面试"></a>xxx公司的sql面试</h1><p>Table EMPLOYEES Structure:<br>EMPLOYEE_ID NUMBER Primary Key,<br>FIRST_NAME VARCHAR2(25),<br>LAST_NAME VARCHAR2(25),<br>Salary number(8,2),<br>HiredDate DATE,<br>Departmentid number(2)<br>Table Departments Structure:<br>Departmentid number(2) Primary Key,<br>DepartmentName VARCHAR2(25).</p><p>(2）基于上述EMPLOYEES表写出查询：写出雇用日期在今年的，或者工资在[1000,2000]之间的，或者员工姓名（last_name）以’Obama’打头的所有员工，列出这些员工的全部个人信息。（4分）<br>select * from employees<br>where Year(hiredDate) = Year(date())<br>or (salary between 1000 and 200)<br>or left(last_name,3)=’abc’;</p><p>(3) 基于上述EMPLOYEES表写出查询：查出部门平均工资大于1800元的部门的所有员工，列出这些员工的全部个人信息。（4分）<br>mysql&gt; select id,name,salary,deptid did from employee1 where (select avg(salary)<br>from employee1 where deptid = did) &gt; 1800;</p><p>(4) 基于上述EMPLOYEES表写出查询：查出个人工资高于其所在部门平均工资的员工，列出这些员工的全部个人信息及该员工工资高出部门平均工资百分比。（5分）<br>select employee1.*,(employee1.salary-t.avgSalary)*100/employee1.salary<br>from employee1,<br>(select deptid,avg(salary) avgSalary from employee1 group by deptid) as t<br>where employee1.deptid = t.deptid and employee1.salary&gt;t.avgSalary;</p><h1 id="oracle中除了数据库备份，还有什么方法备份？"><a href="#oracle中除了数据库备份，还有什么方法备份？" class="headerlink" title="oracle中除了数据库备份，还有什么方法备份？"></a>oracle中除了数据库备份，还有什么方法备份？</h1><p>Oracle数据库有三种标准的备份方法，它们分别是导出/导入(EXP/IMP)、热备份和冷备份。导出备份是一种逻辑备份，冷备份和热备份是物理备份。</p><h1 id="truncate与delete的区别？（delete-from-table和truncate-table-tablea的区别！）"><a href="#truncate与delete的区别？（delete-from-table和truncate-table-tablea的区别！）" class="headerlink" title="truncate与delete的区别？（delete from table和truncate table tablea的区别！）"></a>truncate与delete的区别？（delete from table和truncate table tablea的区别！）</h1><p>truncate是DDL語言.delete是DML語言 DDL語言是自動提交的.命令完成就不可回滾.truncate的速度也比delete要快得多.<br>详细说明：<br>相同点:truncate和不带where子句的delete, 以及drop都会删除表内的数据<br>不同点:</p><ol><li>truncate和 delete只删除数据不删除表的结构(定义)<br>drop语句将删除表的结构被依赖的约束(constrain),触发器(trigger),索引(index); 依赖于该表的存储过程/函数将保留,但是变为invalid状态.</li><li>delete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效;如果有相应的trigger,执行的时候将被触发.<br>truncate,drop是ddl, 操作立即生效,原数据不放到rollback segment中,不能回滚. 操作不触发trigger.</li><li>delete语句不影响表所占用的extent, 高水线(high watermark)保持原位置不动<br>显然drop语句将表所占用的空间全部释放<br>truncate 语句缺省情况下见空间释放到 minextents个 extent,除非使用reuse storage; truncate会将高水线复位(回到最开始).</li><li>速度,一般来说: drop&gt; truncate &gt; delete</li><li>安全性:小心使用drop 和truncate,尤其没有备份的时候.否则哭都来不及<br>使用上,想删除部分数据行用delete,注意带上where子句. 回滚段要足够大.<br>想删除表,当然用drop<br>想保留表而将所有数据删除. 如果和事务无关,用truncate即可. 如果和事务有关,或者想触发trigger,还是用delete.</li></ol><h1 id="Oracle冷备份的通常步骤"><a href="#Oracle冷备份的通常步骤" class="headerlink" title="Oracle冷备份的通常步骤"></a>Oracle冷备份的通常步骤</h1><p>1 正常关闭数据库 2 备份所有重要的文件到备份目录（数据文件、控制文件、重做日志文件等）<br>3 完成备份后启动数据库用冷备份进行恢复时，只需要将所有文件恢复到原有位置，就可以启动数据库了<br>4关闭数据库 SQL&gt;shutdown 5 备份文件到备份的目录 6 然后启动数据库 ＃sqlplus “/as sysdba”SQL&gt;startup 冷备份完毕！！</p><h1 id="对数据库的访问是怎么实现的"><a href="#对数据库的访问是怎么实现的" class="headerlink" title="对数据库的访问是怎么实现的"></a>对数据库的访问是怎么实现的</h1><p>将对持久层数据库的基本添加，修改，查找等操作提取到BaseDAO中,采用JavaBean对数据进行封装，以便对持久层的数据能够很好的处理，实现BaseDAO设计对数据库访问的便捷。业务组件通过DAO 的委托接口调用DAO对象，使得上层组件不 直接依赖于DAO的实现类.</p><h1 id="接口与抽象类的区别"><a href="#接口与抽象类的区别" class="headerlink" title="接口与抽象类的区别"></a>接口与抽象类的区别</h1><p>声明方法的存在而不去实现它的类被叫做抽象类（abstract class），它用于要创建一个体现某些基本行为的类，并为该类声明方法，但不能在该类中实现该类的情况。不能创建abstract 类的实例。然而可以创建一个变量，其类型是一个抽象类，并让它指向具体子类的一个实例。不能有抽象构造函数或抽象静态方法。Abstract 类的子类为它们父类中的所有抽象方法提供实现，否则它们也是抽象类为。取而代之，在子类中实现该方法。知道其行为的其它类可以在类中实现这些方法。<br>接 口（interface）是抽象类的变体。在接口中，所有方法都是抽象的。多继承性可通过实现这样的接口而获得。接口中的所有方法都是抽象的，没有一个有 程序体。接口只可以定义static final成员变量。接口的实现与子类相似，除了该实现类不能从接口定义中继承行为。当类实现特殊接口时，它定义（即将程序体给予）所有这种接口的方法。 然后，它可以在实现了该接口的类的任何对象上调用接口的方法。由于有抽象类，它允许使用接口名作为引用变量的类型。通常的动态联编将生效。引用可以转换到 接口类型或从接口类型转换，instanceof 运算符可以用来决定某对象的类是否实现了接口。</p><h1 id="数据库优化的方案"><a href="#数据库优化的方案" class="headerlink" title="数据库优化的方案"></a>数据库优化的方案</h1><pre><code>建立主键，为数据库创建索引，建立存储过程，触发器，可提高查询速度。
</code></pre><p>1、一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，<br>再把 Mysql 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15 ？<br>(1)如果表的类型是 MyISAM，那么是 18<br>因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里，重启 MySQL 自增主键的最大<br>ID 也不会丢失<br>（2）如果表的类型是 InnoDB，那么是 15<br>InnoDB 表只是把自增主键的最大 ID 记录到内存中，所以重启数据库或者是对表进行<br>OPTIMIZE 操作，都会导致最大 ID 丢失<br>2、Mysql 的技术特点是什么？<br>Mysql 数据库软件是一个客户端或服务器系统，其中包括：支持各种客户端程序和库的多<br>线程 SQL 服务器、不同的后端、广泛的应用程序编程接口和管理工具。<br>3、Heap 表是什么？<br>HEAP 表存在于内存中，用于临时高速存储。<br>BLOB 或 TEXT 字段是不允许的<br>只能使用比较运算符=，&lt;，&gt;，=&gt;，= &lt;<br>HEAP 表不支持 AUTO_INCREMENT<br>索引不可为 NULL<br>4、Mysql 服务器默认端口是什么？<br>Mysql 服务器的默认端口是 3306。<br>5、与 Oracle 相比，Mysql 有什么优势？<br>Mysql 是开源软件，随时可用，无需付费。<br>Mysql 是便携式的<br>带有命令提示符的 GUI。<br>使用 Mysql 查询浏览器支持管理<br>6、如何区分 FLOAT 和 DOUBLE？<br>以下是 FLOAT 和 DOUBLE 的区别：<br>浮点数以 8 位精度存储在 FLOAT 中，并且有四个字节。<br>浮点数存储在 DOUBLE 中，精度为 18 位，有八个字节。<br>7、区分 CHAR_LENGTH 和 LENGTH？<br>CHAR_LENGTH 是字符数，而 LENGTH 是字节数。Latin 字符的这两个数据是相同的，但是对<br>于 Unicode 和其他编码，它们是不同的。<br>8、请简洁描述 Mysql 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？<br>SQL 标准定义的四个隔离级别为：<br>read uncommited ：读到未提交数据<br>read committed：脏读，不可重复读<br>repeatable read：可重读<br>serializable ：串行事物<br>9、在 Mysql 中 ENUM 的用法是什么？<br>ENUM 是一个字符串对象，用于指定一组预定义的值，并可在创建表时使用。<br>Create table size(name ENUM(‘Smail,’Medium’,’Large’);<br>10、如何定义 REGEXP？<br>REGEXP 是模式匹配，其中匹配模式在搜索值的任何位置。<br>11、CHAR 和 VARCHAR 的区别？<br>以下是 CHAR 和 VARCHAR 的区别：<br>CHAR 和 VARCHAR 类型在存储和检索方面有所不同<br>CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255<br>当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。<br>12、列的字符串类型可以是什么？<br>字符串类型是：<br>SET<br>BLOB<br>ENUM<br>CHAR<br>TEXT<br>VARCHAR<br>13、如何获取当前的 Mysql 版本？<br>SELECT VERSION();用于获取当前 Mysql 的版本。<br>14、Mysql 中使用什么存储引擎？<br>存储引擎称为表类型，数据使用各种技术存储在文件中。<br>技术涉及：<br>Storage mechanism<br>Locking levels<br>Indexing<br>Capabilities and functions.<br>15、Mysql 驱动程序是什么？<br>以下是 Mysql 中可用的驱动程序：<br>PHP 驱动程序<br>JDBC 驱动程序<br>ODBC 驱动程序<br>CWRAPPER PYTHON<br>驱动程序 PERL 驱动<br>程序 RUBY 驱动程<br>序 CAP11PHP 驱动<br>程序<br>Ado.net5.mxj<br>16、TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据类型上做什么？<br>创建表时 TIMESTAMP 列用 Zero 更新。只要表中的其他字段发生更改，UPDATE<br>CURRENT_TIMESTAMP 修饰符就将时间戳字段更新为当前时间。<br>17、主键和候选键有什么区别？<br>表格的每一行都由主键唯一标识,一个表只有一个主键。<br>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。<br>18、如何使用 Unix shell 登录 Mysql？<br>我们可以通过以下命令登录：<br>[mysql dir]/bin/mysql -h hostname -u<br>19、 myisamchk 是用来做什么的？<br>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。<br>20、MYSQL 数据库服务器性能分析的方法命令有哪些?<br>21、如何控制 HEAP 表的最大尺寸？<br>Heal 表的大小可通过称为 max_heap_table_size 的 Mysql 配置变量来控制。<br>22、MyISAM Static 和 MyISAM Dynamic 有什么区别？<br>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB 等字<br>段，以适应不同长度的数据类型。点击这里有一套最全阿里面试题总结。<br>MyISAM Static 在受损情况下更容易恢复。<br>23、federated 表是什么？<br>federated 表，允许访问位于其他服务器数据库上的表。<br>24、如果一个表有一列定义为 TIMESTAMP，将发生什么？<br>每当行被更改时，时间戳字段将获取当前时间戳。<br>25、列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？<br>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。<br>26、怎样才能找出最后一次插入时分配了哪个自动增量？<br>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。<br>27、你怎么看到为表格定义的所有索引？<br>索引是通过以下方式为表格定义的：<br>SHOW INDEX FROM<br>28.、LIKE 声明中的％和_是什么意思？<br>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。<br>29、如何在 Unix 和 Mysql 时间戳之间进行转换？<br>UNIX_TIMESTAMP 是从 Mysql 时间戳转换为 Unix 时间戳的命令<br>FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql 时间戳的命令<br>30、列对比运算符是什么？<br>在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或 LIKE 运<br>算符。<br>31、我们如何得到受查询影响的行数？<br>行数可以通过以下代码获得：<br>SELECT COUNT(user_id)FROM users;<br>32、Mysql 查询是否区分大小写？<br>不区分<br>SELECT VERSION(), CURRENT_DATE;<br>SeLect version(), current_date;<br>seleCt vErSiOn(), current_DATE;<br>所有这些例子都是一样的，Mysql 不区分大小写。<br>33.、LIKE 和 REGEXP 操作有什么区别？<br>LIKE 和 REGEXP 运算符用于表示^和％。<br>SELECT * FROM employee WHERE emp_name REGEXP “^b”;<br>SELECT * FROM employee WHERE emp_name LIKE “%b”;<br>34.、BLOB 和 TEXT 有什么区别？<br>BLOB 是一个二进制对象，可以容纳可变数量的数据。有四种类型的 BLOB -<br>TINYBLOB<br>BLOB<br>MEDIUMBLOB 和 LONGBLOB 它们只能在所能容纳<br>价值的最大长度上有所不同。<br>TEXT 是一个不区分大小写的 BLOB。四种 TEXT 类型<br>TINYTEXT<br>TEXT<br>MEDIUMTEXT 和<br>LONGTEXT<br>它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。<br>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT<br>值不区分大小写。<br>35、mysql_fetch_array 和 mysql_fetch_object 的区别是什么？<br>以下是 mysql_fetch_array 和 mysql_fetch_object 的区别：<br>mysql_fetch_array（） - 将结果行作为关联数组或来自数据库的常规数组返回。<br>mysql_fetch_object - 从数据库返回结果行作为对象。<br>36、我们如何在 mysql 中运行批处理模式？<br>以下命令用于在批处理模式下运行：<br>mysql;<br>mysql mysql.out<br>37、MyISAM 表格将在哪里存储，并且还提供其存储格式？<br>每个 MyISAM 表格以三种格式存储在磁盘上：<br>·“.frm”文件存储表定义<br>·数据文件具有“.MYD”（MYData）扩展名<br>索引文件具有“.MYI”（MYIndex）扩展名<br>38.、Mysql 中有哪些不同的表格？<br>共有 5 种类型的表格：<br>MyISAM<br>Heap<br>Merge<br>INNODB<br>ISAM<br>MyISAM 是 Mysql 的默认存储引擎。<br>39、ISAM 是什么？<br>ISAM 简称为索引顺序访问方法。它是由 IBM 开发的，用于在磁带等辅助存储系统上存储和<br>检索数据。<br>40、InnoDB 是什么？<br>lnnoDB 是一个由 Oracle 公司开发的 Innobase Oy 事务安全存储引擎。<br>41、Mysql 如何优化 DISTINCT？<br>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。<br>1<br>SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;<br>42、如何输入字符为十六进制数字？<br>如果想输入字符为十六进制数字，可以输入带有单引号的十六进制数字和前缀（X），或者<br>只用（Ox）前缀输入十六进制数字。<br>如果表达式上下文是字符串，则十六进制数字串将自动转换为字符串。<br>43、如何显示前 50 行？<br>在 Mysql 中，使用以下代码查询显示前 50 行：<br>SELECT*FROM<br>LIMIT 0,50;<br>44、可以使用多少列创建索引？<br>任何标准表最多可以创建 16 个索引列。<br>45、NOW（）和 CURRENT_DATE（）有什么区别？<br>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。<br>CURRENT_DATE（）仅显示当前年份，月份和日期。<br>46、什么样的对象可以使用 CREATE 语句创建？<br>以下对象是使用 CREATE 语句创建的：<br>DATABASE<br>EVENT<br>FUNCTION<br>INDEX<br>PROCEDURE<br>TABLE<br>TRIGGER<br>USER<br>VIEW<br>47、Mysql 表中允许有多少个 TRIGGERS？<br>在 Mysql 表中允许有六个触发器，如下：<br>BEFORE INSERT<br>AFTER INSERT<br>BEFORE UPDATE<br>AFTER UPDATE<br>BEFORE DELETE<br>AFTER DELETE<br>48、什么是非标准字符串类型？<br>以下是非标准字符串类型：<br>TINYTEXT<br>TEXT<br>MEDIUMTEXT<br>LONGTEXT<br>49、什么是通用 SQL 函数？<br>CONCAT(A, B) - 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合<br>并为一个字段。<br>FORMAT(X, D)- 格式化数字 X 到 D 有效数字。<br>CURRDATE(), CURRTIME()- 返回当前日期或时间。<br>NOW（） - 将当前日期和时间作为一个值返回。<br>MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） - 从日期值中提取给定数据。<br>HOUR（），MINUTE（），SECOND（） - 从时间值中提取给定数据。<br>DATEDIFF（A，B） - 确定两个日期之间的差异，通常用于计算年龄<br>SUBTIMES（A，B） - 确定两次之间的差异。<br>FROMDAYS（INT） - 将整数天数转换为日期值。<br>50、解释访问控制列表<br>ACL（访问控制列表）是与对象关联的权限列表。这个列表是 Mysql 服务器安全模型的基<br>础，它有助于排除用户无法连接的问题。<br>Mysql 将 ACL（也称为授权表）缓存在内存中。当用户尝试认证或运行命令时，Mysql 会按<br>照预定的顺序检查 ACL 的认证信息和权限。<br>51、MYSQL 支持事务吗？<br>在缺省模式下，MYSQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，所<br>以在缺省情况下，mysql 是不支持事务的。<br>但是如果你的 MYSQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的 MYSQL 就可以<br>使用事务处理,使用 SET AUTOCOMMIT=0 就可以使 MYSQL 允许在非 autocommit 模式，在非<br>autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK 来回滚你的<br>更改。<br>示例如下：<br>一<br>START TRANSACTION;<br>SELECT @A:=SUM(salary) FROM table1 WHERE type=1;<br>UPDATE table2 SET summmary=@A WHERE type=1;<br>COMMIT;<br>52、mysql 里记录货币用什么字段类型好<br>NUMERIC 和 DECIMAL 类型被 Mysql 实现为同样的类型，这在 SQL92 标准允许。他们被用于<br>保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些<br>类型之一时，精度和规模的能被(并且通常是)指定；点击这里有一套最全阿里面试题总<br>结。<br>例如：<br>salary DECIMAL(9,2)<br>在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代表将被用于<br>存储小数点后的位数。<br>因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到 9999999.99。<br>在 ANSI/ISO SQL92 中，句法 DECIMAL(p)等价于 DECIMAL(p,0)。<br>同样，句法 DECIMAL 等价于 DECIMAL(p,0)，这里实现被允许决定值 p。Mysql 当前不支持<br>DECIMAL/NUMERIC 数据类型的这些变种形式的任一种。<br>这一般说来不是一个严重的问题，因为这些类型的主要益处得自于明显地控制精度和规模<br>的能力。<br>DECIMAL 和 NUMERIC 值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小<br>数精度。<br>一个字符用于值的每一位、小数点(如果 scale&gt;0)和“-”符号(对于负值)。如果 scale 是 0，<br>DECIMAL 和 NUMERIC 值不包含小数点或小数部分。<br>DECIMAL 和 NUMERIC 值得最大的范围与 DOUBLE 一样，但是对于一个给定的 DECIMAL 或<br>NUMERIC 列，实际的范围可由制由给定列的 precision 或 scale 限制。<br>当这样的列赋给了小数点后面的位超过指定 scale 所允许的位的值，该值根据 scale 四舍五<br>入。<br>当一个 DECIMAL 或 NUMERIC 列被赋给了其大小超过指定(或缺省的）precision 和 scale 隐含<br>的范围的值，Mysql 存储表示那个范围的相应的端点值。<br>我希望本文可以帮助你提升技术水平。那些，感觉学的好难，甚至会令你沮丧的人，别担<br>心，我认为，如果你愿意试一试本文介绍的几点，会向前迈进，克服这种感觉。这些要点<br>也许对你不适用，但你会明确一个重要的道理：接受自己觉得受困这个事实是摆脱这个困<br>境的第一步。<br>53、MYSQL 数据表在什么情况下容易损坏？<br>服务器突然断电导致数据文件损坏。<br>强制关机，没有先关闭 mysql 服务等。<br>54、mysql 有关权限的表都有哪几个？<br>Mysql 服务器通过权限表来控制用户对数据库的访问，权限表存放在 mysql 数据库里，由<br>mysql_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv 和<br>host。<br>55、Mysql 中有哪几种锁？<br>MyISAM 支持表锁，InnoDB 支持表锁和行锁，默认为行锁<br>表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量<br>最低<br>行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高<br>最后，欢迎做 Java 的工程师朋友们加入 Java 高级架构进阶 Qqun：963944895<br>群内有技术大咖指点难题，还提供免费的 Java 架构学习资料（里面有高可用、高并发、高性能及分布式、<br>Jvm 性能调优、Spring 源码，MyBatis，Netty,Redis,Kafka,Mysql,Zookeeper,Tomcat,Docker,Dubbo,Nginx 等多个<br>知识点的架构资料）<br>比你优秀的对手在学习，你的仇人在磨刀，你的闺蜜在减肥，隔壁老王在练腰， 我们必须不断学习，否则我<br>们将被学习者超越！<br>趁年轻，使劲拼，给未来的自己一个交代！</p><p>1、一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，<br>删除了第 15,16,17 条记录，再把 Mysql 重启，再 insert 一条记<br>录，这条记录的 ID 是 18 还是 15 ？<br>答<br>(1)如果表的类型是MylSAM，那么是18因为MyISAM表会把自增主键的最大ID记录到数据文件里，重启MySQL自增主键的最大ID也不会丢失(2)如果表的类型是InnoDB，那么是15InnoDB表只是把自增主键的最大ID记录到内存中，所以重启数据库或者是对表进行OPTIMIZE操作，都会导致最大ID丢失。<br>2、Mysql 的技术特点是什么？<br>Mysql 数据库软件是一个客户端或服务器系统，其中包括：支持各种客户端程序和库的多<br>线程 SQL 服务器、不同的后端、广泛的应用程序编程接口和管理工具。<br>3、Heap 表是什么？<br>HEAP 表存在于内存中，用于临时高速存储。<br> BLOB 或 TEXT 字段是不允许的<br> 只能使用比较运算符=，&lt;，&gt;，=&gt;，= &lt;<br> HEAP 表不支持 AUTO_INCREMENT<br> 索引不可为 NULL<br>4、Mysql 服务器默认端口是什么？<br>Mysql 服务器的默认端口是 3306。<br>5、与 Oracle 相比，Mysql 有什么优势？<br> Mysql 是开源软件，随时可用，无需付费。<br> Mysql 是便携式的<br> 带有命令提示符的 GUI。<br> 使用 Mysql 查询浏览器支持管理<br>6、如何区分 FLOAT 和 DOUBLE？<br>以下是 FLOAT 和 DOUBLE 的区别：<br>浮点数以 8 位精度存储在 FLOAT 中，并且有四个字节。<br>浮点数存储在 DOUBLE 中，精度为 18 位，有八个字节。<br>7、区分 CHAR_LENGTH 和 LENGTH？<br>CHAR_LENGTH 是字符数，而 LENGTH 是字节数。Latin 字符的这两个数据是相同的，<br>但是对于 Unicode 和其他编码，它们是不同的。<br>8、请简洁描述 Mysql 中 InnoDB 支持的四种事务隔离级别名<br>称，以及逐级之间的区别？<br>SQL 标准定义的四个隔离级别为：<br>read uncommited ：读到未提交数据<br>read committed：脏读，不可重复读<br>repeatable read：可重读<br>serializable ：串行事物<br>9、在 Mysql 中 ENUM 的用法是什么？<br>ENUM 是一个字符串对象，用于指定一组预定义的值，并可在创建表时使用。<br>Create table size(name ENUM(‘Smail,’Medium’,’Large’);<br>10、如何定义 REGEXP？<br>REGEXP 是模式匹配，其中匹配模式在搜索值的任何位置。<br>11、CHAR 和 VARCHAR 的区别？<br>以下是 CHAR 和 VARCHAR 的区别：<br> CHAR 和 VARCHAR 类型在存储和检索方面有所不同<br> CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255<br>当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。<br>12、列的字符串类型可以是什么？<br>字符串类型是：<br> SET<br> BLOB<br> ENUM<br> CHAR<br> TEXT<br> VARCHAR<br>13、如何获取当前的 Mysql 版本？<br>SELECT VERSION();用于获取当前 Mysql 的版本。<br>14、Mysql 中使用什么存储引擎？<br>存储引擎称为表类型，数据使用各种技术存储在文件中。<br>技术涉及：<br> Storage mechanism<br> Locking levels<br> Indexing<br> Capabilities and functions. 15、Mysql 驱动程序是什么？<br>以下是 Mysql 中可用的驱动程序：<br> PHP 驱动程序<br> JDBC 驱动程序<br> ODBC 驱动程序<br> CWRAPPER<br> PYTHON 驱动程序<br> PERL 驱动程序<br> RUBY 驱动程序<br> CAP11PHP 驱动程序<br> Ado.net5.mxj<br>16、TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据<br>类型上做什么？<br>创建表时 TIMESTAMP 列用 Zero 更新。只要表中的其他字段发生更改，UPDATE<br>CURRENT_TIMESTAMP 修饰符就将时间戳字段更新为当前时间。<br>17、主键和候选键有什么区别？<br>表格的每一行都由主键唯一标识,一个表只有一个主键。<br>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。<br>18、如何使用 Unix shell 登录 Mysql？<br>我们可以通过以下命令登录：</p><h1 id="mysql-dir-bin-mysql-h-hostname-u-p"><a href="#mysql-dir-bin-mysql-h-hostname-u-p" class="headerlink" title="[mysql dir]/bin/mysql -h hostname -u  -p "></a>[mysql dir]/bin/mysql -h hostname -u<username>-p<password></password></username></h1><p>19、 myisamchk 是用来做什么的？<br>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。<br>20、MYSQL 数据库服务器性能分析的方法命令有哪些?<br>Show status<br>·一些值得监控的变量值:<br>Bytes_received和Bytes sent·和服务器之间来往的流量。·Com_服务器正在执行的命令<br>·Created*在查询执行期限间创建的临时表和文件。<br>·Handler_*存储引擎操作。<br>·Select_*不同类型的联接执行计划。<br>·Sort_<em>几种排序信息。<br>Show session status like ‘Select;<br>Show profilesSET profiling=1;Show profileslGShow profile;<br>21、如何控制 HEAP 表的最大尺寸？<br>Heal 表的大小可通过称为 max_heap_table_size 的 Mysql 配置变量来控制。<br>22、MyISAM Static 和 MyISAM Dynamic 有什么区别？<br>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB<br>等字段，以适应不同长度的数据类型。点击这里有一套最全阿里面试题总结。<br>MyISAM Static 在受损情况下更容易恢复。<br>23、federated 表是什么？<br>federated 表，允许访问位于其他服务器数据库上的表。<br>24、如果一个表有一列定义为 TIMESTAMP，将发生什么？<br>每当行被更改时，时间戳字段将获取当前时间戳。<br>25、列设置为 AUTO INCREMENT 时，如果在表中达到最大<br>值，会发生什么情况？<br>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。<br>26、怎样才能找出最后一次插入时分配了哪个自动增量？<br>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名<br>称。<br>27、你怎么看到为表格定义的所有索引？<br>索引是通过以下方式为表格定义的：<br>SHOW INDEX FROM<tablename>;<br>28.、LIKE 声明中的％和_是什么意思？<br>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。<br>29、如何在 Unix 和 Mysql 时间戳之间进行转换？<br>UNIX_TIMESTAMP 是从 Mysql 时间戳转换为 Unix 时间戳的命令<br>FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql 时间戳的命令<br>30、列对比运算符是什么？<br>在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或<br>LIKE 运算符。<br>31、我们如何得到受查询影响的行数？<br>行数可以通过以下代码获得：<br>SELECT COUNT(user_id)FROM users;<br>32、Mysql 查询是否区分大小写？<br>不区分<br>SELECT VERSION(), CURRENT_DATE;<br>SeLect version(), current_date;<br>seleCt vErSiOn(), current_DATE;<br>所有这些例子都是一样的，Mysql 不区分大小写。<br>33.、LIKE 和 REGEXP 操作有什么区别？<br>LIKE 和 REGEXP 运算符用于表示^和％。<br>SELECT * FROM employee WHERE emp_name REGEXP “^b”;<br>SELECT * FROM employee WHERE emp_name LIKE “%b”;<br>34.、BLOB 和 TEXT 有什么区别？<br>BLOB 是一个二进制对象，可以容纳可变数量的数据。有四种类型的 BLOB -  TINYBLOB<br> BLOB<br> MEDIUMBLOB<br> LONGBLOB<br>它们只能在所能容纳价值的最大长度上有所不同。<br>TEXT 是一个不区分大小写的 BLOB。四种 TEXT 类型<br> TINYTEXT<br> TEXT<br> MEDIUMTEXT<br> LONGTEXT<br>它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。<br>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对<br>TEXT 值不区分大小写。<br>35、mysql_fetch_array 和 mysql_fetch_object 的区别是什么？<br>以下是 mysql_fetch_array 和 mysql_fetch_object 的区别：<br>mysql_fetch_array（） - 将结果行作为关联数组或来自数据库的常规数组返回。<br>mysql_fetch_object - 从数据库返回结果行作为对象。<br>36、我们如何在 mysql 中运行批处理模式？<br>以下命令用于在批处理模式下运行：<br>mysql;<br>mysql mysql.out<br>37、MyISAM 表格将在哪里存储，并且还提供其存储格式？<br>每个 MyISAM 表格以三种格式存储在磁盘上：<br>·“.frm”文件存储表定义<br>·数据文件具有“.MYD”（MYData）扩展名<br>索引文件具有“.MYI”（MYIndex）扩展名<br>38.、Mysql 中有哪些不同的表格？<br>共有 5 种类型的表格：<br> MyISAM<br> Heap<br> Merge<br> INNODB<br> ISAM<br>MyISAM 是 Mysql 的默认存储引擎。<br>39、ISAM 是什么？<br>ISAM 简称为索引顺序访问方法。它是由 IBM 开发的，用于在磁带等辅助存储系统上存储<br>和检索数据。<br>40、InnoDB 是什么？<br>lnnoDB 是一个由 Oracle 公司开发的 Innobase Oy 事务安全存储引擎。<br>41、Mysql 如何优化 DISTINCT？<br>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。<br>SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;<br>42、如何输入字符为十六进制数字？<br>如果想输入字符为十六进制数字，可以输入带有单引号的十六进制数字和前缀（X），或者<br>只用（Ox）前缀输入十六进制数字。<br>如果表达式上下文是字符串，则十六进制数字串将自动转换为字符串。<br>43、如何显示前 50 行？<br>在 Mysql 中，使用以下代码查询显示前 50 行：<br>SELECT</tablename></em>FROM<br>LIMIT 0,50;<br>44、可以使用多少列创建索引？<br>任何标准表最多可以创建 16 个索引列。<br>45、NOW（）和 CURRENT_DATE（）有什么区别？<br>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。<br>CURRENT_DATE（）仅显示当前年份，月份和日期。<br>46、什么样的对象可以使用 CREATE 语句创建？<br>以下对象是使用 CREATE 语句创建的：<br> DATABASE<br> EVENT<br> FUNCTION<br> INDEX<br> PROCEDURE<br> TABLE<br> TRIGGER<br> USER<br> VIEW<br>47、Mysql 表中允许有多少个 TRIGGERS？<br>在 Mysql 表中允许有六个触发器，如下：<br> BEFORE INSERT<br> AFTER INSERT<br> BEFORE UPDATE<br> AFTER UPDATE<br> BEFORE DELETE<br> AFTER DELETE<br>48、什么是非标准字符串类型？<br>以下是非标准字符串类型：<br> TINYTEXT<br> TEXT<br> MEDIUMTEXT<br> LONGTEXT<br>49、什么是通用 SQL 函数？<br> CONCAT(A, B) - 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个<br>字段合并为一个字段。<br> FORMAT(X, D)- 格式化数字 X 到 D 有效数字。<br> CURRDATE(), CURRTIME()- 返回当前日期或时间。<br> NOW（） - 将当前日期和时间作为一个值返回。<br> MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） - 从日期值中<br>提取给定数据。<br> HOUR（），MINUTE（），SECOND（） - 从时间值中提取给定数据。<br> DATEDIFF（A，B） - 确定两个日期之间的差异，通常用于计算年龄<br> SUBTIMES（A，B） - 确定两次之间的差异。<br> FROMDAYS（INT） - 将整数天数转换为日期值。<br>50、解释访问控制列表<br>ACL（访问控制列表）是与对象关联的权限列表。这个列表是 Mysql 服务器安全模型的基<br>础，它有助于排除用户无法连接的问题。<br>Mysql 将 ACL（也称为授权表）缓存在内存中。当用户尝试认证或运行命令时，Mysql 会<br>按照预定的顺序检查 ACL 的认证信息和权限。<br>51、MYSQL 支持事务吗？<br>在缺省模式下，MYSQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，<br>所以在缺省情况下，mysql 是不支持事务的。<br>但是如果你的 MYSQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的 MYSQL<br>就 可 以 使 用 事 务 处 理 , 使 用 SET AUTOCOMMIT=0 就 可 以 使 MYSQL 允 许 在 非<br>autocommit 模式，在非 autocommit 模式下，你必须使用 COMMIT 来提交你的更改，<br>或者用 ROLLBACK 来回滚你的更改。<br>示例如下：<br>START TRANSACTION;<br>SELECT @A:=SUM(salary) FROM table1 WHERE type=1;<br>UPDATE table2 SET summmary=@A WHERE type=1;<br>COMMIT;<br>52、 mysql 里记录货币用什么字段类型好<br>NUMERIC 和 DECIMAL 类型被 Mysql 实现为同样的类型，这在 SQL92 标准允许。他们<br>被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是<br>这些类型之一时，精度和规模的能被(并且通常是)指定；点击这里有一套最全阿里面试题总<br>结。<br>例如：<br>salary DECIMAL(9,2)<br>在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代表将被用<br>于存储小数点后的位数。<br>因 此 ， 在 这 种 情 况 下 ， 能 被 存 储 在 salary 列 中 的 值 的 范 围 是 从 -9999999.99 到<br>9999999.99。在 ANSI/ISO SQL92 中，句法 DECIMAL(p)等价于 DECIMAL(p,0)。<br>同样，句法 DECIMAL 等价于 DECIMAL(p,0)，这里实现被允许决定值 p。Mysql 当前不<br>支持 DECIMAL/NUMERIC 数据类型的这些变种形式的任一种。<br>这一般说来不是一个严重的问题，因为这些类型的主要益处得自于明显地控制精度和规模的<br>能力。<br>DECIMAL 和 NUMERIC 值作为字符串存储，而不是作为二进制浮点数，以便保存那些值<br>的小数精度。<br>一个字符用于值的每一位、小数点(如果 scale&gt;0)和“-”符号(对于负值)。如果 scale 是 0，<br>DECIMAL 和 NUMERIC 值不包含小数点或小数部分。<br>DECIMAL 和 NUMERIC 值得最大的范围与 DOUBLE 一样，但是对于一个给定的<br>DECIMAL 或 NUMERIC 列，实际的范围可由制由给定列的 precision 或 scale 限制。<br>当这样的列赋给了小数点后面的位超过指定 scale 所允许的位的值，该值根据 scale 四舍五<br>入。<br>当一个 DECIMAL 或 NUMERIC 列被赋给了其大小超过指定(或缺省的）precision 和 scale<br>隐含的范围的值，Mysql 存储表示那个范围的相应的端点值。<br>53、MYSQL 数据表在什么情况下容易损坏？<br>服务器突然断电导致数据文件损坏。<br>强制关机，没有先关闭 mysql 服务等。<br>54、mysql 有关权限的表都有哪几个？<br>Mysql 服务器通过权限表来控制用户对数据库的访问，权限表存放在 mysql 数据库里，由<br>mysql_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv<br>和 host。<br>55、Mysql 中有哪几种锁？<br>MyISAM 支持表锁，InnoDB 支持表锁和行锁，默认为行锁<br>表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最<br>低<br>行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高</p><p>1.数据库三范式是什么?<br>1.第一范式（1NF）：字段具有原子性,不可再分。(所有关系型数据库系统都满足第一范式数据库表中的字段都是单一属性的，不可再分)<br>2.第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。要求数据库表中的每个实例或行必须可以被惟一地区分。通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主关键字或主键。<br>3.满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。 &gt;所以第三范式具有如下特征： &gt;&gt;1. 每一列只有一个值 &gt;&gt;2. 每一行都能区分。 &gt;&gt;3. 每一个表都不包含其他表已经包含的非主关键字信息。<br>2.有哪些数据库优化方面的经验?<br>1.用PreparedStatement， 一般来说比Statement性能高：一个sql 发给服务器去执行，涉及步骤：语法检查、语义分析， 编译，缓存。<br>2.有外键约束会影响插入和删除性能，如果程序能够保证数据的完整性，那在设计数据库时就去掉外键。<br>3.表中允许适当冗余，譬如，主题帖的回复数量和最后回复时间等<br>4.UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复数据且不需要排序时的话，那么就使用UNION ALL。 &gt;&gt;UNION和UNION ALL关键字都是将两个结果集合并为一个，但这两者从使用和效率上来说都有所不同。 &gt;1. 对重复结果的处理：UNION在进行表链接后会筛选掉重复的记录，Union All不会去除重复记录。 &gt;2. 对排序的处理：Union将会按照字段的顺序进行排序；UNION ALL只是简单的将两个结果合并后就返回。<br>3.请简述常用的索引有哪些种类?<br>1.普通索引: 即针对数据库表创建索引<br>2.唯一索引: 与普通索引类似，不同的就是：MySQL数据库索引列的值必须唯一，但允许有空值<br>3.主键索引: 它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引<br>4.组合索引: 为了进一步榨取MySQL的效率，就要考虑建立组合索引。即将数据库表中的多个字段联合起来作为一个组合索引。<br>4.以及在mysql数据库中索引的工作机制是什么？<br>数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树<br>5.MySQL的基础操作命令:<br>1.MySQL 是否处于运行状态:Debian 上运行命令 service mysql status，在RedHat 上运行命令 service mysqld status<br>2.开启或停止 MySQL 服务 :运行命令 service mysqld start 开启服务；运行命令 service mysqld stop 停止服务<br>3.Shell 登入 MySQL: 运行命令 mysql -u root -p<br>4.列出所有数据库:运行命令 show databases;<br>5.切换到某个数据库并在上面工作:运行命令 use databasename; 进入名为 databasename 的数据库<br>6.列出某个数据库内所有表: show tables;<br>7.获取表内所有 Field 对象的名称和类型 :describe table_name;<br>6.mysql的复制原理以及流程。<br>Mysql内建的复制功能是构建大型，高性能应用程序的基础。将Mysql的数据分布到多个系统上去，这种分布的机制，是通过将Mysql的某一台主机的数据复制到其它主机（slaves）上，并重新执行一遍来实现的。 * 复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。 当一个从服务器连接主服务器时，它通知主服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知新的更新。 过程如下 1. 主服务器把更新记录到二进制日志文件中。 2. 从服务器把主服务器的二进制日志拷贝到自己的中继日志（replay log）中。 3. 从服务器重做中继日志中的时间，把更新应用到自己的数据库上。<br>7.mysql支持的复制类型?<br>1.基于语句的复制： 在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。 一旦发现没法精确复制时，会自动选着基于行的复制。<br>2.基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍. 从mysql5.0开始支持<br>3.混合类型的复制: 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。<br>8.mysql中myisam与innodb的区别？<br>1.事务支持 &gt; MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。 &gt; InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。<br>2.InnoDB支持行级锁，而MyISAM支持表级锁. &gt;&gt; 用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。<br>3.InnoDB支持MVCC, 而MyISAM不支持<br>4.InnoDB支持外键，而MyISAM不支持<br>5.表主键 &gt; MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。 &gt; InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。<br>6.InnoDB不支持全文索引，而MyISAM支持。<br>7.可移植性、备份及恢复 &gt; MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。 &gt; InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了<br>8.存储结构 &gt; MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。 &gt; InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。<br>9.mysql中varchar与char的区别以及varchar(50)中的50代表的涵义？<br>1.varchar与char的区别: char是一种固定长度的类型，varchar则是一种可变长度的类型.<br>2.varchar(50)中50的涵义 : 最多存放50个字节<br>3.int（20）中20的涵义: int(M)中的M indicates the maximum display width (最大显示宽度)for integer types. The maximum legal display width is 255.<br>10.MySQL中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？<br>1.Read Uncommitted（读取未提交内容） &gt;&gt; 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。<br>2.Read Committed（读取提交内容） &gt;&gt; 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。<br>3.Repeatable Read（可重读） &gt;&gt; 这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读（Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control 间隙锁）机制解决了该问题。注：其实多版本只是解决不可重复读问题，而加上间隙锁（也就是它这里所谓的并发控制）才解决了幻读问题。<br>4.Serializable（可串行化） &gt;&gt; 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。<table><thead><tr><th align="left">隔离级别</th><th align="left">脏读（Dirty Read）</th><th align="left">不可重复读（NonRepeatable Read）</th><th align="left">幻读（Phantom Read）</th></tr></thead><tbody><tr><td align="left">未提交读（Read uncommitted）</td><td align="left">可能</td><td align="left">可能</td><td align="left">可能</td></tr><tr><td align="left">已提交读（Read committed）</td><td align="left">不可能</td><td align="left">可能</td><td align="left">可能</td></tr><tr><td align="left">可重复读（Repeatable read）</td><td align="left">不可能</td><td align="left">不可能</td><td align="left">可能</td></tr><tr><td align="left">可串行化（SERIALIZABLE）</td><td align="left">不可能</td><td align="left">不可能</td><td align="left">不可能</td></tr></tbody></table><br>11.表中有大字段X（例如：text类型），且字段X不会经常更新，以读为为主，将该字段拆成子表好处是什么？<br>如果字段里面有大字段（text,blob)类型的，而且这些字段的访问并不多，这时候放在一起就变成缺点了。 MYSQL数据库的记录存储是按行存储的，数据块大小又是固定的（16K），每条记录越小，相同的块存储的记录就越多。此时应该把大字段拆走，这样应付大部分小字段的查询时，就能提高效率。当需要查询大字段时，此时的关联查询是不可避免的，但也是值得的。拆分开后，对字段的UPDAE就要UPDATE多个表了<br>12.MySQL中InnoDB引擎的行锁是通过加在什么上完成（或称实现）的？<br>InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！<br>13.MySQL中控制内存分配的全局参数，有哪些？<br>1.Keybuffersize： &gt; * keybuffersize指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。通过检查状态值Keyreadrequests和Keyreads，可以知道keybuffersize设置是否合理。比例keyreads /keyreadrequests应该尽可能的低，至少是1:100，1:1000更好（上述状态值可以使用SHOW STATUS LIKE ‘keyread%’获得）。 &gt; * keybuffersize只对MyISAM表起作用。即使你不使用MyISAM表，但是内部的临时磁盘表是MyISAM表，也要使用该值。可以使用检查状态值createdtmpdisktables得知详情。对于1G内存的机器，如果不使用MyISAM表，推荐值是16M（8-64M） &gt; * keybuffersize设置注意事项 &gt;&gt;&gt;1. 单个keybuffer的大小不能超过4G，如果设置超过4G，就有可能遇到下面3个bug: &gt;&gt;&gt;&gt;&gt; <a target="_blank" rel="noopener" href="http://bugs.mysql.com/bug.php?id=29446">http://bugs.mysql.com/bug.php?id=29446</a><br>&gt;&gt;&gt;&gt;&gt; <a target="_blank" rel="noopener" href="http://bugs.mysql.com/bug.php?id=29419">http://bugs.mysql.com/bug.php?id=29419</a><br>&gt;&gt;&gt;&gt;&gt; <a target="_blank" rel="noopener" href="http://bugs.mysql.com/bug.php?id=5731">http://bugs.mysql.com/bug.php?id=5731</a><br>&gt;&gt;&gt;2. 建议keybuffer设置为物理内存的1/4(针对MyISAM引擎)，甚至是物理内存的30%~40%，如果keybuffersize设置太大，系统就会频繁的换页，降低系统性能。因为MySQL使用操作系统的缓存来缓存数据，所以我们得为系统留够足够的内存；在很多情况下数据要比索引大得多。 &gt;&gt;&gt;3. 如果机器性能优越，可以设置多个keybuffer,分别让不同的keybuffer来缓存专门的索引<br>2.innodbbufferpool_size &gt; 表示缓冲池字节大小，InnoDB缓存表和索引数据的内存区域。mysql默认的值是128M。最大值与你的CPU体系结构有关，在32位操作系统，最大值是 4294967295 (2^32-1) ，在64 位操作系统，最大值为18446744073709551615 (2^64-1)。 &gt; 在32位操作系统中，CPU和操作系统实用的最大大小低于设置的最大值。如果设定的缓冲池的大小大于1G，设置innodbbufferpoolinstances的值大于1. &gt; * 数据读写在内存中非常快, innodbbufferpoolsize 减少了对磁盘的读写。 当数据提交或满足检查点条件后才一次性将内存数据刷新到磁盘中。然而内存还有操作系统或数据库其他进程使用, 一般设置 buffer pool 大小为总内存的 3/4 至 4/5。 若设置不当, 内存使用可能浪费或者使用过多。 对于繁忙的服务器, buffer pool 将划分为多个实例以提高系统并发性, 减少线程间读写缓存的争用。buffer pool 的大小首先受 innodbbufferpool_instances 影响, 当然影响较小。<br>3.querycachesize &gt; 当mysql接收到一条select类型的query时，mysql会对这条query进行hash计算而得到一个hash值，然后通过该hash值到query cache中去匹配，如果没有匹配中，则将这个hash值存放在一个hash链表中，同时将query的结果集存放进cache中，存放hash值的链表的每一个hash节点存放了相应query结果集在cache中的地址，以及该query所涉及到的一些table的相关信息；如果通过hash值匹配到了一样的query，则直接将cache中相应的query结果集返回给客户端。如果mysql任何一个表中的任何一条数据发生了变化，便会通知query cache需要与该table相关的query的cache全部失效，并释放占用的内存地址。 &gt; query cache优缺点 &gt;&gt; 1. query语句的hash计算和hash查找带来的资源消耗。mysql会对每条接收到的select类型的query进行hash计算然后查找该query的cache是否存在，虽然hash计算和查找的效率已经足够高了，一条query所带来的消耗可以忽略，但一旦涉及到高并发，有成千上万条query时，hash计算和查找所带来的开销就的重视了； &gt;&gt; 2. query cache的失效问题。如果表变更比较频繁，则会造成query cache的失效率非常高。表变更不仅仅指表中的数据发生变化，还包括结构或者索引的任何变化； &gt;&gt; 3. 对于不同sql但同一结果集的query都会被缓存，这样便会造成内存资源的过渡消耗。sql的字符大小写、空格或者注释的不同，缓存都是认为是不同的sql（因为他们的hash值会不同）； &gt;&gt; 4. 相关参数设置不合理会造成大量内存碎片，相关的参数设置会稍后介绍。<br>4.readbuffersize &gt;是MySQL读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL会为它分配一段内存缓冲区。readbuffersize变量控制这一缓冲区的大小。如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能。<br>14.若一张表中只有一个字段VARCHAR(N)类型，utf8编码，则N最大值为多少(精确到数量级即可)?<br>由于utf8的每个字符最多占用3个字节。而MySQL定义行的长度不能超过65535，因此N的最大值计算方法为：(65535-1-2)/3。减去1的原因是实际存储从第二个字节开始，减去2的原因是因为要在列表长度存储实际的字符长度，除以3是因为utf8限制：每个字符最多占用3个字节。<br>15. [SELECT *] 和[SELECT 全部字段]的2种写法有何优缺点?<br>1.前者要解析数据字典，后者不需要<br>2.结果输出顺序，前者与建表列顺序相同，后者按指定字段顺序。<br>3.表字段改名，前者不需要修改，后者需要改<br>4.后者可以建立索引进行优化，前者无法优化<br>5.后者的可读性比前者要高<br>16.HAVNG 子句 和 WHERE的异同点?<br>1.语法上：where 用表中列名，having用select结果别名<br>2.影响结果范围：where从表读出数据的行数，having返回客户端的行数<br>3.索引：where 可以使用索引，having不能使用索引，只能在临时结果集操作<br>4.where后面不能使用聚集函数，having是专门使用聚集函数的。<br>17.MySQL当记录不存在时insert,当记录存在时update，语句怎么写？<br>INSERT INTO table (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=c+1;<br>18.MySQL的insert和update的select语句语法<br><code>SQL insert into student (stuid,stuname,deptid) select 10,&#39;xzm&#39;,3 from student where stuid &gt; 8; update student a inner join student b on b.stuID=10 set a.stuname=concat(b.stuname, b.stuID) where a.stuID=10 ; </code></p><p>1、一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，<br>再把 Mysql 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15 ？<br>(1)如果表的类型是 MyISAM，那么是 18<br>因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里，重启 MySQL 自增主键的最大<br>ID 也不会丢失<br>（2）如果表的类型是 InnoDB，那么是 15<br>InnoDB 表只是把自增主键的最大 ID 记录到内存中，所以重启数据库或者是对表进行<br>OPTIMIZE 操作，都会导致最大 ID 丢失<br>2、Mysql 的技术特点是什么？<br>Mysql 数据库软件是一个客户端或服务器系统，其中包括：支持各种客户端程序和库的多<br>线程 SQL 服务器、不同的后端、广泛的应用程序编程接口和管理工具。<br>3、Heap 表是什么？<br>HEAP 表存在于内存中，用于临时高速存储。<br>BLOB 或 TEXT 字段是不允许的<br>只能使用比较运算符=，&lt;，&gt;，=&gt;，= &lt;<br>HEAP 表不支持 AUTO_INCREMENT<br>索引不可为 NULL<br>4、Mysql 服务器默认端口是什么？<br>Mysql 服务器的默认端口是 3306。<br>5、与 Oracle 相比，Mysql 有什么优势？<br>Mysql 是开源软件，随时可用，无需付费。<br>Mysql 是便携式的<br>带有命令提示符的 GUI。<br>使用 Mysql 查询浏览器支持管理<br>6、如何区分 FLOAT 和 DOUBLE？<br>以下是 FLOAT 和 DOUBLE 的区别：<br>浮点数以 8 位精度存储在 FLOAT 中，并且有四个字节。<br>浮点数存储在 DOUBLE 中，精度为 18 位，有八个字节。<br>7、区分 CHAR_LENGTH 和 LENGTH？<br>CHAR_LENGTH 是字符数，而 LENGTH 是字节数。Latin 字符的这两个数据是相同的，但是对<br>于 Unicode 和其他编码，它们是不同的。<br>8、请简洁描述 Mysql 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？<br>SQL 标准定义的四个隔离级别为：<br>read uncommited ：读到未提交数据<br>read committed：脏读，不可重复读<br>repeatable read：可重读<br>serializable ：串行事物<br>9、在 Mysql 中 ENUM 的用法是什么？<br>ENUM 是一个字符串对象，用于指定一组预定义的值，并可在创建表时使用。<br>Create table size(name ENUM(‘Smail,’Medium’,’Large’);<br>10、如何定义 REGEXP？<br>REGEXP 是模式匹配，其中匹配模式在搜索值的任何位置。<br>11、CHAR 和 VARCHAR 的区别？<br>以下是 CHAR 和 VARCHAR 的区别：<br>CHAR 和 VARCHAR 类型在存储和检索方面有所不同<br>CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255<br>当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。<br>12、列的字符串类型可以是什么？<br>字符串类型是：<br>SET<br>BLOB<br>ENUM<br>CHAR<br>TEXT<br>VARCHAR<br>13、如何获取当前的 Mysql 版本？<br>SELECT VERSION();用于获取当前 Mysql 的版本。<br>14、Mysql 中使用什么存储引擎？<br>存储引擎称为表类型，数据使用各种技术存储在文件中。<br>技术涉及：<br>Storage mechanism<br>Locking levels<br>Indexing<br>Capabilities and functions.<br>15、Mysql 驱动程序是什么？<br>以下是 Mysql 中可用的驱动程序：<br>PHP 驱动程序<br>JDBC 驱动程序<br>ODBC 驱动程序<br>CWRAPPER PYTHON<br>驱动程序 PERL 驱动<br>程序 RUBY 驱动程<br>序 CAP11PHP 驱动<br>程序<br>Ado.net5.mxj<br>16、TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据类型上做什么？<br>创建表时 TIMESTAMP 列用 Zero 更新。只要表中的其他字段发生更改，UPDATE<br>CURRENT_TIMESTAMP 修饰符就将时间戳字段更新为当前时间。<br>17、主键和候选键有什么区别？<br>表格的每一行都由主键唯一标识,一个表只有一个主键。<br>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。<br>18、如何使用 Unix shell 登录 Mysql？<br>我们可以通过以下命令登录：<br>[mysql dir]/bin/mysql -h hostname -u<br>19、 myisamchk 是用来做什么的？<br>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。<br>20、MYSQL 数据库服务器性能分析的方法命令有哪些?<br>21、如何控制 HEAP 表的最大尺寸？<br>Heal 表的大小可通过称为 max_heap_table_size 的 Mysql 配置变量来控制。<br>22、MyISAM Static 和 MyISAM Dynamic 有什么区别？<br>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB 等字<br>段，以适应不同长度的数据类型。点击这里有一套最全阿里面试题总结。<br>MyISAM Static 在受损情况下更容易恢复。<br>23、federated 表是什么？<br>federated 表，允许访问位于其他服务器数据库上的表。<br>24、如果一个表有一列定义为 TIMESTAMP，将发生什么？<br>每当行被更改时，时间戳字段将获取当前时间戳。<br>25、列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？<br>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。<br>26、怎样才能找出最后一次插入时分配了哪个自动增量？<br>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。<br>27、你怎么看到为表格定义的所有索引？<br>索引是通过以下方式为表格定义的：<br>SHOW INDEX FROM<br>28.、LIKE 声明中的％和_是什么意思？<br>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。<br>29、如何在 Unix 和 Mysql 时间戳之间进行转换？<br>UNIX_TIMESTAMP 是从 Mysql 时间戳转换为 Unix 时间戳的命令<br>FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql 时间戳的命令<br>30、列对比运算符是什么？<br>在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或 LIKE 运<br>算符。<br>31、我们如何得到受查询影响的行数？<br>行数可以通过以下代码获得：<br>SELECT COUNT(user_id)FROM users;<br>32、Mysql 查询是否区分大小写？<br>不区分<br>SELECT VERSION(), CURRENT_DATE;<br>SeLect version(), current_date;<br>seleCt vErSiOn(), current_DATE;<br>所有这些例子都是一样的，Mysql 不区分大小写。<br>33.、LIKE 和 REGEXP 操作有什么区别？<br>LIKE 和 REGEXP 运算符用于表示^和％。<br>SELECT * FROM employee WHERE emp_name REGEXP “^b”;<br>SELECT * FROM employee WHERE emp_name LIKE “%b”;<br>34.、BLOB 和 TEXT 有什么区别？<br>BLOB 是一个二进制对象，可以容纳可变数量的数据。有四种类型的 BLOB -<br>TINYBLOB<br>BLOB<br>MEDIUMBLOB 和 LONGBLOB 它们只能在所能容纳<br>价值的最大长度上有所不同。<br>TEXT 是一个不区分大小写的 BLOB。四种 TEXT 类型<br>TINYTEXT<br>TEXT<br>MEDIUMTEXT 和<br>LONGTEXT<br>它们对应于四种 BLOB 类型，并具有相同的最大长度和存储要求。<br>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT<br>值不区分大小写。<br>35、mysql_fetch_array 和 mysql_fetch_object 的区别是什么？<br>以下是 mysql_fetch_array 和 mysql_fetch_object 的区别：<br>mysql_fetch_array（） - 将结果行作为关联数组或来自数据库的常规数组返回。<br>mysql_fetch_object - 从数据库返回结果行作为对象。<br>36、我们如何在 mysql 中运行批处理模式？<br>以下命令用于在批处理模式下运行：<br>mysql;<br>mysql mysql.out<br>37、MyISAM 表格将在哪里存储，并且还提供其存储格式？<br>每个 MyISAM 表格以三种格式存储在磁盘上：<br>·“.frm”文件存储表定义<br>·数据文件具有“.MYD”（MYData）扩展名<br>索引文件具有“.MYI”（MYIndex）扩展名<br>38.、Mysql 中有哪些不同的表格？<br>共有 5 种类型的表格：<br>MyISAM<br>Heap<br>Merge<br>INNODB<br>ISAM<br>MyISAM 是 Mysql 的默认存储引擎。<br>39、ISAM 是什么？<br>ISAM 简称为索引顺序访问方法。它是由 IBM 开发的，用于在磁带等辅助存储系统上存储和<br>检索数据。<br>40、InnoDB 是什么？<br>lnnoDB 是一个由 Oracle 公司开发的 Innobase Oy 事务安全存储引擎。<br>41、Mysql 如何优化 DISTINCT？<br>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。<br>1<br>SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;<br>42、如何输入字符为十六进制数字？<br>如果想输入字符为十六进制数字，可以输入带有单引号的十六进制数字和前缀（X），或者<br>只用（Ox）前缀输入十六进制数字。<br>如果表达式上下文是字符串，则十六进制数字串将自动转换为字符串。<br>43、如何显示前 50 行？<br>在 Mysql 中，使用以下代码查询显示前 50 行：<br>SELECT*FROM<br>LIMIT 0,50;<br>44、可以使用多少列创建索引？<br>任何标准表最多可以创建 16 个索引列。<br>45、NOW（）和 CURRENT_DATE（）有什么区别？<br>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。<br>CURRENT_DATE（）仅显示当前年份，月份和日期。<br>46、什么样的对象可以使用 CREATE 语句创建？<br>以下对象是使用 CREATE 语句创建的：<br>DATABASE<br>EVENT<br>FUNCTION<br>INDEX<br>PROCEDURE<br>TABLE<br>TRIGGER<br>USER<br>VIEW<br>47、Mysql 表中允许有多少个 TRIGGERS？<br>在 Mysql 表中允许有六个触发器，如下：<br>BEFORE INSERT<br>AFTER INSERT<br>BEFORE UPDATE<br>AFTER UPDATE<br>BEFORE DELETE<br>AFTER DELETE<br>48、什么是非标准字符串类型？<br>以下是非标准字符串类型：<br>TINYTEXT<br>TEXT<br>MEDIUMTEXT<br>LONGTEXT<br>49、什么是通用 SQL 函数？<br>CONCAT(A, B) - 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合<br>并为一个字段。<br>FORMAT(X, D)- 格式化数字 X 到 D 有效数字。<br>CURRDATE(), CURRTIME()- 返回当前日期或时间。<br>NOW（） - 将当前日期和时间作为一个值返回。<br>MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） - 从日期值中提取给定数据。<br>HOUR（），MINUTE（），SECOND（） - 从时间值中提取给定数据。<br>DATEDIFF（A，B） - 确定两个日期之间的差异，通常用于计算年龄<br>SUBTIMES（A，B） - 确定两次之间的差异。<br>FROMDAYS（INT） - 将整数天数转换为日期值。<br>50、解释访问控制列表<br>ACL（访问控制列表）是与对象关联的权限列表。这个列表是 Mysql 服务器安全模型的基<br>础，它有助于排除用户无法连接的问题。<br>Mysql 将 ACL（也称为授权表）缓存在内存中。当用户尝试认证或运行命令时，Mysql 会按<br>照预定的顺序检查 ACL 的认证信息和权限。<br>51、MYSQL 支持事务吗？<br>在缺省模式下，MYSQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，所<br>以在缺省情况下，mysql 是不支持事务的。<br>但是如果你的 MYSQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的 MYSQL 就可以<br>使用事务处理,使用 SET AUTOCOMMIT=0 就可以使 MYSQL 允许在非 autocommit 模式，在非<br>autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK 来回滚你的<br>更改。<br>示例如下：<br>一<br>START TRANSACTION;<br>SELECT @A:=SUM(salary) FROM table1 WHERE type=1;<br>UPDATE table2 SET summmary=@A WHERE type=1;<br>COMMIT;<br>52、mysql 里记录货币用什么字段类型好<br>NUMERIC 和 DECIMAL 类型被 Mysql 实现为同样的类型，这在 SQL92 标准允许。他们被用于<br>保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些<br>类型之一时，精度和规模的能被(并且通常是)指定；点击这里有一套最全阿里面试题总<br>结。<br>例如：<br>salary DECIMAL(9,2)<br>在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代表将被用于<br>存储小数点后的位数。<br>因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到 9999999.99。<br>在 ANSI/ISO SQL92 中，句法 DECIMAL(p)等价于 DECIMAL(p,0)。<br>同样，句法 DECIMAL 等价于 DECIMAL(p,0)，这里实现被允许决定值 p。Mysql 当前不支持<br>DECIMAL/NUMERIC 数据类型的这些变种形式的任一种。<br>这一般说来不是一个严重的问题，因为这些类型的主要益处得自于明显地控制精度和规模<br>的能力。<br>DECIMAL 和 NUMERIC 值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小<br>数精度。<br>一个字符用于值的每一位、小数点(如果 scale&gt;0)和“-”符号(对于负值)。如果 scale 是 0，<br>DECIMAL 和 NUMERIC 值不包含小数点或小数部分。<br>DECIMAL 和 NUMERIC 值得最大的范围与 DOUBLE 一样，但是对于一个给定的 DECIMAL 或<br>NUMERIC 列，实际的范围可由制由给定列的 precision 或 scale 限制。<br>当这样的列赋给了小数点后面的位超过指定 scale 所允许的位的值，该值根据 scale 四舍五<br>入。<br>当一个 DECIMAL 或 NUMERIC 列被赋给了其大小超过指定(或缺省的）precision 和 scale 隐含<br>的范围的值，Mysql 存储表示那个范围的相应的端点值。<br>我希望本文可以帮助你提升技术水平。那些，感觉学的好难，甚至会令你沮丧的人，别担<br>心，我认为，如果你愿意试一试本文介绍的几点，会向前迈进，克服这种感觉。这些要点<br>也许对你不适用，但你会明确一个重要的道理：接受自己觉得受困这个事实是摆脱这个困<br>境的第一步。<br>53、MYSQL 数据表在什么情况下容易损坏？<br>服务器突然断电导致数据文件损坏。<br>强制关机，没有先关闭 mysql 服务等。<br>54、mysql 有关权限的表都有哪几个？<br>Mysql 服务器通过权限表来控制用户对数据库的访问，权限表存放在 mysql 数据库里，由<br>mysql_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv 和<br>host。<br>55、Mysql 中有哪几种锁？<br>MyISAM 支持表锁，InnoDB 支持表锁和行锁，默认为行锁<br>表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量<br>最低<br>行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高<br>最后，欢迎做 Java 的工程师朋友们加入 Java 高级架构进阶 Qqun：963944895<br>群内有技术大咖指点难题，还提供免费的 Java 架构学习资料（里面有高可用、高并发、高性能及分布式、<br>Jvm 性能调优、Spring 源码，MyBatis，Netty,Redis,Kafka,Mysql,Zookeeper,Tomcat,Docker,Dubbo,Nginx 等多个<br>知识点的架构资料）<br>比你优秀的对手在学习，你的仇人在磨刀，你的闺蜜在减肥，隔壁老王在练腰， 我们必须不断学习，否则我<br>们将被学习者超越！<br>趁年轻，使劲拼，给未来的自己一个交代！</p><p>&lt;最全 MySQL 面试 50 题和答案&gt;<br>Mysql 中有哪几种锁？<br>1.表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率<br>最高，并发度最低。<br>2.行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，<br>并发度也最高。<br>3. 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和<br>行锁之间，并发度一般。<br>Mysql 中有哪些不同的表格？<br>共有 5 种类型的表格：<br>. MyISAM<br>. Heap<br>. Merge<br>. INNODB<br>. ISAM<br>简述在 MySQL 数据库中 MyISAM 和 InnoDB 的区别<br>MyISAM：<br>不支持事务，但是每次查询都是原子的；<br>支持表级锁，即每次操作是对整个表加锁；<br>存储表的总行数；<br>一个 MYISAM 表有三个文件：索引文件、表结构文件、数据文件；<br>采用菲聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本<br>一致，但是辅索引不用保证唯一性。<br>InnoDb：<br>支持 ACID 的事务，支持事务的四种隔离级别；<br>支持行级锁及外键约束：因此可以支持写并发；<br>不存储总行数；<br>一个 InnoDb 引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一<br>个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系<br>统文件大小限制，一般为 2G），受操作系统文件大小的限制；<br>主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主<br>键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最<br>好使用自增主键，防止插入数据时，为维持 B+树结构，文件的大调整。<br>Mysql 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？<br>SQL 标准定义的四个隔离级别为：<br>. read uncommited ：读到未提交数据<br>. read committed：脏读，不可重复读<br>. repeatable read：可重读<br>. serializable ：串行事物<br>CHAR 和 VARCHAR 的区别？<br>1.CHAR 和 VARCHAR 类型在存储和检索方面有所不同<br>2.CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255<br>当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除<br>尾随空格。<br>主键和候选键有什么区别？<br>表格的每一行都由主键唯一标识,一个表只有一个主键。<br>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外<br>键引用。<br>myisamchk 是用来做什么的？<br>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。<br>MyISAM Static 和 MyISAM Dynamic 有什么区别？<br>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像<br>TEXT，BLOB 等字段，以适应不同长度的数据类型。<br>MyISAM Static 在受损情况下更容易恢复。<br>如果一个表有一列定义为 TIMESTAMP，将发生什么？<br>每当行被更改时，时间戳字段将获取当前时间戳。<br>列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？<br>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。<br>怎样才能找出最后一次插入时分配了哪个自动增量？<br>（1）Where 子句中：where 表之间的连接必须写在其他 Where 条件之前，那<br>些可以过滤掉最大数量记录的条件必须写在 Where 子句的末尾.HAVING 最后。<br>（2）用 EXISTS 替代 IN、用 NOT EXISTS 替代 NOT IN。<br>（3） 避免在索引列上使用计算<br>（4）避免在索引列上使用 IS NULL 和 IS NOT NULL<br>（5）对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order<br>by 涉及的列上建立索引。<br>（6）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放<br>弃使用索引而进行全表扫描<br>（7）应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃<br>使用索引而进行全表扫描</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/554d7a59d68c.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/554d7a59d68c.html" class="post-title-link" itemprop="url">Zookeeper</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:19:03 / 修改时间：16:20:30" itemprop="dateCreated datePublished" datetime="2023-12-20T16:19:03+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="zookeeper-都有哪些使用场景？"><a href="#zookeeper-都有哪些使用场景？" class="headerlink" title="zookeeper 都有哪些使用场景？"></a>zookeeper 都有哪些使用场景？</h1><p>面试官心理分析<br>现在聊的 topic 是分布式系统，面试官跟你聊完了 dubbo 相关的一些问题之后，已经确认你对分布式服务框架/RPC框架基本都有一些认知了。那么他可能开始要跟你聊分布式相关的其它问题了。<br>分布式锁这个东西，很常用的，你做 Java 系统开发，分布式系统，可能会有一些场景会用到。最常用的分布式锁就是基于 zookeeper 来实现的。<br>其实说实话，问这个问题，一般就是看看你是否了解 zookeeper，因为 zookeeper 是分布式系统中很常见的一个基础系统。而且问的话常问的就是说 zookeeper 的使用场景是什么？看你知道不知道一些基本的使用场景。但是其实 zookeeper 挖深了自然是可以问的很深很深的。<br>面试题剖析<br>大致来说，zookeeper 的使用场景如下，我就举几个简单的，大家能说几个就好了：<br>分布式协调<br>分布式锁<br>元数据/配置信息管理<br>HA高可用性</p><h4 id="分布式协调"><a href="#分布式协调" class="headerlink" title="分布式协调"></a>分布式协调</h4><p>这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值注册个监听器，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。<br>s</p><h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也尝试去创建那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</p><h4 id="元数据-配置信息管理"><a href="#元数据-配置信息管理" class="headerlink" title="元数据/配置信息管理"></a>元数据/配置信息管理</h4><p>zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？</p><h4 id="HA高可用性"><a href="#HA高可用性" class="headerlink" title="HA高可用性"></a>HA高可用性</h4><p>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个重要进程一般会做主备两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。</p><h1 id="什么是-ZooKeeper"><a href="#什么是-ZooKeeper" class="headerlink" title="什么是 ZooKeeper"></a>什么是 ZooKeeper</h1><p>ZooKeeper 的由来<br>下面这段内容摘自《从Paxos到Zookeeper 》第四章第一节的某段内容，推荐大家阅读以下：<br>Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。<br>关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好要用来进行分布式环境的协调一一于是，Zookeeper的名字也就由此诞生了。<br>1.1 ZooKeeper 概览<br>ZooKeeper 是一个开源的分布式协调服务，ZooKeeper框架最初是在“Yahoo!”上构建的，用于以简单而稳健的方式访问他们的应用程序。 后来，Apache ZooKeeper成为Hadoop，HBase和其他分布式框架使用的有组织服务的标准。 例如，Apache HBase使用ZooKeeper跟踪分布式数据的状态。ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。<br>原语： 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。<br>ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。<br>Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心。 服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。如下图所示，在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。</p><p>1.2 结合个人使用情况的讲一下 ZooKeeper<br>在我自己做过的项目中，主要使用到了 ZooKeeper 作为 Dubbo 的注册中心(Dubbo 官方推荐使用 ZooKeeper注册中心)。另外在搭建 solr 集群的时候，我使用 ZooKeeper 作为 solr 集群的管理工具。这时，ZooKeeper 主要提供下面几个功能：1、集群管理：容错、负载均衡。2、配置文件的集中管理3、集群的入口。<br>我个人觉得在使用 ZooKeeper 的时候，最好是使用 集群版的 ZooKeeper 而不是单机版的。官网给出的架构图就描述的是一个集群版的 ZooKeeper 。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。<br>为什么最好使用奇数台服务器构成 ZooKeeper 集群？<br>我们知道在Zookeeper中 Leader 选举算法采用了Zab协议。Zab核心思想是当多数 Server 写成功，则任务数据写成功。<br>①如果有3个Server，则最多允许1个Server 挂掉。<br>②如果有4个Server，则同样最多允许1个Server挂掉。<br>既然3个或者4个Server，同样最多允许1个Server挂掉，那么它们的可靠性是一样的，所以选择奇数个ZooKeeper Server即可，这里选择3个Server。12341234<br>二 关于 ZooKeeper 的一些重要概念<br>2.1 重要概念总结<br>● ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。<br>● 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。<br>● ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。<br>● ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）<br>● ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。<br>● ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提交数据节点监听服务。<br>下面关于会话（Session）、 Znode、版本、Watcher、ACL概念的总结都在《从Paxos到Zookeeper 》第四章第一节以及第七章第八节有提到，感兴趣的可以看看！<br>2.2 会话（Session）<br>Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。<br>在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。<br>2.3 Znode<br>在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。<br>Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。<br>在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。<br>2.4 版本<br>在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 cversion（当前ZNode的ACL版本）。<br>2.5 Watcher<br>Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。<br>2.6 ACL<br>Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限。</p><p>其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。<br>三 ZooKeeper 特点<br>● 顺序一致性： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。<br>● 原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。<br>● 单一系统映像 ： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。<br>● 可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。<br>四 ZooKeeper 设计目标<br>4.1 简单的数据模型<br>ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。</p><p>4.2 可构建集群<br>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。<br>ZooKeeper 官方提供的架构图：</p><p>上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。<br>4.3 顺序访问<br>对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）<br>4.4 高性能<br>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）<br>五 ZooKeeper 集群角色介绍<br>最典型集群模式： Master/Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。<br>但是，在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。如下图所示</p><p>ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，Follower 和 Observer 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。</p><p>六 ZooKeeper &amp;ZAB 协议&amp;Paxos算法<br>6.1 ZAB 协议&amp;Paxos算法<br>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。<br>6.2 ZAB 协议介绍<br>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。<br>6.3 ZAB 协议两种基本的模式：崩溃恢复和消息广播<br>ZAB协议包括两种基本的模式，分别是 崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。<br>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。<br>七 总结<br>通过阅读本文，想必大家已从 ①ZooKeeper的由来。 -&gt; ②ZooKeeper 到底是什么 。-&gt; ③ ZooKeeper 的一些重要概念（会话（Session）、 Znode、版本、Watcher、ACL）-&gt; ④ZooKeeper 的特点。 -&gt; ⑤ZooKeeper 的设计目标。-&gt; ⑥ ZooKeeper 集群角色介绍（Leader、Follower 和 Observer 三种角色）-&gt; ⑦ZooKeeper &amp;ZAB 协议&amp;Paxos算法。这七点了解了 ZooKeeper 。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/4f75e46c0d1c.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/4f75e46c0d1c.html" class="post-title-link" itemprop="url">设计模式</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:17:58 / 修改时间：16:18:19" itemprop="dateCreated datePublished" datetime="2023-12-20T16:17:58+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">设计模式</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>1、⼯⼚⽅法模式(利⽤创建同⼀接⼝的不同实例)：<br>1、普通⼯⼚模式：建⽴⼀个⼯⼚类，对实现了同⼀接⼝的⼀些类进⾏实例的创建；<br>1 public class SendFactory {<br>2<br>3 public Sender produce(String type) {<br>4 if (“mail”.equals(type)) {<br>5 return new MailSender();<br>6 } else if (“sms”.equals(type)) {<br>7 return new SmsSender();<br>8 } else {<br>9 System.out.println(“请输⼊正确的类型!”);<br>10 return null;<br>11 }<br>12 }<br>13 }<br>2、多个⼯⼚⽅法模式：提供多个⼯⼚⽅法，分别创建对象；<br>1 public class SendFactory {<br>2<br>3 public Sender produceMail(){<br>4 return new MailSender();<br>5 }<br>6<br>7 public Sender produceSms(){<br>8 return new SmsSender();<br>9 }<br>10 }<br>3、静态⼯⼚⽅法模式：将上⾯的多个⼯⼚⽅法置为静态的，不需要创建⼯⼚实例，直接调⽤即可；<br>4、适⽤场景：凡是出现了⼤量不同种类的产品需要创建，并且具有共同的接⼝时，可以通过⼯⼚⽅法模式进⾏创建。在以上的三种模式<br>中，第⼀种如果传⼊的字符串有误，不能正确创建对象，第三种相对于第⼆种，不需要实例化⼯⼚类，所以，⼤多数情况下，我们会选⽤第三种——静<br>态⼯⼚⽅法模式。<br>2、抽象⼯⼚模式(多个⼯⼚)：创建多个⼯⼚类，提⾼⼯⼚的扩展性，不⽤像上⾯⼀样如果增加产品则要去修改唯⼀的⼯⼚类；<br>3、单例模式(保证对象只有⼀个实例)：保证在⼀个JVM中，该对象只有⼀个实例存在；<br>1、适⽤场景：<br>1、某些类创建⽐较频繁，对于⼀些⼤型的对象，这是⼀笔很⼤的系统开销。<br>2、省去了new操作符，降低了系统内存的使⽤频率，减轻GC压⼒。<br>3、有些类如交易所的核⼼交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（⽐如⼀个军队出现了多个司<br>令员同时指挥，肯定会乱成⼀团），所以只有使⽤单例模式，才能保证核⼼交易服务器独⽴控制整个流程。<br>2、代码：<br>1 public class Singleton {<br>2<br>3 /* 持有私有静态实例，防⽌被引⽤，此处赋值为null，⽬的是实现延迟加载 <em>/<br>4 private static Singleton instance = null;<br>5<br>6 /</em> 私有构造⽅法，防⽌被实例化 <em>/<br>7 private Singleton() {<br>8 }<br>9<br>10 /</em> 静态⼯程⽅法，创建实例 <em>/<br>11 public static Singleton getInstance() {<br>12 if (instance == null) {<br>13 instance = new Singleton();<br>14 }<br>15 return instance;<br>16 }<br>17<br>18 /</em> 如果该对象被⽤于序列化，可以保证对象在序列化前后保持⼀致 */<br>19 public Object readResolve() {<br>20 return instance;<br>21 }<br>22 }<br>3、分类：<br>1、饿汉式：类初始化时创建单例，线程安全，适⽤于单例占内存⼩的场景，否则推荐使⽤懒汉式延迟加载；<br>1 public class Singleton{<br>2 private static Singleton instance = new Singleton();<br>3 private Singleton(){}<br>4 public static Singleton newInstance(){<br>5 return instance;<br>6 }<br>7 }<br>2、懒汉式：需要创建单例实例的时候再创建，需要考虑线程安全(性能不太好)：<br>1 public class Singleton{<br>2 private static Singleton instance = null;<br>3 private Singleton(){}<br>4 public static synchronized Singleton newInstance(){<br>5 if(null == instance){<br>6 instance = new Singleton();<br>7 }<br>8 return instance;<br>9 }<br>10 }<br>3、双重检验锁：效率⾼；(解决问题：假如两个线程A、B，A执⾏了if (instance == null)语句，它会认为单例对象没有创建，此时线程切到B也<br>执⾏了同样的语句，B也认为单例对象没有创建，然后两个线程依次执⾏同步代码块，并分别创建了⼀个单例对象。)<br>1 public class Singleton {<br>2 private static volatile Singleton instance = null;//volatile的⼀个语义是禁⽌指令重排序优化<br>3 private Singleton(){}<br>4 public static Singleton getInstance() {<br>5 if (instance == null) {<br>6 synchronized (Singleton.class) {<br>7 if (instance == null) {//2<br>8 instance = new Singleton();<br>9 }<br>10 }<br>11 }<br>12 return instance;<br>13 }<br>14 }<br>4、静态内部类⽅式：可以同时保证延迟加载和线程安全。<br>1 public class Singleton{<br>2 private static class SingletonHolder{<br>3 public static Singleton instance = new Singleton();<br>4 }<br>5 private Singleton(){}<br>6 public static Singleton newInstance(){<br>7 return SingletonHolder.instance;<br>8 }<br>9 }<br>5、枚举：使⽤枚举除了线程安全和防⽌反射调⽤构造器之外，还提供了⾃动序列化机制，防⽌反序列化的时候创建新的对象。<br>1 public enum Singleton{<br>2 instance;<br>3 public void whateverMethod(){}<br>4 }<br>4、原型模式(对⼀个原型对象进⾏复制、克隆产⽣类似新对象)：将⼀个对象作为原型，对其进⾏复制、克隆，产⽣⼀个和元对象类似的新对<br>象；<br>1、核⼼：它的核⼼是原型类Prototype，需要实现Cloneable接⼝，和重写Object类中的clone⽅法；<br>2、作⽤：使⽤原型模式创建对象⽐直接new⼀个对象在性能上要好的多，因为Object类的clone⽅法是⼀个本地⽅法，它直接操作内存<br>中的⼆进制流，特别是复制⼤对象时，性能的差别⾮常明显。<br>5、适配器模式(接⼝兼容)：将某个类的接⼝转换成客户端期望的另⼀个接⼝表示，⽬的是消除由于接⼝不匹配所造成的类的兼容性问题。<br>1、类的适配器模式：<br>2、对象的适配器模式：</p><p>3、接⼝的适配器模式：</p><p>4、使⽤场景：<br>1、类的适配器模式：当希望将⼀个类转换成满⾜另⼀个新接⼝的类时，可以使⽤类的适配器模式，创建⼀个新类，继承原有的类，<br>实现新的接⼝即可。<br>2、对象的适配器模式：当希望将⼀个对象转换成满⾜另⼀个新接⼝的对象时，可以创建⼀个Wrapper类，持有原类的⼀个实例，在<br>Wrapper类的⽅法中，调⽤实例的⽅法就⾏。<br>3、接⼝的适配器模式：当不希望实现⼀个接⼝中所有的⽅法时，可以创建⼀个抽象类Wrapper，实现所有⽅法，我们写别的类的时<br>候，继承抽象类即可。<br>6、装饰模式(给对象动态增加新功能，需持有对象实例)：装饰模式就是给⼀个对象增加⼀些新的功能，⽽且是动态的，要求装饰对象和被装<br>饰对象实现同⼀个接⼝，装饰对象持有被装饰对象的实例：<br>1、示例：</p><p>2、使⽤场景：<br>1、需要扩展⼀个类的功能。<br>2、动态的为⼀个对象增加功能，⽽且还能动态撤销。（继承不能做到这⼀点，继承的功能是静态的，不能动态增删。）<br>7、代理模式(持有被代理类的实例，进⾏操作前后控制)：采⽤⼀个代理类调⽤原有的⽅法，且对产⽣的结果进⾏控制。<br>8、外观模式(集合所有操作到⼀个类)：外观模式是为了解决类与类之间的依赖关系的，像spring⼀样，可以将类和类之间的关系配置到配置<br>⽂件中，⽽外观模式就是将他们的关系放在⼀个Facade类中，降低了类类之间的耦合度。</p><p>9、桥接模式(数据库驱动桥接)：桥接模式就是把事物和其具体实现分开，使他们可以各⾃独⽴的变化。桥接的⽤意是：将抽象化与实现化解<br>耦，使得⼆者可以独⽴变化，像我们常⽤的JDBC桥DriverManager⼀样，JDBC进⾏连接数据库的时候，在各个数据库之间进⾏切换，基本不需要<br>动太多的代码，甚⾄丝毫不⽤动，原因就是JDBC提供统⼀接⼝，每个数据库提供各⾃的实现，⽤⼀个叫做数据库驱动的程序来桥接就⾏了。<br>10、组合模式(部分整体模式)：组合模式有时⼜叫部分-整体模式在处理类似树形结构的问题时⽐较⽅便。<br>11、享元模式(共享池、数据库连接池)：享元模式的主要⽬的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，<br>通常与⼯⼚模式⼀起使⽤。当⼀个客户端请求时，⼯⼚需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，<br>则创建⼀个新对象，如数据库连接池；<br>12、策略模式(多种算法封装)：策略模式定义了⼀系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使⽤<br>算法的客户。需要设计⼀个接⼝，为⼀系列实现类提供统⼀的⽅法，多个实现类实现该接⼝：<br>1 ICalculator cal = new Plus(); //ICalculator是统⼀接⼝，Plus是实现类(多个)<br>2 int result = cal.calculate(exp); //jvm根据实现类不同⽽调⽤不同实现类的⽅法<br>13、模板⽅法模式(抽象⽅法作为⻣架，具体逻辑让⼦类实现)：定义⼀个操作中算法的框架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改<br>变算法的结构即可重定义该算法中的某些特定步骤。完成公共动作和特殊动作的分离。<br>1 //题⽬：排序并打印：<br>2 abstract class AbstractSort {<br>3 /**<br>4 * 将数组array由⼩到⼤排序<br>5 * @param array<br>6 */<br>7 protected abstract void sort(int[] array);<br>8<br>9 public void showSortResult(int[] array){<br>10 System.out.print(“排序结果：”);//打印<br>11 }<br>12 }<br>13 //排序<br>14 class ConcreteSort extends AbstractSort {<br>15<br>16 @Override<br>17 protected void sort(int[] array){<br>18 for(int i=0; i&lt;array.length-1; i++){<br>19 selectSort(array, i);<br>20 }<br>21 }<br>22<br>23 private void selectSort(int[] array, int index) {<br>24 //排序的实现逻辑<br>25 }<br>26 }<br>27 //测试<br>28 public class Client {<br>29 public static int[] a = { 10, 32, 1, 9, 5, 7, 12, 0, 4, 3 }; // 预设数据数组<br>30 public static void main(String[] args){<br>31 AbstractSort s = new ConcreteSort();<br>32 s.showSortResult(a);<br>33 }<br>34 }<br>14、观察者模式(发布-订阅模式)：当⼀个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是⼀种⼀对多的关<br>系。类似于邮件订阅和RSS订阅，当你订阅了该⽂章，如果后续有更新，会及时通知你。<br>15、迭代器模式(遍历集合)：迭代器模式就是顺序访问聚集中的对象。<br>16、责任链模式(多任务形成⼀条链，请求在链上传递)：有多个对象，每个对象持有对下⼀个对象的引⽤，这样就会形成⼀条链，请求在<br>这条链上传递，直到某⼀对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的<br>情况下，对系统进⾏动态的调整。<br>17、命令模式(实现请求和执⾏的解耦)：命令模式的⽬的就是达到命令的发出者和执⾏者之间解耦，实现请求和执⾏分开，熟悉Struts的<br>同学应该知道，Struts其实就是⼀种将请求和呈现分离的技术，其中必然涉及命令模式的思想！<br>18、备忘录模式(保存和恢复对象状态)：主要⽬的是保存⼀个对象的某个状态，以便在适当的时候恢复对象。<br>19、状态模式(对象状态改变时改变其⾏为)：当对象的状态改变时，同时改变其⾏为。状态模式就两点：1、可以通过改变状态来获得不同<br>的⾏为。2、你的好友能同时看到你的变化。</p><p>20、访问者模式(数据接⼝稳定，但算法易变)：访问者模式把数据结构和作⽤于结构上的操作解耦合，使得操作集合可相对⾃由地演化。<br>访问者模式适⽤于数据结构相对稳定算法⼜易变化的系统。因为访问者模式使得算法操作增加变得容易。访问者模式就是⼀种分离对象数据结构与⾏<br>为的⽅法，通过这种分离，可达到为⼀个被访问者动态添加新的操作⽽⽆需做其它的修改的效果。<br>21、中介者模式：中介者模式也是⽤来降低类类之间的耦合的。如果使⽤中介者模式，只需关⼼和Mediator类的关系，具体类类之间的关系<br>及调度交给Mediator就⾏，这有点像spring容器的作⽤。<br>22、解释器模式(对于⼀些固定⽂法构建⼀个解释句⼦的解释器，如正则表达式)：解释器模式⽤来做各种各样的解释器，如正则表达式等的<br>解释器。<br>23、建造者模式(创建复合对象)：⼯⼚类模式提供的是创建单个类的模式，⽽建造者模式则是将各种产品集中起来进⾏管理，⽤来创建复合对<br>象，所谓复合对象就是指某个类具有不同的属性<br>24、设计模式的六⼤原则：<br>1、开闭原则（Open Close Principle）<br>开闭原则就是说对扩展开放，对修改关闭。在程序需要进⾏拓展的时候，不能去修改原有的代码，实现⼀个热插拔的效果。<br>所以⼀句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使⽤接⼝和抽象类，后⾯的具<br>体设计中我们会提到这点。<br>2、⾥⽒代换原则（Liskov Substitution Principle）<br>⾥⽒代换原则(Liskov Substitution Principle LSP)⾯向对象设计的基本原则之⼀。 ⾥⽒代换原则中说，任何基类<br>可以出现的地⽅，⼦类⼀定可以出现。 LSP是继承复⽤的基⽯，只有当衍⽣类可以替换掉基类，软件单位的功能不受到影响时，<br>基类才能真正被复⽤，⽽衍⽣类也能够在基类的基础上增加新的⾏为。⾥⽒代换原则是对“开-闭”原则的补充。实现“开-闭”原则<br>的关键步骤就是抽象化。⽽基类与⼦类的继承关系就是抽象化的具体实现，所以⾥⽒代换原则是对实现抽象化的具体步骤的规<br>范。—— From Baidu 百科<br>3、依赖倒转原则（Dependence Inversion Principle）<br>这个是开闭原则的基础，具体内容：真对接⼝编程，依赖于抽象⽽不依赖于具体。<br>4、接⼝隔离原则（Interface Segregation Principle）<br>这个原则的意思是：使⽤多个隔离的接⼝，⽐使⽤单个接⼝要好。还是⼀个降低类之间的耦合度的意思，从这⼉我们看出，<br>其实设计模式就是⼀个软件的设计思想，从⼤型软件架构出发，为了升级和维护⽅便。所以上⽂中多次出现：降低依赖，降低耦<br>合。<br>5、迪⽶特法则（最少知道原则）（Demeter Principle）<br>为什么叫最少知道原则，就是说：⼀个实体应当尽量少的与其他实体之间发⽣相互作⽤，使得系统功能模块相对独⽴。<br>6、合成复⽤原则（Composite Reuse Principle）<br>原则是尽量使⽤合成/聚合的⽅式，⽽不是使⽤继承<br>25、jdk中的设计模式：</p><ol><li>单例模式：<br>java.lang.Runtime#getRuntime()<br>java.awt.Desktop#getDesktop()<br>java.lang.System#getSecurityManager()</li><li>责任链模式：<br>java.util.logging.Logger#log()<br>javax.servlet.Filter#doFilter()</li><li>观察者模式：<br>java.util.Observer/ java.util.Observable（很少在现实世界中使⽤）<br>所有实现java.util.EventListener（因此实际上各地的Swing）<br>javax.servlet.http.HttpSessionBindingListener<br>javax.servlet.http.HttpSessionAttributeListener<br>javax.faces.event.PhaseListener<br>26、spring中的设计模式：<br>a. 简单⼯⼚：spring中的BeanFactory就是简单⼯⼚模式的体现，根据传⼊⼀个唯⼀的标识来获得bean对象，但是否是在传⼊<br>参数后创建还是传⼊参数前创建这个要根据具体情况来定。<br>b. 单例模式：Spring下默认的bean均为singleton。<br>c. 代理模式：为其他对象提供⼀种代理以控制对这个对象的访问。 从结构上来看和Decorator模式类似，但Proxy是控制，更像<br>是⼀种对功能的限制，⽽Decorator是增加职责。 spring的Proxy模式在aop中有体现，⽐如JdkDynamicAopProxy和<br>Cglib2AopProxy。<br>d. 观察者模式：定义对象间的⼀种⼀对多的依赖关系，当⼀个对象的状态发⽣改变时，所有依赖于它的对象都得到通知并被⾃<br>动更新。spring中Observer模式常⽤的地⽅是listener的实现。如ApplicationListener。</li></ol><p>1.请列举出在JDK中几个常用的设计模式？</p><p>单例模式（Singleton pattern）用于Runtime，Calendar和其他的一些类中。工厂模式（Factory pattern）被用于各种不可变的类如 Boolean，像Boolean.valueOf，观察者模式（Observer pattern）被用于 Swing 和很多的事件监听中。装饰器设计模式（Decorator design pattern）被用于多个 Java IO 类中。</p><p>2.什么是设计模式？你是否在你的代码里面使用过任何设计模式？</p><p>设计模式是世界上各种各样程序员用来解决特定设计问题的尝试和测试的方法。设计模式是代码可用性的延伸</p><p>3.Java 中什么叫单例设计模式？请用Java 写出线程安全的单例模式</p><p>单例模式重点在于在整个系统上共享一些创建时较耗资源的对象。整个应用中只维护一个特定类实例，它被所有组件共同使用。Java.lang.Runtime是单例模式的经典例子。从 Java 5 开始你可以使用枚举（enum）来实现线程安全的单例。</p><p>4.在 Java 中，什么叫观察者设计模式（observer design pattern）？</p><p>观察者模式是基于对象的状态变化和观察者的通讯，以便他们作出相应的操作。简单的例子就是一个天气系统，当天气变化时必须在展示给公众的视图中进行反映。这个视图对象是一个主体，而不同的视图是观察者。</p><p>5.使用工厂模式最主要的好处是什么？在哪里使用？</p><p>工厂模式的最大好处是增加了创建对象时的封装层次。如果你使用工厂来创建对象，之后你可以使用更高级和更高性能的实现来替换原始的产品实现或类，这不需要在调用层做任何修改。</p><p>6.举一个用 Java 实现的装饰模式(decorator design pattern)？它是作用于对象层次还是类层次？</p><p>装饰模式增加强了单个对象的能力。Java IO 到处都使用了装饰模式，典型例子就是 Buffered 系列类如BufferedReader和BufferedWriter，它们增强了Reader和Writer对象，以实现提升性能的 Buffer 层次的读取和写入。</p><p>7.在 Java 中，为什么不允许从静态方法中访问非静态变量？</p><p>Java 中不能从静态上下文访问非静态数据只是因为非静态变量是跟具体的对象实例关联的，而静态的却没有和任何实例关联。</p><p>8.设计一个 ATM 机，请说出你的设计思路？</p><p>比如设计金融系统来说，必须知道它们应该在任何情况下都能够正常工作。不管是断电还是其他情况，ATM 应该保持正确的状态（事务） , 想想 加锁（locking）、事务（transaction）、错误条件（error condition）、边界条件（boundary condition） 等等。尽管你不能想到具体的设计，但如果你可以指出非功能性需求，提出一些问题，想到关于边界条件，这些都会是很好的。</p><p>9.在 Java 中，什么时候用重载，什么时候用重写？</p><p>如果你看到一个类的不同实现有着不同的方式来做同一件事，那么就应该用重写（overriding），而重载（overloading）是用不同的输入做同一件事。在 Java 中，重载的方法签名不同，而重写并不是。</p><p>10.举例说明什么情况下会更倾向于使用抽象类而不是接口？</p><p>接口和抽象类都遵循”面向接口而不是实现编码”设计原则，它可以增加代码的灵活性，可以适应不断变化的需求。下面有几个点可以帮助你回答这个问题：</p><p>在 Java 中，你只能继承一个类，但可以实现多个接口。所以一旦你继承了一个类，你就失去了继承其他类的机会了。<br>接口通常被用来表示附属描述或行为如：Runnable、Clonable、Serializable等等，因此当你使用抽象类来表示行为时，你的类就不能同时是Runnable和Clonable(注：这里的意思是指如果把Runnable等实现为抽象类的情况)，因为在 Java 中你不能继承两个类，但当你使用接口时，你的类就可以同时拥有多个不同的行为。<br>在一些对时间要求比较高的应用中，倾向于使用抽象类，它会比接口稍快一点。<br>如果希望把一系列行为都规范在类继承层次内，并且可以更好地在同一个地方进行编码，那么抽象类是一个更好的选择。有时，接口和抽象类可以一起使用，接口中定义函数，而在抽象类中定义默认的实现。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/372274a5b315.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/372274a5b315.html" class="post-title-link" itemprop="url">搜索引擎</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:16:06 / 修改时间：16:16:24" itemprop="dateCreated datePublished" datetime="2023-12-20T16:16:06+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" itemprop="url" rel="index"><span itemprop="name">搜索引擎</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>lucene 和 es 的前世今生<br>lucene 是最先进、功能最强大的搜索库。如果直接基于 lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。<br>elasticsearch 基于 lucene，隐藏了 lucene 的复杂性，提供了简单易用的 restful api / Java api 接口（另外还有其他语言的 api 接口）。<br>分布式的文档存储引擎<br>分布式的搜索引擎和分析引擎<br>分布式，支持 PB 级数据<br>es 的核心概念<br>Near Realtime<br>近实时，有两层意思：<br>从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）<br>基于 es 执行搜索和分析可以达到秒级<br>Cluster 集群<br>集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。<br>Node 节点<br>Node 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 elasticsearch 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。<br>Document &amp; field<br>文档是 es 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。<br>{<br>“product_id”: “1”,<br>“product_name”: “iPhone X”,<br>“product_desc”: “苹果手机”,<br>“category_id”: “2”,<br>“category_name”: “电子产品”<br>}<br>Index<br>索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 ducument。<br>Type<br>类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。<br>shard<br>单台机器无法存储大量数据，es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。<br>replica<br>任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5个 replica shard，最小的高可用配置，是 2 台服务器。<br>这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。</p><p>es 核心概念 vs. db 核心概念<br>es dbindex 数据库type 数据表docuemnt 一行数据以上是一个简单的类比。</p><p>面试题<br>es 的分布式架构原理能说一下么（es 是如何实现分布式的啊）？<br>面试官心理分析<br>在搜索这块，lucene 是最流行的搜索库。几年前业内一般都问，你了解 lucene 吗？你知道倒排索引的原理吗？现在早已经 out 了，因为现在很多项目都是直接用基于 lucene 的分布式搜索引擎—— ElasticSearch，简称为 es。<br>而现在分布式搜索基本已经成为大部分互联网行业的 Java 系统的标配，其中尤为流行的就是 es，前几年 es 没火的时候，大家一般用 solr。但是这两年基本大部分企业和项目都开始转向 es 了。<br>所以互联网面试，肯定会跟你聊聊分布式搜索引擎，也就一定会聊聊 es，如果你确实不知道，那你真的就 out 了。<br>如果面试官问你第一个问题，确实一般都会问你 es 的分布式架构设计能介绍一下么？就看看你对分布式搜索引擎架构的一个基本理解。<br>面试题剖析<br>ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。<br>es 中存储数据的基本单位是索引，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql 里的一张表。<br>index -&gt; type -&gt; mapping -&gt; document -&gt; field。<br>这样吧，为了做个更直白的介绍，我在这里做个类比。但是切记，不要划等号，类比只是为了便于理解。<br>index 相当于 mysql 里的一张表。而 type 没法跟 mysql 里去对比，一个 index 里可以有多个 type，每个 type 的字段都是差不多的，但是有一些略微的差别。假设有一个 index，是订单 index，里面专门是放订单数据的。就好比说你在 mysql 中建表，有些订单是实物商品的订单，比如一件衣服、一双鞋子；有些订单是虚拟商品的订单，比如游戏点卡，话费充值。就两种订单大部分字段是一样的，但是少部分字段可能有略微的一些差别。<br>所以就会在订单 index 里，建两个 type，一个是实物商品订单 type，一个是虚拟商品订单 type，这两个 type 大部分字段是一样的，少部分字段是不一样的。<br>很多情况下，一个 index 里可能就一个 type，但是确实如果说是一个 index 里有多个 type 的情况（注意，mapping types这个概念在 ElasticSearch 7.X 已被完全移除，详细说明可以参考官方文档），你可以认为 index 是一个类别的表，具体的每个 type 代表了 mysql 中的一个表。每个 type 有一个 mapping，如果你认为一个 type 是具体的一个表，index 就代表多个 type 同属于的一个类型，而 mapping 就是这个 type 的表结构定义，你在 mysql 中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。实际上你往 index 里的一个 type 里面写的一条数据，叫做一条 document，一条 document 就代表了 mysql 中某个表里的一行，每个 document 有多个 field，每个 field 就代表了这个 document 中的一个字段的值。</p><p>你搞一个索引，这个索引可以拆分成多个 shard，每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是支持横向扩展，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是提高性能，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。<br>接着就是这个 shard 的数据实际是有多个备份，就是说每个 shard 都有一个 primary shard，负责写入数据，但是还有几个 replica shard。primary shard 写入数据之后，会将数据同步到其他几个 replica shard 上去。</p><p>通过这个 replica 的方案，每个 shard 的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。<br>es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点其实就是干一些管理的工作的，比如维护索引元数据、负责切换 primary shard 和 replica shard 身份等。要是 master 节点宕机了，那么会重新选举一个节点为 master 节点。<br>如果是非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard。接着你要是修复了那个宕机机器，重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。<br>说得更简单一点，就是说如果某个非 master 节点宕机了。那么此节点上的 primary shard 不就没了。那好，master 会让 primary shard 对应的 replica shard（在其他机器上）切换为 primary shard。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。<br>其实上述就是 ElasticSearch 作为分布式搜索引擎最基本的一个架构设计。</p><p>面试题<br>es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？<br>面试官心理分析<br>问这个，其实面试官就是要看看你了解不了解 es 的一些基本原理，因为用 es 无非就是写入数据，搜索数据。你要是不明白你发起一个写入和搜索请求的时候，es 在干什么，那你真的是……<br>对 es 基本就是个黑盒，你还能干啥？你唯一能干的就是用 es 的 api 读写数据了。要是出点什么问题，你啥都不知道，那还能指望你什么呢？<br>面试题剖析<br>es 写数据过程<br>客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。<br>coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。<br>实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。<br>coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。</p><p>es 读数据过程<br>可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。<br>客户端发送请求到任意一个 node，成为 coordinate node。<br>coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin 随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。<br>接收请求的 node 返回 document 给 coordinate node。<br>coordinate node 返回 document 给客户端。<br>es 搜索数据过程<br>es 最强大的是做全文检索，就是比如你有三条数据：<br>java真好玩儿啊<br>java好难学啊<br>j2ee特别牛<br>你根据 java 关键词来搜索，将包含 java的 document 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。<br>客户端发送请求到一个 coordinate node。<br>协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。<br>query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。<br>fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。<br>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。<br>写数据底层原理</p><p>先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。<br>如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中，但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。<br>每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file，这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。<br>但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。<br>操作系统里面，磁盘文件其实都有一个东西，叫做 os cache，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 os cache，先进入操作系统级别的一个内存缓存中去。只要 buffer 中的数据被 refresh 操作刷入 os cache中，这个数据就可以被搜索到了。<br>为什么叫 es 是准实时的？ NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 restful api 或者 java api，手动执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 os cache中，让数据立马就可以被搜索到。只要数据被输入 os cache 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。<br>重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 buffer 数据写入一个又一个新的 segment file 中去，每次 refresh 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 commit 操作。<br>commit 操作发生第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。然后，将一个 commit point 写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到磁盘文件中去。最后清空 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。<br>这个 commit 操作叫做 flush。默认 30 分钟自动执行一次 flush，但如果 translog 过大，也会触发 flush。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。<br>translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 translog 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。<br>translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会丢失 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。<br>实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的数据丢失。<br>总结一下，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。<br>数据写入 segment file 之后，同时就建立好了倒排索引。<br>删除/更新数据底层原理<br>如果是删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。<br>如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。<br>buffer 每 refresh 一次，就会产生一个 segment file，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 segment file 合并成一个，同时这里会将标识为 deleted 的 doc 给物理删除掉，然后将新的 segment file 写入磁盘，这里会写一个 commit point，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。<br>底层 lucene<br>简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。<br>通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。<br>倒排索引<br>在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。<br>那么，倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。<br>举个栗子。<br>有以下文档：<br>DocId Doc<br>1 谷歌地图之父跳槽 Facebook<br>2 谷歌地图之父加盟 Facebook<br>3 谷歌地图创始人拉斯离开谷歌加盟 Facebook<br>4 谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关<br>5 谷歌地图之父拉斯加盟社交网站 Facebook<br>对文档进行分词之后，得到以下倒排索引。<br>WordId Word DocIds<br>1 谷歌 1,2,3,4,5<br>2 地图 1,2,3,4,5<br>3 之父 1,2,4,5<br>4 跳槽 1,4<br>5 Facebook 1,2,3,4,5<br>6 加盟 2,3,5<br>7 创始人 3<br>8 拉斯 3,5<br>9 离开 3<br>10 与 4<br>.. .. ..<br>另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。<br>那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 Facebook，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。<br>要注意倒排索引的两个重要细节：<br>倒排索引中的所有词项对应一个或多个文档；<br>倒排索引中的词项根据字典顺序升序排列<br>上面只是一个简单的栗子，并没有严格按照字典顺序升序排列。</p><p>面试题<br>es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？<br>面试官心理分析<br>这个问题是肯定要问的，说白了，就是看你有没有实际干过 es，因为啥？其实 es 性能并没有你想象中那么好的。很多时候数据量大了，特别是有几亿条数据的时候，可能你会懵逼的发现，跑个搜索怎么一下 5<del>10s，坑爹了。第一次搜索的时候，是 5</del>10s，后面反而就快了，可能就几百毫秒。<br>你就很懵，每个用户第一次访问都会比较慢，比较卡么？所以你要是没玩儿过 es，或者就是自己玩玩儿 demo，被问到这个问题容易懵逼，显示出你对 es 确实玩儿的不怎么样？<br>面试题剖析<br>说实话，es 性能优化是没有什么银弹的，啥意思呢？就是不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景。也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。<br>性能优化的杀手锏——filesystem cache<br>你往 es 里写的数据，实际上都写到磁盘文件里去了，查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。</p><p>es 的搜索引擎严重依赖于底层的 filesystem cache，你如果给 filesystem cache 更多的内存，尽量让内存可以容纳所有的 idx segment file 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。<br>性能差距究竟可以有多大？我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。但如果是走 filesystem cache，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。<br>这里有个真实的案例。某个公司 es 节点有 3 台机器，每台机器看起来内存很多，64G，总内存就是 64 * 3 = 192G。每台机器给 es jvm heap 是 32G，那么剩下来留给 filesystem cache 的就是每台机器才 32G，总共集群里给 filesystem cache 的就是 32 * 3 = 96G 内存。而此时，整个磁盘上索引数据文件，在 3 台机器上一共占用了 1T 的磁盘容量，es 数据量是 1T，那么每台机器的数据量是 300G。这样性能好吗？ filesystem cache 的内存才 100G，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差。<br>归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。<br>根据我们自己的生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，就是你要用来搜索的那些索引，如果内存留给 filesystem cache 的是 100G，那么你就将索引数据控制在 100G 以内，这样的话，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。<br>比如说你现在有一行数据。id,name,age …. 30 个字段。但是你现在搜索，只需要根据 id,name,age 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 90% 的数据是不用来搜索的，结果硬是占据了 es 机器上的 filesystem cache 的空间，单条数据的数据量越大，就会导致 filesystem cahce 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的少数几个字段就可以了，比如说就写入 es id,name,age 三个字段，然后你可以把其他的字段数据存在 mysql/hbase 里，我们一般是建议用 es + hbase 这么一个架构。<br>hbase 的特点是适用于海量数据的在线存储，就是对 hbase 可以写入海量数据，但是不要做复杂的搜索，做很简单的一些根据 id 或者范围进行查询的这么一个操作就可以了。从 es 中根据 name 和 age 去搜索，拿到的结果可能就 20 个 doc id，然后根据 doc id 到 hbase 里去查询每个 doc id 对应的完整的数据，给查出来，再返回给前端。<br>写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms，可能你原来那么玩儿，1T 数据都放 es，会每次查询都是 5<del>10s，现在可能性能就会很高，每次查询就是 50ms。<br>数据预热<br>假如说，哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 filesystem cache 一倍，比如说你写入一台机器 60G 数据，结果 filesystem cache 就 30G，还是有 30G 数据留在了磁盘上。<br>其实可以做数据预热。<br>举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 filesystem cache 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。<br>或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 filesystem cache 里去。<br>对于那些你觉得比较热的、经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据每隔一段时间，就提前访问一下，让数据进入 filesystem cache 里面去。这样下次别人访问的时候，性能一定会好很多。<br>冷热分离<br>es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。<br>你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 filesystem cache 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。<br>document 模型设计<br>对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。<br>最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。<br>document 模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es 能支持的操作就那么多，不要考虑用 es 做一些它不好操作的事情。如果真的有那种操作，尽量在 document 模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的。<br>分页性能优化<br>es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。<br>分布式的，你要查第 100 页的 10 条数据，不可能说从 5 个 shard，每个 shard 就查 2 条数据，最后到协调节点合并成 10 条数据吧？你必须得从每个 shard 都查 1000 条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第 100 页的数据。你翻页的时候，翻的越深，每个 shard 返回的数据就越多，而且协调节点处理的时间越长，非常坑爹。所以用 es 做分页的时候，你会发现越翻到后面，就越是慢。<br>我们之前也是遇到过这个问题，用 es 作分页，前几页就几十毫秒，翻到 10 页或者几十页的时候，基本上就要 5</del>10 秒才能查出来一页数据了。<br>有什么解决方案吗？<br>不允许深度分页（默认深度分页性能很差）<br>跟产品经理说，你系统不允许翻那么深的页，默认翻的越深，性能就越差。<br>类似于 app 里的推荐商品不断下拉出来一页一页的<br>类似于微博中，下拉刷微博，刷出来一页一页的，你可以用 scroll api，关于如何使用，自行上网搜索。<br>scroll 会一次性给你生成所有数据的一个快照，然后每次滑动向后翻页就是通过游标 scroll_id 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。<br>但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，不能随意跳到任何一页的场景。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。<br>初始化时必须指定 scroll 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。<br>除了用 scroll api，你也可以用 search_after 来做，search_after 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。</p><p>面试题<br>es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？<br>面试官心理分析<br>这个问题，包括后面的 redis 什么的，谈到 es、redis、mysql 分库分表等等技术，面试必问！就是你生产环境咋部署的？说白了，这个问题没啥技术含量，就是看你有没有在真正的生产环境里干过这事儿！<br>有些同学可能是没在生产环境中干过的，没实际去拿线上机器部署过 es 集群，也没实际玩儿过，也没往 es 集群里面导入过几千万甚至是几亿的数据量，可能你就不太清楚这里面的一些生产项目中的细节。<br>如果你是自己就玩儿过 demo，没碰过真实的 es 集群，那你可能此时会懵。别懵，你一定要云淡风轻的回答出来这个问题，表示你确实干过这事儿。<br>面试题剖析<br>其实这个问题没啥，如果你确实干过 es，那你肯定了解你们生产 es 集群的实际情况，部署了几台机器？有多少个索引？每个索引有多大数据量？每个索引给了多少个分片？你肯定知道！<br>但是如果你确实没干过，也别虚，我给你说一个基本的版本，你到时候就简单说一下就好了。<br>es 生产集群我们部署了 5 台机器，每台机器是 6 核 64G 的，集群总内存是 320G。<br>我们 es 集群的日增量数据大概是 2000 万条，每天日增量数据大概是 500MB，每月增量数据大概是 6 亿，15G。目前系统已经运行了几个月，现在 es 集群里数据总量大概是 100G 左右。<br>目前线上有 5 个索引（这个结合你们自己业务来，看看自己有哪些数据可以放 es 的），每个索引的数据量大概是 20G，所以这个数据量之内，我们每个索引分配的是 8 个 shard，比默认的 5 个 shard 多了 3 个 shard。<br>大概就这么说一下就行了。</p></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/f17ba5c005d6.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/f17ba5c005d6.html" class="post-title-link" itemprop="url">Linux</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:14:12" itemprop="dateCreated datePublished" datetime="2023-12-20T16:14:12+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-24 11:46:25" itemprop="dateModified" datetime="2023-12-24T11:46:25+08:00">2023-12-24</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="使⽤两种命令创建⼀个⽂件？"><a href="#使⽤两种命令创建⼀个⽂件？" class="headerlink" title="使⽤两种命令创建⼀个⽂件？"></a>使⽤两种命令创建⼀个⽂件？</h1><ul><li>touch a.txt</li><li>vi a.txt</li><li>mkdir abc</li><li>cat &gt; a.txt 建⽴⼀⽂件，然后把接下来的键盘输⼊写⼊⽂件，直到按Ctrl+D为⽌.</li></ul><h1 id="硬链接和软连接的区别？"><a href="#硬链接和软连接的区别？" class="headerlink" title="硬链接和软连接的区别？"></a>硬链接和软连接的区别？</h1><h4 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h4><ul><li>⽂件有相同的 inode 及 data block；</li><li>只能对已存在的⽂件进⾏创建；</li><li>不能交叉⽂件系统进⾏硬链接的创建；</li><li>不能对⽬录进⾏创建，只可对⽂件创建；</li><li>删除⼀个硬链接⽂件并不影响其他有相同 inode 号的⽂件。</li></ul><h4 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h4><ul><li>软链接有⾃⼰的⽂件属性及权限等；</li><li>可对不存在的⽂件或⽬录创建软链接；</li><li>软链接可交叉⽂件系统；</li><li>软链接可对⽂件或⽬录创建；</li><li>创建软链接时，链接计数 i_nlink 不会增加；</li><li>删除软链接并不影响被指向的⽂件，但若被指向的原⽂件被删除，则相关软连接被称为死链接（即 dangling<br>link，若被指向路径⽂件被重新创建，死链接可恢复为正常的软链接）。</li></ul><h1 id="linux常⽤命令有哪些"><a href="#linux常⽤命令有哪些" class="headerlink" title="linux常⽤命令有哪些"></a>linux常⽤命令有哪些</h1><ul><li>查找关闭端⼝进程 netstat -nlp | grep :3306 kill pid</li><li>删除⽂件 rm -rf</li><li>查找⽇志 cat xx.log | grep ‘xxx’ | more</li><li>解压tar.gz tar -xzvf file.tar.gz</li><li>创建⽂件 touch filename cat &gt; filename</li><li>修改⽂件 vi</li></ul><h1 id="怎么查看⼀个java线程的资源耗⽤"><a href="#怎么查看⼀个java线程的资源耗⽤" class="headerlink" title="怎么查看⼀个java线程的资源耗⽤"></a>怎么查看⼀个java线程的资源耗⽤</h1><ul><li>linux下，所有的java内部线程，其实都对应了⼀个进程id，也就是说，linux上的jvm将java程序中的线程映射为操作系统进程。</li><li>jps -lvm或者ps -ef | grep java查看当前机器上运⾏的Java应⽤进程</li><li>top -Hp pid可以查看Java所有线程的资源耗⽤</li><li>printf “%x\n” pid等到线程ID的16进制</li><li>jstack Java应⽤进程ID | grep 线程ID的16进制</li></ul><h1 id="Load过⾼的可能性有哪些？"><a href="#Load过⾼的可能性有哪些？" class="headerlink" title="Load过⾼的可能性有哪些？"></a>Load过⾼的可能性有哪些？</h1><ul><li>cpu load的飙升，⼀⽅⾯可能和full gc的次数增⼤有关，⼀⽅⾯可能和死循环有关系</li></ul><h1 id="etc-hosts⽂件什么作⽤"><a href="#etc-hosts⽂件什么作⽤" class="headerlink" title="/etc/hosts⽂件什么作⽤"></a>/etc/hosts⽂件什么作⽤</h1><ul><li>在当前主机给ip设置别名，通过该别名可以访问到该ip地址，通过别名、ip访问的效果是⼀样的</li></ul><h1 id="如何快速的将⼀个⽂本中的”abc”转换成”xyz”？"><a href="#如何快速的将⼀个⽂本中的”abc”转换成”xyz”？" class="headerlink" title="如何快速的将⼀个⽂本中的”abc”转换成”xyz”？"></a>如何快速的将⼀个⽂本中的”abc”转换成”xyz”？</h1><ul><li>vi filename编辑⽂本，按Esc键，输⼊:%s/abc/xyz/g</li></ul><h1 id="如何在log⽂件中搜索找出error的⽇志？"><a href="#如何在log⽂件中搜索找出error的⽇志？" class="headerlink" title="如何在log⽂件中搜索找出error的⽇志？"></a>如何在log⽂件中搜索找出error的⽇志？</h1><ul><li>cat xx.log | grep ‘error’</li></ul><h1 id="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件"><a href="#发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件" class="headerlink" title="发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?"></a>发现硬盘空间不够，如何快速找出占⽤空间最⼤的⽂件?</h1><ul><li>find . -type f -size +100M | xargs du -h | sort -nr</li></ul><h1 id="Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）"><a href="#Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）" class="headerlink" title="Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）"></a>Java服务端问题排查（OOM，CPU⾼，Load⾼，类冲突）</h1><h4 id="业务⽇志相关"><a href="#业务⽇志相关" class="headerlink" title="业务⽇志相关"></a>业务⽇志相关</h4><ul><li>less或者more</li><li>grep</li><li>tail -f filename</li><li>切忌vim直接打开⼤⽇志⽂件，因为会直接加载到内存的</li></ul><h4 id="数据库相关"><a href="#数据库相关" class="headerlink" title="数据库相关"></a>数据库相关</h4><ul><li>登录线上库，show processlist查看数据库连接情况</li></ul><h4 id="jvm相关："><a href="#jvm相关：" class="headerlink" title="jvm相关："></a>jvm相关：</h4><ul><li>jps显示java进程</li><li>jinfo实时查看和调整jvm参数</li><li>jstat监控jvm各种运⾏状态信息；</li><li>jstack(Stack Trace for Java)命令⽤于⽣成JVM进程当前时刻的线程的调⽤堆栈，可以⽤来定位线程间死锁、<br>锁等待、等待外部资源等</li><li>jmap(Memory Map for Java) 命令⽤于⽣成堆转储快照dump⽂件，除了这种⽅式还可以通过-<br>XX:HeapDumpOnOutOfMemoryError参数，可以在虚拟机发⽣OOM的时候⾃动⽣成堆的dump⽂件，或者kill -3<br>命令发出进程退出信号”吓唬”⼀下虚拟机，也能拿到dump⽂件。</li></ul><h4 id="oom问题："><a href="#oom问题：" class="headerlink" title="oom问题："></a>oom问题：</h4><ul><li>配置了-XX:+HeapDumpOnOutOfMemoryError, 在发⽣OOM的时候会在-XX:HeapDumpPath⽣成堆的dump⽂<br>件，结合MAT，可以对dump⽂件进⾏分析，查找出发⽣OOM的原因。</li><li>另外⼿动dump堆快照，可以使⽤命令jmap -dump:format=b,file=file_name pid 或者kill -3 pid</li></ul><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><ul><li>jps -v</li><li>jstack -l pid</li></ul><h4 id="线程block、线程数暴涨："><a href="#线程block、线程数暴涨：" class="headerlink" title="线程block、线程数暴涨："></a>线程block、线程数暴涨：</h4><ul><li>jstack -l pid |wc -l</li><li>jstack -l pid |grep “BLOCKED”|wc -l</li><li>jstack -l pid |grep “Waiting on condition”|wc -l<br>线程block问题⼀般是等待io、等待⽹络、等待监视器锁等造成，可能会导致请求超时、造成造成线程数暴涨导致系统502等。</li></ul><h4 id="服务器问题："><a href="#服务器问题：" class="headerlink" title="服务器问题："></a>服务器问题：</h4><h5 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h5><ul><li>top</li></ul><h5 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h5><ul><li>free -m -c10 -s1：<ul><li>-m：以MB为单位显示，其他的有-k -g -b</li><li>-s: 间隔多少秒持续观察内存使⽤状况</li><li>-c:观察多少次</li></ul></li><li>vmstat 1 10：1表示每隔1s输出⼀次,10 表示输出10次<ul><li>r: 运⾏队列中进程数量，这个值也可以判断是否需要增加CPU。（⻓期⼤于1）</li><li>b: 等待IO的进程数量。</li></ul></li></ul><h5 id="io"><a href="#io" class="headerlink" title="io"></a>io</h5><ul><li>iostat -m 1 10：<ul><li>-m：某些使⽤block为单位的列强制使⽤MB为单位</li><li>1 10：数据显示每隔1秒刷新⼀次，共显示10次</li></ul></li></ul><h5 id="⽹络"><a href="#⽹络" class="headerlink" title="⽹络"></a>⽹络</h5><ul><li>netstat -antp：<ul><li>-a (all)显示所有选项，默认不显示LISTEN相关</li><li>-t (tcp)仅显示tcp相关选项</li><li>-u (udp)仅显示udp相关选项</li><li>-n 拒绝显示别名，能显示数字的全部转化成数字。</li><li>-l 仅列出有在 Listen (监听) 的服服务状态</li><li>-p 显示建⽴相关链接的程序名</li></ul></li></ul><h1 id="Thread-dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）"><a href="#Thread-dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）" class="headerlink" title="Thread dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）"></a>Thread dump⽂件如何分析（Runnable，锁，代码栈，操作系统线程id关联）</h1><h4 id="Thread-Dump-能诊断的问题"><a href="#Thread-Dump-能诊断的问题" class="headerlink" title="Thread Dump 能诊断的问题"></a>Thread Dump 能诊断的问题</h4><ul><li>查找内存泄露，常⻅的是程序⾥load⼤量的数据到缓存；</li><li>发现死锁线程；</li></ul><h4 id="如何抓取Thread-Dump信息："><a href="#如何抓取Thread-Dump信息：" class="headerlink" title="如何抓取Thread Dump信息："></a>如何抓取Thread Dump信息：</h4><ul><li>⼀般当服务器挂起,崩溃或者性能底下时,就需要抓取服务器的线程堆栈(Thread Dump)⽤于后续的分析. 在实际运⾏中，往往⼀次 dump的信息，还不⾜以确认问题。为了反映线程状态的动态变化，需要接连多次做threaddump，每次间隔10-20s，建议⾄少产⽣三次 dump信息，如果每次 dump都指向同⼀个问题，我们才确定问题的典型性。</li></ul><h4 id="linux命令获取"><a href="#linux命令获取" class="headerlink" title="linux命令获取"></a>linux命令获取</h4><ul><li>ps –ef | grep java</li><li>kill -3<pid></pid></li></ul><h4 id="jdk⾃带⼯具获取"><a href="#jdk⾃带⼯具获取" class="headerlink" title="jdk⾃带⼯具获取"></a>jdk⾃带⼯具获取</h4><ul><li>jps 或 ps –ef|grepjava (获取PID)</li><li>jstack [-l ]<pid>| tee -a jstack.log (获取ThreadDump)</pid></li></ul><h1 id="如何查看Java应⽤的线程信息？"><a href="#如何查看Java应⽤的线程信息？" class="headerlink" title="如何查看Java应⽤的线程信息？"></a>如何查看Java应⽤的线程信息？</h1><ul><li>通过top命令拿到线程的pid后使⽤jstack命令</li></ul><h1 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h1><ul><li>wc -l</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://javainterviewguide.github.io/publishes/fca1d6209800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="褚岩"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Java后端面试指南"><meta itemprop="description" content="路漫漫其修远兮，吾将上下而求索"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | Java后端面试指南"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/publishes/fca1d6209800.html" class="post-title-link" itemprop="url">计算机网络</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-12-20 16:11:54" itemprop="dateCreated datePublished" datetime="2023-12-20T16:11:54+08:00">2023-12-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-12-23 18:26:08" itemprop="dateModified" datetime="2023-12-23T18:26:08+08:00">2023-12-23</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">网络</span></a></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="TCP建⽴连接的过程。"><a href="#TCP建⽴连接的过程。" class="headerlink" title="TCP建⽴连接的过程。"></a>TCP建⽴连接的过程。</h1><h4 id="三次握⼿"><a href="#三次握⼿" class="headerlink" title="三次握⼿"></a>三次握⼿</h4><ul><li>第⼀次握⼿(客户端发送syn包到服务器端)：客户端发送syn包到服务器端，进⼊syn_send状态，等待服务器端的确认；</li><li>第⼆次握⼿(服务器返回syn+ack包给客户端)：服务器端收到客户端的syn包，发送syn+ack包给客户端，进⼊syn_recv状态；</li><li>第三次握⼿(客服端返回ack包给服务端)：客户端收到服务器端的syn+ack包，发送个ack包到服务器端，⾄此，客户端与服务器端进⼊established状态；</li><li>握⼿过程中传送的包不包含任何数据，连接建⽴后才会开始传送数据，理想状态下，TCP连接⼀旦建⽴，在通信双⽅的任何⼀⽅主动关闭连接前，TCP连接都会⼀直保持下去。</li></ul><h1 id="TCP断开连接的过程。"><a href="#TCP断开连接的过程。" class="headerlink" title="TCP断开连接的过程。"></a>TCP断开连接的过程。</h1><h4 id="四次握⼿"><a href="#四次握⼿" class="headerlink" title="四次握⼿"></a>四次握⼿</h4><ul><li>第⼀次握⼿：主动关闭⽅发送fin包到被动关闭⽅，告诉被动关闭⽅我不会再给你发送数据了；</li><li>第⼆次握⼿：被动关闭⽅收到syn包，发送ack给对⽅，确认序号为收到序号+1；</li><li>第三次握⼿：被动关闭⽅也也发送fin包给主动关闭⽅，告诉对⽅我也不会给你发送数据了；</li><li>第四次握⼿：主动关闭⽅收到syn包，发送ack给对⽅，⾄此，完成四次握⼿；</li></ul><h1 id="浏览器发⽣302跳转背后的逻辑"><a href="#浏览器发⽣302跳转背后的逻辑" class="headerlink" title="浏览器发⽣302跳转背后的逻辑"></a>浏览器发⽣302跳转背后的逻辑</h1><ul><li>浏览器在原请求地址的响应的Location域找到要跳转的URI执⾏跳转。</li></ul><h4 id="浏览器输⼊URL后发⽣了什么"><a href="#浏览器输⼊URL后发⽣了什么" class="headerlink" title="浏览器输⼊URL后发⽣了什么"></a>浏览器输⼊URL后发⽣了什么</h4><ul><li>DNS域名解析；</li><li>建⽴TCP连接；</li><li>发送HTTP请求；</li><li>服务器处理请求；</li><li>返回响应结果；</li><li>关闭TCP连接；</li><li>浏览器解析HTML；</li><li>浏览器布局渲染；</li></ul><h1 id="HTTP协议的交互流程。-HTTP和HTTPS的差异，-SSL的交互流程？"><a href="#HTTP协议的交互流程。-HTTP和HTTPS的差异，-SSL的交互流程？" class="headerlink" title="HTTP协议的交互流程。 HTTP和HTTPS的差异， SSL的交互流程？"></a>HTTP协议的交互流程。 HTTP和HTTPS的差异， SSL的交互流程？</h1><h4 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h4><ul><li>建⽴TCP连接；</li><li>发送HTTP请求；</li><li>服务器处理请求；</li><li>返回响应结果；</li><li>关闭TCP连接；</li></ul><h5 id="http三次握⼿："><a href="#http三次握⼿：" class="headerlink" title="http三次握⼿："></a>http三次握⼿：</h5><ul><li>第⼀次握⼿：客户端发送syn包(syn=j)到服务器，并进⼊SYN_SEND状态，等待服务器确认；</li><li>第⼆次握⼿：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时⾃⼰也发送⼀个SYN包（syn=k），即<br>SYN+ACK包，此时服务器进⼊SYN_RECV状态；</li><li>第三次握⼿：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进⼊ESTABLISHED状态，完成三次握⼿。</li></ul><h4 id="HTTPS协议"><a href="#HTTPS协议" class="headerlink" title="HTTPS协议"></a>HTTPS协议</h4><ul><li>TTPS协议就是基于SSL的HTTP协议</li><li>HTTPS使⽤与HTTP不同的端⼝（HTTPS80 ， HTTPSS443）</li><li>提供了身份验证与加密通信⽅法，被⼴泛⽤于互联⽹上安全敏感的通信。</li><li>客户端请求SSL连接，并将⾃⼰⽀持的加密规则发给⽹站。</li><li>服务器端将⾃⼰的身份信息以证书形式发回给客户端。证书⾥⾯包含了⽹站地址，加密公钥，以及证书的颁发机构。</li><li>获得证书后，客户要做以下⼯作<ul><li>验证证书合法性</li><li>如果证书受信任，客户端会⽣成⼀串随机数的密码，并⽤证书提供的公钥进⾏加密。</li><li>将加密好的随机数发给服务器。</li><li>获得到客户端发的加密了的随机数之后，服务器⽤⾃⼰的私钥进⾏解密，得到这个随机数，把这个随机数作为对称加密的密钥。（利⽤⾮对称加密传输对称加密的密钥）</li><li>之后服务器与客户之间就可以⽤随机数对各⾃的信息进⾏加密，解密。</li></ul></li><li>注意的是：证书是⼀个公钥，这个公钥是进⾏加密⽤的。⽽私钥是进⾏解密⽤的。公钥任何都知道，私钥只有⾃⼰知道。这是⾮对称加密。⽽对称加密就是钥匙只有⼀把，我们都知道。</li><li>之所以⽤到对称加密，是因为对称加密的速度更快。⽽⾮对称加密的可靠性更⾼。</li><li>客户端请求–服务端发送证书（公钥）–客户端验证证书，并⽣成随机数，通过公钥加密后发送给服务端–服务端⽤私钥解密出随机数–对称加密传输数据。</li></ul><h4 id="HTTP与HTTPS的区别"><a href="#HTTP与HTTPS的区别" class="headerlink" title="HTTP与HTTPS的区别"></a>HTTP与HTTPS的区别</h4><ul><li>HTTPS协议需要申请证书。</li><li>HTTP是明⽂传输；HTTPS使⽤的是具有安全性的SSL加密传输协议</li><li>HTTP端⼝是80；HTTPS端⼝号是443</li><li>HTTP连接简单⽆状态；HTTPS由SSL+HTTP协议构件的可进⾏加密传输、身份验证的⽹络协议。</li></ul><h4 id="Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解"><a href="#Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解" class="headerlink" title="Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解?"></a>Rest和Http什么关系？⼤家都说Rest很轻置，你对Rest⻛格如何理解?</h4><ul><li>Http是⼀种协议，Rest是⼀种软件架构⻛格。</li><li>URL定位资源，⽤HTTP动词（GET,POST,DELETE,DETC）描述操作。</li><li>GET表示查询、POST表示新建、PUT表示更新、DELETE表示删除等。<ul><li>GET /api/v1/user 获取⽤户列表</li><li>GET /api/v1/user/1 获取ID为1的⽤户</li><li>POST /api/v1/user 新建⽤户</li><li>PUT /api/v1/user/1 更新ID为1的⽤户信息</li><li>DELETE /api/v1/user/1 删除ID为1的⽤户</li></ul></li><li>概念：REST（英⽂：Representational State Transfer，简称REST，表现层状态转化），指的是⼀组架构约束条件和原则。满⾜这些约束条件和原则的应⽤程序或设计就是 RESTful。</li><li>⼀种软件架构⻛格，设计⻛格⽽不是标准，只是提供了⼀组设计原则和约束条件。它主要⽤于客户端和服务器交互类的软件。基于这个⻛格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。</li><li>Restful架构：<ul><li>每⼀个URI代表⼀种资源；</li><li>客户端和服务器之间，传递这种资源的某种表现层；</li><li>客户端通过四个HTTP动词(GET⽤来获取资源，POST⽤来新建资源（也可以⽤于更新资源），PUT⽤来更新资源，DELETE⽤来删除资源。)，对服务器端资源进⾏操作，实现”表现层状态转化”。</li></ul></li></ul><h1 id="TCP的滑动窗⼝协议有什么⽤？讲讲原理。"><a href="#TCP的滑动窗⼝协议有什么⽤？讲讲原理。" class="headerlink" title="TCP的滑动窗⼝协议有什么⽤？讲讲原理。"></a>TCP的滑动窗⼝协议有什么⽤？讲讲原理。</h1><ul><li>滑动窗⼝协议是传输层进⾏流控的⼀种措施，接收⽅通过通告发送⽅⾃⼰的窗⼝⼤⼩，从⽽控制发送⽅的发送速度，从⽽达到防⽌发送⽅发送速度过快⽽导致来不及接受。</li></ul><h1 id="HTTP协议都有哪些⽅法？"><a href="#HTTP协议都有哪些⽅法？" class="headerlink" title="HTTP协议都有哪些⽅法？"></a>HTTP协议都有哪些⽅法？</h1><ul><li>GET 请求获取由Request-URI所标识的资源。</li><li>POST 在Request-URI所标识的资源后附加新的数据。</li><li>HEAD 请求获取由Request-URI所标识的资源的响应消息报头。</li><li>OPTIONS 请求查询服务器的性能，或查询与资源相关的选项和需求。</li><li>PUT 请求服务器存储⼀个资源，并⽤Request-URI作为其标识。</li><li>DELETE 请求服务器删除由Request-URI所标识的资源。</li><li>TRACE 请求服务器回送收到的请求信息，主要⽤语测试或诊断。</li></ul><h1 id="交换机与路由器的区别？"><a href="#交换机与路由器的区别？" class="headerlink" title="交换机与路由器的区别？"></a>交换机与路由器的区别？</h1><h4 id="⼯作层次不同"><a href="#⼯作层次不同" class="headerlink" title="⼯作层次不同"></a>⼯作层次不同</h4><ul><li>最初的交换机⼯作在OSI模型中的数据链路层，⼯作原理简单</li><li>路由器⼯作在OSI模型中的⽹络层，得更多协议信息，做更智能的转发决策</li></ul><h4 id="数据转发所依据的对象不同"><a href="#数据转发所依据的对象不同" class="headerlink" title="数据转发所依据的对象不同"></a>数据转发所依据的对象不同</h4><ul><li>交换机是利⽤物理地址（MAC地址），确定转发的⽬的地址。（MAC固化硬件，⼀般不可更改）</li><li>路由器是利⽤IP地址，确定转发的⽬的地址。（IP通常为⽹关或p系统⾃动分配的）</li></ul><h4 id="是否可以分割⼴播域"><a href="#是否可以分割⼴播域" class="headerlink" title="是否可以分割⼴播域"></a>是否可以分割⼴播域</h4><ul><li>传统的交换机可以分割冲突域，不能分割⼴播域，⽽路由器可以分割⼴播域</li><li>由交换机连接的⽹段仍然属于同⼀⼴播域，⼴播数据报会在交换机连接的所有⽹段上传播，某些情况导致通信拥堵和安全漏洞。</li><li>连接到路由器上的⽹段被分配成不同的⼴播域，所以，⼴播数据不穿过路由器</li><li>虽然三层交换机可以分割⼴播域，但是⼦⼴播域之间不能通信，还是需要路由器</li></ul><h4 id="路由器提供了防⽕墙的服务"><a href="#路由器提供了防⽕墙的服务" class="headerlink" title="路由器提供了防⽕墙的服务"></a>路由器提供了防⽕墙的服务</h4><ul><li>路由器仅仅转发特定地址的数据包，不传送不⽀持路由协议的数据包，不传送未知⽬标⽹络数据包，从⽽可以防⽌⼴播⻛暴</li></ul><h4 id="表"><a href="#表" class="headerlink" title="表"></a>表</h4><ul><li>⼆层交换机上存在MAC表，三层交换机上存在路由表、MAC表、ARP表，路由器上存在路由表和ARP表。</li><li>总之，交换机在具体的城域⽹中扮演着VLAN透传的⻆⾊，就是桥。</li><li>路由器的每⼀个端⼝都是⼀个独⽴的⼴播域和冲突域，⽽交换机是只有⼀个⼴播域和端⼝数量的冲突域。</li></ul><h1 id="Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？"><a href="#Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？" class="headerlink" title="Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？"></a>Socket⽹络通信、NIO流以及多线程处理技术，Netty、Mina？</h1><h4 id="socket⽹络通信"><a href="#socket⽹络通信" class="headerlink" title="socket⽹络通信"></a>socket⽹络通信</h4><ul><li>NIO流以及多线程处理技术：</li><li>BIO:阻塞式，线程池初始时创建⼀定量线程，超过则等待；</li><li>NIO:⾮阻塞式，不同的线程⼲专业的事情，提⾼系统吞吐量；</li><li>NIO+异步处理：让少量的线程做⼤量的事情；</li></ul><h4 id="Mina"><a href="#Mina" class="headerlink" title="Mina"></a>Mina</h4><ul><li>Apache Mina是⼀个能够帮助⽤户开发⾼性能和⾼伸缩性⽹络应⽤程序的框架。</li><li>它通过Java nio技术基于TCP/IP和UDP/IP协议提供了抽象的、事件驱动的、异步的API</li><li>采⽤⾮阻塞⽅式的异步传输，⽀持批量传输数据</li><li>mina框架简单⾼效，完成了底层的线程管理，内置编码器能够满⾜⼤多数⽤户的需求，省去了消息编码和解码的⼯作。</li></ul><h4 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h4><ul><li>本质是JBoss开发的⼀个jar包，⽬的是开发⾼性能、⾼可靠性的⽹络服务和客户端服务</li><li>提供异步⾮阻塞的、事件驱动的⽹络应⽤程序的NIO框架和⼯具</li><li>处理socket</li><li>通过Future-Listener机制，⽤户可以⽅便的主动获取或者通过通知机制获得IO操作结果。</li></ul><h1 id="http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）"><a href="#http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）" class="headerlink" title="http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）"></a>http协议（报⽂结构，断点续传，多线程下载，什么是⻓连接）</h1><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul><li>HTTP协议是Hyper Text Transfer Protocol（超⽂本传输协议）的缩写,是⽤于从万维⽹（WWW:World Wide Web ）服务器传输超⽂本到本地浏览器的传送协议。</li><li>HTTP是⼀个基于TCP/IP通信协议来传递数据（HTML ⽂件, 图⽚⽂件, 查询结果等）。</li><li>HTTP是⼀个属于应⽤层的⾯向对象的协议，由于其简捷、快速的⽅式，适⽤于分布式超媒体信息系统。它于1990年提出，经过⼏年的使⽤与发展，得到不断地完善和扩展。⽬前在WWW中使⽤的是HTTP/1.0的第六版，HTTP/1.1的规范化⼯作正在进⾏之中，⽽且HTTP-NG(Next Generation of HTTP)的建议已经提出。</li><li>HTTP协议⼯作于客户端-服务端架构为上。</li><li>浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求</li><li>Web服务器根据接收到的请求后，向客户端发送响应信息。</li></ul><h4 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h4><ul><li>简单快速：客户向服务器请求服务时，只需传送请求⽅法和路径。请求⽅法常⽤的有GET、HEAD、POST。每种⽅法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模⼩，因⽽通信速度很快。</li><li>灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。</li><li>⽆连接：⽆连接的含义是限制每次连接只处理⼀个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采⽤这种⽅式可以节省传输时间。</li><li>⽆状态：HTTP协议是⽆状态协议。⽆状态是指协议对于事务处理没有记忆能⼒。缺少状态意味着如果后续处理需要前⾯的信息，则它必须重传，这样可能导致每次连接传送的数据量增⼤。另⼀⽅⾯，在服务器不需要先前信息时它的应答就较快。</li><li>⽀持B/S及C/S模式。</li></ul><h1 id="get与post区别"><a href="#get与post区别" class="headerlink" title="get与post区别"></a>get与post区别</h1><ul><li>表单的method如果为get,那么所有的参数信息都会显示在浏览器的地址栏，当我们使⽤浏览器地址栏输⼊⽹址的⽅式来发送请求时,那么该请求⼀定是get⽅式</li><li>对于get⽅式,底层是将所有参数附加在请求资源的后⾯⼀起传递的，对于post⽅式,底层是将所有参数附加在请求参数的最后⼀⾏的下⼀⾏的下⼀⾏，Get请求的数据是被附在url之后（HTTP协议头中），POST请求数据则放置在HTTP包的包体head中；</li><li>对于get,post⽅式,servlet不同处理：doGet()，doPost();</li><li>浏览器处理：重复访问使⽤GET⽅法请求的⻚⾯，浏览器会使⽤缓存处理后续请求。使⽤POST⽅法的form提交时，浏览器基于POST将产⽣永久改变的假设，将让⽤户进⾏提交确认。</li></ul><h1 id="rpc和http的区别，使⽤场景"><a href="#rpc和http的区别，使⽤场景" class="headerlink" title="rpc和http的区别，使⽤场景"></a>rpc和http的区别，使⽤场景</h1><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><h5 id="传输协议"><a href="#传输协议" class="headerlink" title="传输协议"></a>传输协议</h5><ul><li>RPC，可以基于TCP协议，也可以基于HTTP协议</li><li>HTTP，基于HTTP协议</li></ul><h5 id="传输效率"><a href="#传输效率" class="headerlink" title="传输效率"></a>传输效率</h5><ul><li>RPC，使⽤⾃定义的TCP协议，可以让请求报⽂体积更⼩，或者使⽤HTTP2协议，也可以很好的减少报⽂的体积，提⾼传输效率</li><li>HTTP，如果是基于HTTP1.1的协议，请求中会包含很多⽆⽤的内容，如果是基于HTTP2.0，那么简单的封装以下是可以作为⼀个RPC来使⽤的，这时标准RPC框架更多的是服务治理性能消耗，主要在于序列化和反序列化的耗时<br>RPC，可以基于thrift实现⾼效的⼆进制传输</li><li>HTTP，⼤部分是通过json来实现的，字节⼤⼩和序列化耗时都⽐thrift要更消耗性能</li></ul><h5 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h5><ul><li>RPC，基本都⾃带了负载均衡策略</li><li>HTTP，需要配置Nginx，HAProxy来实现</li></ul><h5 id="服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）"><a href="#服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）" class="headerlink" title="服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）"></a>服务治理（下游服务新增，重启，下线时如何不影响上游调⽤者）</h5><ul><li>RPC，能做到⾃动通知，不影响上游</li><li>HTTP，需要事先通知，修改Nginx/HAProxy配置</li></ul><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li>RPC主要⽤于公司内部的服务调⽤，性能消耗低，传输效率⾼，服务治理⽅便。</li><li>HTTP主要⽤于对外的异构环境，浏览器接⼝调⽤，APP接⼝调⽤，第三⽅接⼝调⽤等。</li></ul><h1 id="说说TCP-UDP和socket-Http之间联系和区别"><a href="#说说TCP-UDP和socket-Http之间联系和区别" class="headerlink" title="说说TCP,UDP和socket,Http之间联系和区别"></a>说说TCP,UDP和socket,Http之间联系和区别</h1><h4 id="TCP协议"><a href="#TCP协议" class="headerlink" title="TCP协议"></a>TCP协议</h4><ul><li>TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议，由IETF的RFC 793定义。</li><li>在简化的计算机网络OSI模型中，它完成第四层传输层所指定的功能，用户数据报协议（UDP）是同一层内另一个重要的传输协议。</li><li>在因特网协议族（Internet protocol suite）中，TCP层是位于IP层之上，应用层之下的中间层。</li><li>不同主机的应用层之间经常需要可靠的、像管道一样的连接，但是IP层不提供这样的流机制，而是提供不可靠的包交换。</li></ul><h5 id="TCP的优点"><a href="#TCP的优点" class="headerlink" title="TCP的优点"></a>TCP的优点</h5><ul><li>可靠，稳定</li><li>TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。</li></ul><h5 id="TCP的缺点"><a href="#TCP的缺点" class="headerlink" title="TCP的缺点"></a>TCP的缺点</h5><ul><li>慢，效率低，占用系统资源高，易被攻击</li><li>TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。<br>由于TCP存在确认机制和三次握手机制，这些是导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。</li></ul><h5 id="TCP应用场景"><a href="#TCP应用场景" class="headerlink" title="TCP应用场景"></a>TCP应用场景</h5><ul><li>当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。</li><li>在日常生活中，常见使用TCP协议的应用比如：浏览器使用HTTP，Outlook使用POP、SMTP，QQ文件传输等。</li></ul><h4 id="UDP协议"><a href="#UDP协议" class="headerlink" title="UDP协议"></a>UDP协议</h4><ul><li>U- DP 是User Datagram Protocol的简称， 中文名是用户数据报协议，是OSI（Open System Interconnection，开放式系统互联） 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，IETF RFC 768是UDP的正式规范。UDP在IP报文的协议号是17。</li></ul><h5 id="UDP的优点"><a href="#UDP的优点" class="headerlink" title="UDP的优点"></a>UDP的优点</h5><ul><li>快，比TCP稍安全</li><li>UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击……</li></ul><h5 id="UDP的缺点"><a href="#UDP的缺点" class="headerlink" title="UDP的缺点"></a>UDP的缺点</h5><ul><li>不可靠，不稳定</li><li>因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。</li></ul><h5 id="UDP应用场景"><a href="#UDP应用场景" class="headerlink" title="UDP应用场景"></a>UDP应用场景</h5><ul><li>当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。在日常生活中，常见使用UDP协议的应用比如：QQ语音、QQ视频、TFTP等。</li><li>TCP和UDP使用IP协议从一个网络传送数据包到另一个网络。把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。</li><li>TCP/IP是个协议组，可分为三个层次：网络层、传输层和应用层。<ul><li>在网络层有：IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议。</li><li>在传输层中有：TCP协议与UDP协议。</li><li>在应用层有：FTP、HTTP、TELNET、SMTP、DNS等协议。</li></ul></li><li>因此，HTTP本身就是一个协议，是从Web服务器传输超文本到本地浏览器的传送协议。</li><li>TCP和UDP是FTP，HTTP和SMTP之类使用的传输层协议。</li><li>虽然TCP和UDP都是用来传输其他协议的，它们却有一个显著的不同：TCP提供有保证的数据传输，而UDP不提供。这意味着TCP有一个特殊的机制来确保数据安全的不出错的从一个端点传到另一个端点，而UDP不提供任何这样的保证。</li></ul><h4 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h4><ul><li>HTTP（超文本传输协议）是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。客户端使用Web浏览器发起HTTP请求给Web服务器，Web服务器发送被请求的信息给客户端。</li><li>HTTP是短连接：客户端发送请求都需要服务器端回送响应.请求结束后，主动释放链接，因此为短连接。通常的做法是，不需要任何数据，也要保持每隔一段时间向服务器发送”保持连接”的请求。这样可以保证客户端在服务器端是”上线”状态。</li><li>HTTP连接使用的是”请求-响应”方式，不仅在请求时建立连接，而且客户端向服务器端请求后，服务器才返回数据。</li></ul><h4 id="Socket协议"><a href="#Socket协议" class="headerlink" title="Socket协议"></a>Socket协议</h4><ul><li>网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。</li><li>建立网络通信连接至少要一对端口号（socket）。socket本质是编程接口（API），对TCP/IP的封装，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口；HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。</li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><nav class="pagination"><span class="page-number current">1</span><a class="page-number" href="/default-index/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/default-index/page/4/">4</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/default-index/page/2/"><i class="fa fa-angle-right"></i></a></nav></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">褚岩</span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.2/anime.min.js"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>